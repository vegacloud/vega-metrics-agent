This file is a merged representation of a subset of the codebase, containing specifically included files and files not matching ignore patterns, combined into a single document by Repomix.
The content has been processed where empty lines have been removed.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Only files matching these patterns are included: **/*, .cursorrules, .cursor/rules/*
- Files matching these patterns are excluded: .*.*, **/*.pbxproj, **/node_modules/**, **/dist/**, **/build/**, **/compile/**, **/*.spec.*, **/*.pyc, **/.env, **/.env.*, **/*.env, **/*.env.*, **/*.lock, **/*.lockb, **/package-lock.*, **/pnpm-lock.*, **/*.tsbuildinfo
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Empty lines have been removed from all files
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

<additional_info>

</additional_info>

</file_summary>

<directory_structure>
charts/
  vega-metrics-agent/
    templates/
      clusterrole.yaml
      clusterrolebinding.yaml
      deployment.yaml
      namespace.yaml
      secrets.yaml
      serviceaccount.yaml
    .gitignore
    .helmignore
    .repomixignore
    Chart.yaml
    values.yaml
licenses/
  APL.txt
  BSL.txt
pkg/
  agent/
    agent.go
  collectors/
    cluster.go
    collector.go
    cronJob.go
    daemonsets.go
    hpa.go
    job.go
    namespace.go
    networking.go
    node.go
    persistentvolume.go
    persistentvolumeclaim.go
    pod.go
    replicaset.go
    replicationController..go
    storageclass.go
    workload.go
  config/
    config_loader.go
    config.go
    SCHEMAVERSION
    VERSION
  health/
    health.go
  models/
    metrics.go
  utils/
    auth.go
    k8sconfig.go
    metrics_test.go
    metrics.go
    s3.go
    safememory.go
    validate.go
test/
  resources/
    AWS_EKS_FARGATE.cft.yaml
    AWS_EKS_NODES.cft.yaml
    AZURECLUSTER-nodes.yaml
    buildkindtestcluster.sh
    kind-config.yaml
    test-resources.yaml
.gitignore
Dockerfile
go.mod
LICENSE
main.go
Makefile
README.md
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="charts/vega-metrics-agent/templates/clusterrole.yaml">
# Copyright 2024 Vega Cloud, Inc.
# Use of this software is governed by the Business Source License
# included in the file licenses/BSL.txt.
# As of the Change Date specified in that file, in accordance with
# the Business Source License, use of this software will be governed
# by the Apache License, Version 2.0, included in the file
# licenses/APL.txt.
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: metrics-agents
  annotations:
    "helm.sh/hook-weight": "1"
rules:
  - apiGroups: ["authentication.k8s.io"]
    resources: ["selfsubjectreviews"]
    verbs: ["create"]
  # Core API resources
  - apiGroups: [""]
    resources:
      - configmaps
      - endpoints
      - events
      - limitranges
      - limitranges/status
      - namespaces
      - namespaces/finalizers
      - namespaces/status
      - nodes
      - nodes/log
      - nodes/metrics
      - nodes/proxy
      - nodes/stats
      - nodes/stats/summary
      - nodes/status
      - persistentvolumeclaims
      - persistentvolumeclaims/status
      - persistentvolumes
      - persistentvolumes/status
      - pods
      - pods/ephemeralcontainers
      - pods/exec
      - pods/log
      - pods/metrics
      - pods/portforward
      - pods/proxy
      - pods/stats
      - pods/status
      - replicationcontrollers
      - resourcequotas
      - resourcequotas/status
      - serviceaccounts
      - services
      - services/proxy
      - services/status
    verbs: ["get", "list", "watch"]
  # Workload resources (batch and apps)
  - apiGroups: ["batch", "apps"]
    resources:
      - cronjobs
      - cronjobs/status
      - daemonsets
      - daemonsets/status
      - deployments
      - deployments/scale
      - deployments/status
      - jobs
      - jobs/status
      - replicasets
      - replicasets/scale
      - replicasets/status
      - statefulsets
      - statefulsets/scale
      - statefulsets/status
    verbs: ["get", "list", "watch"]
  # Networking resources (networking.k8s.io and extensions)
  - apiGroups: ["networking.k8s.io", "extensions"]
    resources:
      - ingresses
      - ingresses/status
      - ingressclasses
      - networkpolicies
      - networkpolicies/status
    verbs: ["get", "list", "watch"]
  # Metrics resources
  - apiGroups: ["metrics.k8s.io", "custom.metrics.k8s.io", "external.metrics.k8s.io", "pohpa.metrics.k8s.io"]
    resources:
      - "*"
      - pods/recommendations
    verbs: ["get", "list", "watch"]
  # Autoscaling resources
  - apiGroups: ["autoscaling", "autoscaling.k8s.io"]
    resources:
      - horizontalpodautoscalers
      - horizontalpodautoscalers/scale
      - horizontalpodautoscalers/status
      - verticalpodautoscalers
      - verticalpodautoscalers/status
    verbs: ["get", "list", "watch"]
  # Storage & Snapshot & CSI resources
  - apiGroups: ["storage.k8s.io", "snapshot.storage.k8s.io", "csi.storage.k8s.io"]
    resources:
      - storageclasses
      - volumeattachments
      - volumeattachments/status
      - csidrivers
      - csinodes
      - csistoragecapacities
      - volumeattributes
      - volumesnapshots
      - volumesnapshots/status
      - volumesnapshotcontents
      - volumesnapshotclasses
      - csiservices
    verbs: ["get", "list", "watch"]
  # Security resources (policy and security.k8s.io)
  - apiGroups: ["policy", "security.k8s.io"]
    resources:
      - poddisruptionbudgets
      - poddisruptionbudgets/status
      - podlabels
      - podmetrics
      - podsecuritypolicies
      - securitycontextconstraints
    verbs: ["get", "list", "watch"]
  # Coordination for node leases
  - apiGroups: ["coordination.k8s.io"]
    resources: ["leases"]
    verbs: ["get", "list", "watch"]
  # Node resources
  - apiGroups: ["node.k8s.io"]
    resources:
      - runtimeclasses
      - runtimeclasses/status
    verbs: ["get", "list", "watch"]
  # GPU resources
  - apiGroups: ["nvidia.com"]
    resources:
      - gpus
      - podgpus
    verbs: ["get", "list", "watch"]
  # Topology
  - apiGroups: ["topology.kubernetes.io"]
    resources:
      - nodes
      - noderesourcetopologies
      - topologyspreadconstraints
    verbs: ["get", "list", "watch"]
  # Events.k8s.io
  - apiGroups: ["events.k8s.io"]
    resources: ["events"]
    verbs: ["get", "list", "watch"]
  # Kubelet metrics and stats (NonResourceURLs)
  - nonResourceURLs:
      - "/metrics"
      - "/metrics/cadvisor"
      - "/metrics/probes"
      - "/metrics/resource"
      - "/stats/*"
      - "/stats/summary"
    verbs: ["get"]
</file>

<file path="charts/vega-metrics-agent/templates/clusterrolebinding.yaml">
# Copyright 2024 Vega Cloud, Inc.
#
# Use of this software is governed by the Business Source License
# included in the file licenses/BSL.txt.
#
# As of the Change Date specified in that file, in accordance with
# the Business Source License, use of this software will be governed
# by the Apache License, Version 2.0, included in the file
# licenses/APL.txt.
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: metrics-agents
  annotations:
    "helm.sh/hook-weight": "2"
subjects:
  - kind: ServiceAccount
    name: {{ .Values.serviceAccount.name }}
    namespace: {{ .Values.namespace }}
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: metrics-agents
</file>

<file path="charts/vega-metrics-agent/templates/namespace.yaml">
# Copyright 2024 Vega Cloud, Inc.
#
# Use of this software is governed by the Business Source License
# included in the file licenses/BSL.txt.
#
# As of the Change Date specified in that file, in accordance with
# the Business Source License, use of this software will be governed
# by the Apache License, Version 2.0, included in the file
# licenses/APL.txt.
apiVersion: v1
kind: Namespace
metadata:
  name: {{ .Values.namespace }}
</file>

<file path="charts/vega-metrics-agent/templates/secrets.yaml">
# Copyright 2024 Vega Cloud, Inc.
# Use of this software is governed by the Business Source License
# included in the file licenses/BSL.txt.
# As of the Change Date specified in that file, in accordance with
# the Business Source License, use of this software will be governed
# by the Apache License, Version 2.0, included in the file
# licenses/APL.txt.
apiVersion: v1
kind: Secret
metadata:
  name: vega-metrics-agent-secret
  namespace: {{ .Values.namespace }}
type: Opaque
stringData:
  VEGA_CLIENT_ID: "{{ .Values.vega.clientId }}"
  VEGA_CLIENT_SECRET: "{{ .Values.vega.clientSecret }}"
</file>

<file path="charts/vega-metrics-agent/templates/serviceaccount.yaml">
# Copyright 2024 Vega Cloud, Inc.
#
# Use of this software is governed by the Business Source License
# included in the file licenses/BSL.txt.
#
# As of the Change Date specified in that file, in accordance with
# the Business Source License, use of this software will be governed
# by the Apache License, Version 2.0, included in the file
# licenses/APL.txt.
apiVersion: v1
kind: ServiceAccount
metadata:
  name: {{ .Values.serviceAccount.name }}
  namespace: {{ .Values.namespace }}
  annotations:
    "helm.sh/hook-weight": "0"
automountServiceAccountToken: true  # Add this line
</file>

<file path="charts/vega-metrics-agent/.helmignore">
# Patterns to ignore when building packages.
# This supports shell glob matching, relative path matching, and
# negation (prefixed with !). Only one pattern per line.
.DS_Store
# Common VCS dirs
.git/
.gitignore
.bzr/
.bzrignore
.hg/
.hgignore
.svn/
# Common backup files
*.swp
*.bak
*.tmp
*.orig
*~
# Various IDEs
.project
.idea/
*.tmproj
.vscode/
</file>

<file path="charts/vega-metrics-agent/Chart.yaml">
# Copyright 2024 Vega Cloud, Inc.
#
# Use of this software is governed by the Business Source License
# included in the file licenses/BSL.txt.
#
# As of the Change Date specified in that file, in accordance with
# the Business Source License, use of this software will be governed
# by the Apache License, Version 2.0, included in the file
# licenses/APL.txt.
apiVersion: v2
name: vega-metrics-agent
description: A Helm chart for deploying Vega Metrics Agent
version: 1.1.3
appVersion: "1.1.3"
type: application
</file>

<file path="licenses/APL.txt">
Apache License
                           Version 2.0, January 2004
                        http://www.apache.org/licenses/

   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION

   1. Definitions.

      "License" shall mean the terms and conditions for use, reproduction,
      and distribution as defined by Sections 1 through 9 of this document.

      "Licensor" shall mean the copyright owner or entity authorized by
      the copyright owner that is granting the License.

      "Legal Entity" shall mean the union of the acting entity and all
      other entities that control, are controlled by, or are under common
      control with that entity. For the purposes of this definition,
      "control" means (i) the power, direct or indirect, to cause the
      direction or management of such entity, whether by contract or
      otherwise, or (ii) ownership of fifty percent (50%) or more of the
      outstanding shares, or (iii) beneficial ownership of such entity.

      "You" (or "Your") shall mean an individual or Legal Entity
      exercising permissions granted by this License.

      "Source" form shall mean the preferred form for making modifications,
      including but not limited to software source code, documentation
      source, and configuration files.

      "Object" form shall mean any form resulting from mechanical
      transformation or translation of a Source form, including but
      not limited to compiled object code, generated documentation,
      and conversions to other media types.

      "Work" shall mean the work of authorship, whether in Source or
      Object form, made available under the License, as indicated by a
      copyright notice that is included in or attached to the work
      (an example is provided in the Appendix below).

      "Derivative Works" shall mean any work, whether in Source or Object
      form, that is based on (or derived from) the Work and for which the
      editorial revisions, annotations, elaborations, or other modifications
      represent, as a whole, an original work of authorship. For the purposes
      of this License, Derivative Works shall not include works that remain
      separable from, or merely link (or bind by name) to the interfaces of,
      the Work and Derivative Works thereof.

      "Contribution" shall mean any work of authorship, including
      the original version of the Work and any modifications or additions
      to that Work or Derivative Works thereof, that is intentionally
      submitted to Licensor for inclusion in the Work by the copyright owner
      or by an individual or Legal Entity authorized to submit on behalf of
      the copyright owner. For the purposes of this definition, "submitted"
      means any form of electronic, verbal, or written communication sent
      to the Licensor or its representatives, including but not limited to
      communication on electronic mailing lists, source code control systems,
      and issue tracking systems that are managed by, or on behalf of, the
      Licensor for the purpose of discussing and improving the Work, but
      excluding communication that is conspicuously marked or otherwise
      designated in writing by the copyright owner as "Not a Contribution."

      "Contributor" shall mean Licensor and any individual or Legal Entity
      on behalf of whom a Contribution has been received by Licensor and
      subsequently incorporated within the Work.

   2. Grant of Copyright License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      copyright license to reproduce, prepare Derivative Works of,
      publicly display, publicly perform, sublicense, and distribute the
      Work and such Derivative Works in Source or Object form.

   3. Grant of Patent License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      (except as stated in this section) patent license to make, have made,
      use, offer to sell, sell, import, and otherwise transfer the Work,
      where such license applies only to those patent claims licensable
      by such Contributor that are necessarily infringed by their
      Contribution(s) alone or by combination of their Contribution(s)
      with the Work to which such Contribution(s) was submitted. If You
      institute patent litigation against any entity (including a
      cross-claim or counterclaim in a lawsuit) alleging that the Work
      or a Contribution incorporated within the Work constitutes direct
      or contributory patent infringement, then any patent licenses
      granted to You under this License for that Work shall terminate
      as of the date such litigation is filed.

   4. Redistribution. You may reproduce and distribute copies of the
      Work or Derivative Works thereof in any medium, with or without
      modifications, and in Source or Object form, provided that You
      meet the following conditions:

      (a) You must give any other recipients of the Work or
          Derivative Works a copy of this License; and

      (b) You must cause any modified files to carry prominent notices
          stating that You changed the files; and

      (c) You must retain, in the Source form of any Derivative Works
          that You distribute, all copyright, patent, trademark, and
          attribution notices from the Source form of the Work,
          excluding those notices that do not pertain to any part of
          the Derivative Works; and

      (d) If the Work includes a "NOTICE" text file as part of its
          distribution, then any Derivative Works that You distribute must
          include a readable copy of the attribution notices contained
          within such NOTICE file, excluding those notices that do not
          pertain to any part of the Derivative Works, in at least one
          of the following places: within a NOTICE text file distributed
          as part of the Derivative Works; within the Source form or
          documentation, if provided along with the Derivative Works; or,
          within a display generated by the Derivative Works, if and
          wherever such third-party notices normally appear. The contents
          of the NOTICE file are for informational purposes only and
          do not modify the License. You may add Your own attribution
          notices within Derivative Works that You distribute, alongside
          or as an addendum to the NOTICE text from the Work, provided
          that such additional attribution notices cannot be construed
          as modifying the License.

      You may add Your own copyright statement to Your modifications and
      may provide additional or different license terms and conditions
      for use, reproduction, or distribution of Your modifications, or
      for any such Derivative Works as a whole, provided Your use,
      reproduction, and distribution of the Work otherwise complies with
      the conditions stated in this License.

   5. Submission of Contributions. Unless You explicitly state otherwise,
      any Contribution intentionally submitted for inclusion in the Work
      by You to the Licensor shall be under the terms and conditions of
      this License, without any additional terms or conditions.
      Notwithstanding the above, nothing herein shall supersede or modify
      the terms of any separate license agreement you may have executed
      with Licensor regarding such Contributions.

   6. Trademarks. This License does not grant permission to use the trade
      names, trademarks, service marks, or product names of the Licensor,
      except as required for reasonable and customary use in describing the
      origin of the Work and reproducing the content of the NOTICE file.

   7. Disclaimer of Warranty. Unless required by applicable law or
      agreed to in writing, Licensor provides the Work (and each
      Contributor provides its Contributions) on an "AS IS" BASIS,
      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
      implied, including, without limitation, any warranties or conditions
      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
      PARTICULAR PURPOSE. You are solely responsible for determining the
      appropriateness of using or redistributing the Work and assume any
      risks associated with Your exercise of permissions under this License.

   8. Limitation of Liability. In no event and under no legal theory,
      whether in tort (including negligence), contract, or otherwise,
      unless required by applicable law (such as deliberate and grossly
      negligent acts) or agreed to in writing, shall any Contributor be
      liable to You for damages, including any direct, indirect, special,
      incidental, or consequential damages of any character arising as a
      result of this License or out of the use or inability to use the
      Work (including but not limited to damages for loss of goodwill,
      work stoppage, computer failure or malfunction, or any and all
      other commercial damages or losses), even if such Contributor
      has been advised of the possibility of such damages.

   9. Accepting Warranty or Additional Liability. While redistributing
      the Work or Derivative Works thereof, You may choose to offer,
      and charge a fee for, acceptance of support, warranty, indemnity,
      or other liability obligations and/or rights consistent with this
      License. However, in accepting such obligations, You may act only
      on Your own behalf and on Your sole responsibility, not on behalf
      of any other Contributor, and only if You agree to indemnify,
      defend, and hold each Contributor harmless for any liability
      incurred by, or claims asserted against, such Contributor by reason
      of your accepting any such warranty or additional liability.

   END OF TERMS AND CONDITIONS

   APPENDIX: How to apply the Apache License to your work.

      To apply the Apache License to your work, attach the following
      boilerplate notice, with the fields enclosed by brackets "{}"
      replaced with your own identifying information. (Don't include
      the brackets!)  The text should be enclosed in the appropriate
      comment syntax for the file format. We also recommend that a
      file or class name and description of purpose be included on the
      same "printed page" as the copyright notice for easier
      identification within third-party archives.

   Copyright {}

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
</file>

<file path="licenses/BSL.txt">
Business Source License 1.1

Parameters

Licensor:             Vega Cloud, Inc.
Licensed Work:        Vega Metrics Agent 0.0.1 and Later
                      The Licensed Work is (c) 2024 Vega Cloud, Inc.
Additional Use Grant: 

You may make production use of the Licensed Work, provided Your use does not 
include offering the Licensed Work to third parties on a hosted or embedded 
basis in order to compete with Vega Cloud’s paid version(s) of the Licensed Work. 

For purposes of this license:

A “competitive offering” is a Product that is offered to third parties on a paid 
basis, including through paid support arrangements, that significantly overlaps 
with the capabilities of Vega Cloud’s paid version(s) of the Licensed Work. If 
Your Product is not a competitive offering when You first make it generally 
available, it will not become a competitive offering later due to Vega Cloud 
releasing a new version of the Licensed Work with additional capabilities. In 
addition, Products that are not provided on a paid basis are not competitive.

“Product” means software that is offered to end users to manage in their own 
environments or offered as a service on a hosted basis.

“Embedded” means including the source code or executable code from the Licensed 
Work in a competitive offering. “Embedded” also means packaging the competitive 
offering in such a way that the Licensed Work must be accessed or downloaded for 
the competitive offering to operate.

Hosting or using the Licensed Work(s) for internal purposes within an organization 
is not considered a competitive offering. Vega Cloud considers your organization to 
include all of your affiliates under common control.



Change Date:          2027-10-01

Change License:       Apache License, Version 2.0

Notice

The Business Source License (this document, or the “License”) is not an Open
Source license. However, the Licensed Work will eventually be made available
under an Open Source License, as stated in this License.

License text copyright (c) 2017 MariaDB Corporation Ab, All Rights Reserved.
“Business Source License” is a trademark of MariaDB Corporation Ab.

-----------------------------------------------------------------------------

Business Source License 1.1

Terms

The Licensor hereby grants you the right to copy, modify, create derivative
works, redistribute, and make non-production use of the Licensed Work. The
Licensor may make an Additional Use Grant, above, permitting limited
production use.

Effective on the Change Date, or the fourth anniversary of the first publicly
available distribution of a specific version of the Licensed Work under this
License, whichever comes first, the Licensor hereby grants you rights under
the terms of the Change License, and the rights granted in the paragraph
above terminate.

If your use of the Licensed Work does not comply with the requirements
currently in effect as described in this License, you must purchase a
commercial license from the Licensor, its affiliated entities, or authorized
resellers, or you must refrain from using the Licensed Work.

All copies of the original and modified Licensed Work, and derivative works
of the Licensed Work, are subject to this License. This License applies
separately for each version of the Licensed Work and the Change Date may vary
for each version of the Licensed Work released by Licensor.

You must conspicuously display this License on each original or modified copy
of the Licensed Work. If you receive the Licensed Work in original or
modified form from a third party, the terms and conditions set forth in this
License apply to your use of that work.

Any use of the Licensed Work in violation of this License will automatically
terminate your rights under this License for the current and all other
versions of the Licensed Work.

This License does not grant you any right in any trademark or logo of
Licensor or its affiliates (provided that you may use a trademark or logo of
Licensor as expressly required by this License).

TO THE EXTENT PERMITTED BY APPLICABLE LAW, THE LICENSED WORK IS PROVIDED ON
AN “AS IS” BASIS. LICENSOR HEREBY DISCLAIMS ALL WARRANTIES AND CONDITIONS,
EXPRESS OR IMPLIED, INCLUDING (WITHOUT LIMITATION) WARRANTIES OF
MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, NON-INFRINGEMENT, AND
TITLE.

MariaDB hereby grants you permission to use this License’s text to license
your works, and to refer to it using the trademark “Business Source License”,
as long as you comply with the Covenants of Licensor below.

Covenants of Licensor

In consideration of the right to use this License’s text and the “Business
Source License” name and trademark, Licensor covenants to MariaDB, and to all
other recipients of the licensed work to be provided by Licensor:

1. To specify as the Change License the GPL Version 2.0 or any later version,
   or a license that is compatible with GPL Version 2.0 or a later version,
   where “compatible” means that software provided under the Change License can
   be included in a program with software provided under GPL Version 2.0 or a
   later version. Licensor may specify additional Change Licenses without
   limitation.

2. To either: (a) specify an additional grant of rights to use that does not
   impose any additional restriction on the right granted in this License, as
   the Additional Use Grant; or (b) insert the text “None”.

3. To specify a Change Date.

4. Not to modify this License in any other way.
</file>

<file path="pkg/agent/agent.go">
// Package agent provides the main struct and methods for the metrics agent
// Copyright 2024 Vega Cloud, Inc.
//
// Use of this software is governed by the Business Source License
// included in the file licenses/BSL.txt.
//
// As of the Change Date specified in that file, in accordance with
// the Business Source License, use of this software will be governed
// by the Apache License, Version 2.0, included in the file
// licenses/APL.txt.
package agent
import (
	"bytes"
	"context"
	"encoding/json"
	"errors"
	"fmt"
	"io"
	"net/http"
	"os"
	"regexp"
	"strings"
	"sync"
	"time"
	"github.com/sirupsen/logrus"
	"crypto/tls"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"github.com/vegacloud/kubernetes/metricsagent/pkg/collectors"
	"github.com/vegacloud/kubernetes/metricsagent/pkg/config"
	"github.com/vegacloud/kubernetes/metricsagent/pkg/utils"
	corev1 "k8s.io/api/core/v1"
	"k8s.io/client-go/kubernetes"
	"k8s.io/client-go/rest"
	"k8s.io/client-go/transport"
)
// MetricsAgent is the main struct for the metrics agent
type MetricsAgent struct {
	config     *config.Config
	collectors map[string]collectors.Collector
	uploader   utils.Uploader
	httpClient *http.Client
	logger     *logrus.Entry
}
// CheckinRequest represents the request structure for agent checkin operations.
type CheckinRequest struct {
	AgentID         string             `json:"agent_id"`
	ClusterName     string             `json:"cluster_name"`
	ClusterVersion  *string            `json:"cluster_version,omitempty"`
	AgentVersion    *string            `json:"agent_version,omitempty"`
	SchemaVersion   *string            `json:"schema_version,omitempty"`
	ClusterProvider *string            `json:"cluster_provider,omitempty"`
	AgentStatus     *string            `json:"agent_status,omitempty"`
	CollectorStatus *map[string]string `json:"collector_status,omitempty"`
}
// NewMetricsAgent creates a new MetricsAgent
func NewMetricsAgent(cfg *config.Config, logger *logrus.Entry) (*MetricsAgent, error) {
	logger = logger.WithField("function", "NewMetricsAgent")
	clientConfig, err := utils.GetExistingClientConfig()
	if err != nil {
		return nil, fmt.Errorf("failed to get existing client config: %w", err)
	}
	token, err := os.ReadFile("/var/run/secrets/kubernetes.io/serviceaccount/token")
	if err != nil {
		return nil, fmt.Errorf("failed to read service account token: %w", err)
	}
	restClient := clientConfig.Clientset.CoreV1().RESTClient().(*rest.RESTClient)
	restClient.Client.Transport = &http.Transport{TLSClientConfig: &tls.Config{InsecureSkipVerify: cfg.VegaInsecure}} // #nosec G402
	restClient.Client.Transport = transport.NewBearerAuthRoundTripper(string(token), restClient.Client.Transport)
	clusterVersion, err := getClusterVersion(clientConfig.Clientset)
	if err != nil {
		return nil, fmt.Errorf("failed to get cluster version: %w", err)
	}
	logger.Infof("Cluster version: %s", clusterVersion)
	logger.Debugf("Getting Cluster Provider before the function")
	clusterProvider := getClusterProvider(clientConfig.Clientset, clusterVersion, logger)
	logger.Debugf("Getting Cluster Provider after the function")
	logger.Infof("Cluster provider: %s", clusterProvider)
	cfg.ClusterVersion = clusterVersion
	cfg.ClusterProvider = clusterProvider
	collectorsMap := initializeCollectors(clientConfig.Clientset, cfg)
	logger.Debugf("loaded %v collectors", len(collectorsMap))
	uploader, err := utils.NewS3Uploader(cfg)
	if err != nil {
		return nil, fmt.Errorf("failed to create S3 uploader: %w", err)
	}
	ma := &MetricsAgent{
		config:     cfg,
		collectors: collectorsMap,
		uploader:   uploader,
		logger:     logger.WithField("component", "MetricsAgent"),
		httpClient: &http.Client{Timeout: 90 * time.Second},
	}
	if cfg.ShouldAgentCheckIn {
		logger.Debug("Attempting to check in with the metrics server")
		if err := ma.Checkin(context.Background()); err != nil {
			logger.WithError(err).Debug("Checkin attempt failed with detailed error")
			logrus.WithError(err).Error("Failed to check in with the metrics server")
		}
	}
	return ma, nil
}
// initializeCollectors initializes the collectors map
func initializeCollectors(clientset *kubernetes.Clientset, cfg *config.Config) map[string]collectors.Collector {
	return map[string]collectors.Collector{
		"cluster":               collectors.NewClusterCollector(clientset, cfg),
		"namespace":             collectors.NewNamespaceCollector(clientset, cfg),
		"node":                  collectors.NewNodeCollector(clientset, cfg),
		"pod":                   collectors.NewPodCollector(clientset, cfg),
		"pv":                    collectors.NewPersistentVolumeCollector(clientset, cfg),
		"pvc":                   collectors.NewPersistentVolumeClaimCollector(clientset, cfg),
		"workload":              collectors.NewWorkloadCollector(clientset, cfg),
		"daemonset":             collectors.NewDaemonSetCollector(clientset, cfg),
		"network":               collectors.NewNetworkingCollector(clientset, cfg),
		"job":                   collectors.NewJobCollector(clientset, cfg),
		"cronjob":               collectors.NewCronJobCollector(clientset, cfg),
		"hpa":                   collectors.NewHPACollector(clientset, cfg),
		"replicationcontroller": collectors.NewReplicationControllerCollector(clientset, cfg),
		"storageclass":          collectors.NewStorageClassCollector(clientset, cfg),
		"replicaset":            collectors.NewReplicaSetCollector(clientset, cfg),
	}
}
// Run starts the metrics collection and upload process
func (ma *MetricsAgent) Run(ctx context.Context) {
	// Check if we should start collection immediately
	if ma.config.StartCollectionNow {
		ma.logger.Info("Starting metrics collection immediately as per configuration")
		if err := ma.collectAndUploadMetrics(ctx); err != nil {
			ma.logger.WithError(err).Error("Failed to collect and upload metrics")
		}
	} else {
		// Calculate the time to the next upcoming half-hour
		now := time.Now()
		nextHalfHour := now.Truncate(30 * time.Minute).Add(30 * time.Minute)
		timeUntilNextHalfHour := time.Until(nextHalfHour)
		// Log the time until the first execution
		ma.logger.Infof("Waiting %v until next half-hour to start metrics collection", timeUntilNextHalfHour)
		// Wait until the next half-hour
		select {
		case <-time.After(timeUntilNextHalfHour):
		case <-ctx.Done():
			ma.logger.Info("Stopping metrics agent before first run")
			return
		}
		// Collect and upload metrics at the next half-hour mark
		if err := ma.collectAndUploadMetrics(ctx); err != nil {
			ma.logger.WithError(err).Error("Failed to collect and upload metrics")
		}
	}
	// Start the ticker for regular intervals after the first execution
	ticker := time.NewTicker(ma.config.VegaPollInterval)
	defer ticker.Stop()
	// Run the metrics collection in a loop
	for {
		select {
		case <-ctx.Done():
			ma.logger.Info("Stopping metrics agent")
			return
		case <-ticker.C:
			if err := ma.collectAndUploadMetrics(ctx); err != nil {
				ma.logger.WithError(err).Error("Failed to collect and upload metrics")
			}
		}
	}
}
func (ma *MetricsAgent) collectAndUploadMetrics(ctx context.Context) error {
	var wg sync.WaitGroup
	var mu sync.Mutex
	metrics := make(map[string]interface{})
	var combinedErrors error
	// Create a buffered channel to limit the number of concurrent collectors
	concurrencyLimit := ma.config.VegaMaxConcurrency
	semaphore := make(chan struct{}, concurrencyLimit)
	startTime := time.Now()
	if ma.config.ShouldAgentCheckIn {
		go func() {
			logrus.Info("Starting Kubernetes Data Collection")
			if err := ma.Checkin(ctx); err != nil {
				logrus.WithError(err).Error("Failed to check in with the metrics server")
			}
		}()
	}
	// Collect metrics from each collector concurrently
	for name, collector := range ma.collectors {
		wg.Add(1)
		go func(name string, collector collectors.Collector) {
			defer wg.Done()
			// Acquire a slot in the semaphore
			semaphore <- struct{}{}
			defer func() { <-semaphore }() // Release the slot when done
			ma.logger.WithField("collector", name).Info("Collecting metrics")
			collectedMetrics, err := collector.CollectMetrics(ctx)
			if err != nil {
				ma.logger.WithField("collector", name).WithError(err).Error("Failed to collect metrics")
				mu.Lock()
				combinedErrors = errors.Join(combinedErrors, fmt.Errorf("collector %s: %w", name, err))
				mu.Unlock()
				return
			}
			mu.Lock()
			metrics[name] = collectedMetrics
			mu.Unlock()
		}(name, collector)
	}
	wg.Wait()
	if err := ma.uploader.UploadMetrics(ctx, metrics); err != nil {
		return fmt.Errorf("failed to upload metrics: %w", err)
	}
	if combinedErrors != nil {
		ma.logger.WithError(combinedErrors).Error("Failed to collect and upload metrics")
		return combinedErrors
	}
	ma.logger.Debugf("Successfully collected and uploaded metrics, in %v", time.Since(startTime))
	return nil
}
// Checkin calls the /agents/checkin endpoint on the metrics server
// with the AgentId, VegaOrgSlug, VegaClientID, and VegaClusterName
func (ma *MetricsAgent) Checkin(ctx context.Context) error {
	const (
		statusError = "Error"
		statusOk    = "Ok"
	)
	checkinURL := ma.config.MetricsCollectorAPI + "/agents/checkin"
	collectorStatus := make(map[string]string)
	hasError := false
	for name, collector := range ma.collectors {
		_, err := collector.CollectMetrics(ctx)
		if err != nil {
			collectorStatus[name] = statusError
			hasError = true
		} else {
			collectorStatus[name] = statusOk
		}
	}
	agentStatus := statusOk
	if hasError {
		agentStatus = statusError
	}
	ma.logger.WithFields(logrus.Fields{
		"collector_status_length": len(collectorStatus),
		"agent_status":            agentStatus,
	}).Debug("Collector and Agent status")
	payload := CheckinRequest{
		AgentID:         ma.config.AgentID,
		ClusterName:     ma.config.VegaClusterName,
		ClusterVersion:  &ma.config.ClusterVersion,
		AgentVersion:    &ma.config.AgentVersion,
		SchemaVersion:   &ma.config.SchemaVersion,
		ClusterProvider: &ma.config.ClusterProvider,
		AgentStatus:     &agentStatus,
		CollectorStatus: &collectorStatus,
	}
	// log payloads agent id
	ma.logger.WithField("agent_id", ma.config.AgentID).Debug("Payload")
	payloadBytes, err := json.Marshal(payload)
	if err != nil {
		return fmt.Errorf("failed to marshal check-in payload: %w", err)
	}
	ma.logger.WithField("payload", string(payloadBytes)).Debug("Payload")
	req, err := http.NewRequestWithContext(ctx, http.MethodPost, checkinURL, bytes.NewBuffer(payloadBytes))
	if err != nil {
		return fmt.Errorf("failed to create check-in request: %w", err)
	}
	req.Header.Set("Content-Type", "application/json")
	token, err := utils.GetVegaAuthToken(ctx, ma.httpClient, ma.config)
	if err != nil {
		return fmt.Errorf("failed to get auth token: %w", err)
	}
	req.Header.Set("Authorization", "Bearer "+token)
	resp, err := ma.httpClient.Do(req)
	if err != nil {
		return fmt.Errorf("failed to send check-in request: %w", err)
	}
	defer resp.Body.Close()
	if resp.StatusCode != http.StatusOK {
		body, _ := io.ReadAll(resp.Body)
		return fmt.Errorf("check-in request failed with status %d: %s", resp.StatusCode, string(body))
	}
	ma.logger.Debug("Successfully checked in with the metrics server")
	return nil
}
// getClusterVersion retrieves the Kubernetes cluster version using the clientset
func getClusterVersion(clientset *kubernetes.Clientset) (string, error) {
	versionInfo, err := clientset.Discovery().ServerVersion()
	if err != nil {
		return "", fmt.Errorf("failed to get server version: %w", err)
	}
	return versionInfo.String(), nil
}
var eksPattern = regexp.MustCompile(`(?i)eks|aws|amazon`)
func isEKS(clusterVersion string, logger *logrus.Entry) bool {
	logger.Debugf("Checking if cluster is EKS")
	return eksPattern.MatchString(clusterVersion)
}
func isAKS(clientset *kubernetes.Clientset, logger *logrus.Entry) bool {
	logger.Debugf("Checking if cluster is AKS")
	var aksAzurePattern = regexp.MustCompile(`(?i)aks|azure`)
	pods, err := clientset.CoreV1().Pods("").List(context.Background(), metav1.ListOptions{})
	if err != nil {
		return false
	}
	// Create a channel to receive results
	results := make(chan bool, len(pods.Items))
	// Process each pod in a separate goroutine
	for _, pod := range pods.Items {
		go func(pod corev1.Pod) {
			labels := pod.GetLabels()
			// Fast path check
			if managedBy, exists := labels["kubernetes.azure.com/managedby"]; exists {
				if strings.EqualFold(managedBy, "aks") {
					results <- true
					return
				}
			}
			// Slower path check
			for key, value := range labels {
				combined := key + " " + value
				if aksAzurePattern.MatchString(combined) {
					results <- true
					return
				}
			}
			results <- false
		}(pod)
	}
	// Collect results
	for range pods.Items {
		if <-results {
			return true
		}
	}
	return false
}
func isGKE(clientset *kubernetes.Clientset, logger *logrus.Entry) bool {
	logger.Debugf("Checking if cluster is GKE")
	discoveryClient := clientset.Discovery()
	apiGroups, err := discoveryClient.ServerGroups()
	if err != nil {
		return false
	}
	for _, group := range apiGroups.Groups {
		if strings.Contains(group.Name, "gke") {
			return true
		}
	}
	return false
}
// getClusterProvider determines the cloud provider based on API groups
func getClusterProvider(clientset *kubernetes.Clientset, clusterVersion string, logger *logrus.Entry) string {
	logger.Debugf("Getting Cluster Provider")
	if isEKS(clusterVersion, logger) {
		logger.Debug("Cluster is EKS")
		return "AWS"
	} else if isAKS(clientset, logger) {
		logger.Debug("Cluster is AKS")
		return "AZURE"
	} else if isGKE(clientset, logger) {
		logger.Debug("Cluster is GKE")
		return "GCP"
	}
	return "UNKNOWN"
}
</file>

<file path="pkg/collectors/cluster.go">
// Copyright 2024 Vega Cloud, Inc.
//
// Use of this software is governed by the Business Source License
// included in the file licenses/BSL.txt.
//
// As of the Change Date specified in that file, in accordance with
// the Business Source License, use of this software will be governed
// by the Apache License, Version 2.0, included in the file
// licenses/APL.txt.
// Package collectors hosts the collection functions
package collectors
import (
	"context"
	"fmt"
	"os"
	"regexp"
	"runtime/debug"
	"strings"
	"github.com/sirupsen/logrus"
	v1 "k8s.io/api/core/v1"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/client-go/kubernetes"
	"github.com/vegacloud/kubernetes/metricsagent/pkg/config"
	"github.com/vegacloud/kubernetes/metricsagent/pkg/models"
	"github.com/vegacloud/kubernetes/metricsagent/pkg/utils"
)
// ClusterCollector collects cluster-wide metrics
type ClusterCollector struct {
	clientset *kubernetes.Clientset
	config    *config.Config
}
// NewClusterCollector creates a new cluster collector
func NewClusterCollector(clientset *kubernetes.Clientset, cfg *config.Config) *ClusterCollector {
	logrus.Debug("Starting ClusterCollector")
	logrus.Debug("ClusterCollector initialized successfully")
	return &ClusterCollector{
		clientset: clientset,
		config:    cfg,
	}
}
// CollectMetrics collects cluster-wide metrics
func (cc *ClusterCollector) CollectMetrics(ctx context.Context) (interface{}, error) {
	defer func() {
		if r := recover(); r != nil {
			logrus.WithFields(logrus.Fields{
				"panic":      r,
				"stacktrace": string(debug.Stack()),
			}).Error("Recovered from panic in HPACollector.CollectMetrics")
		}
	}()
	metrics, err := cc.CollectClusterMetrics(ctx)
	if err != nil {
		logrus.WithFields(logrus.Fields{
			"error": err,
		}).Error("Failed to collect HPA metrics")
		return []models.ClusterMetrics{}, nil
	}
	logrus.WithField("count", len(metrics)).Debug("Successfully collected HPA metrics")
	return metrics, nil
}
var eksPattern = regexp.MustCompile(`(?i)eks|aws|amazon`)
func isEKS(clusterVersion string, logger *logrus.Entry) bool {
	logger.Debugf("Checking if cluster is EKS")
	return eksPattern.MatchString(clusterVersion)
}
func isAKS(clientset *kubernetes.Clientset, logger *logrus.Entry) bool {
	logger.Debugf("Checking if cluster is AKS")
	var aksAzurePattern = regexp.MustCompile(`(?i)aks|azure`)
	pods, err := clientset.CoreV1().Pods("").List(context.Background(), metav1.ListOptions{})
	if err != nil {
		return false
	}
	// Create a channel to receive results
	results := make(chan bool, len(pods.Items))
	// Process each pod in a separate goroutine
	for _, pod := range pods.Items {
		go func(pod v1.Pod) {
			labels := pod.GetLabels()
			// Fast path check
			if managedBy, exists := labels["kubernetes.azure.com/managedby"]; exists {
				if strings.EqualFold(managedBy, "aks") {
					results <- true
					return
				}
			}
			// Slower path check
			for key, value := range labels {
				combined := key + " " + value
				if aksAzurePattern.MatchString(combined) {
					results <- true
					return
				}
			}
			results <- false
		}(pod)
	}
	// Collect results
	for range pods.Items {
		if <-results {
			return true
		}
	}
	return false
}
func isGKE(clientset *kubernetes.Clientset, logger *logrus.Entry) bool {
	logger.Debugf("Checking if cluster is GKE")
	discoveryClient := clientset.Discovery()
	apiGroups, err := discoveryClient.ServerGroups()
	if err != nil {
		return false
	}
	for _, group := range apiGroups.Groups {
		if strings.Contains(group.Name, "gke") {
			return true
		}
	}
	return false
}
// getClusterProvider determines the cloud provider based on API groups
func getClusterProvider(clientset *kubernetes.Clientset, clusterVersion string, logger *logrus.Entry) string {
	logger.Debugf("Getting Cluster Provider")
	if isEKS(clusterVersion, logger) {
		logger.Debug("Cluster is EKS")
		return "AWS"
	} else if isAKS(clientset, logger) {
		logger.Debug("Cluster is AKS")
		return "AZURE"
	} else if isGKE(clientset, logger) {
		logger.Debug("Cluster is GKE")
		return "GCP"
	}
	return "UNKNOWN"
}
// CollectClusterMetrics collects cluster-wide metrics
func (cc *ClusterCollector) CollectClusterMetrics(ctx context.Context) ([]models.ClusterMetrics, error) {
	logger := logrus.WithField("collector", "ClusterCollector")
	// Add debug logging for the client configuration
	if token, err := os.ReadFile("/var/run/secrets/kubernetes.io/serviceaccount/token"); err == nil {
		logger.Debugf("Service account token length: %d", len(string(token)))
	}
	// Verify client identity before collecting metrics
	if err := VerifyCollectorClient(ctx, cc.clientset, cc.config.VegaNamespace, "ClusterCollector"); err != nil {
		return nil, err
	}
	version, err := cc.clientset.Discovery().ServerVersion()
	if err != nil {
		return nil, fmt.Errorf("failed to get server version: %w", err)
	}
	clusterVersion := version.String()
	clusterProvider := getClusterProvider(cc.clientset, clusterVersion, logger)
	nodes, err := cc.clientset.CoreV1().Nodes().List(ctx, metav1.ListOptions{})
	if err != nil {
		return nil, fmt.Errorf("failed to list nodes: %w", err)
	}
	logger.Debugf("Successfully listed %d nodes", len(nodes.Items))
	pods, err := cc.clientset.CoreV1().Pods("").List(ctx, metav1.ListOptions{})
	if err != nil {
		return nil, fmt.Errorf("failed to list pods: %w", err)
	}
	logger.Debugf("Successfully listed %d pods", len(pods.Items))
	var metrics []models.ClusterMetrics
	clusterMetrics := models.ClusterMetrics{
		KubernetesVersion: clusterVersion,
		ClusterProvider:   clusterProvider,
		NodeCount:         len(nodes.Items),
		PodCount:          len(pods.Items),
		ContainerCount:    cc.countContainers(pods.Items),
		NodeLabels:        make(map[string]map[string]string),
		PodLabels:         make(map[string]map[string]string),
	}
	clusterMetrics.TotalCapacity = cc.calculateTotalCapacity(nodes.Items)
	clusterMetrics.TotalAllocatable = cc.calculateTotalAllocatable(nodes.Items)
	clusterMetrics.TotalRequests = cc.calculateTotalRequests(pods.Items)
	clusterMetrics.TotalLimits = cc.calculateTotalLimits(pods.Items)
	// Collect labels for nodes
	for _, node := range nodes.Items {
		clusterMetrics.NodeLabels[node.Name] = node.Labels
	}
	// Collect labels for pods
	for _, pod := range pods.Items {
		podKey := fmt.Sprintf("%s/%s", pod.Namespace, pod.Name)
		clusterMetrics.PodLabels[podKey] = pod.Labels
	}
	metrics = append(metrics, clusterMetrics)
	return metrics, nil
}
func (cc *ClusterCollector) calculateTotalCapacity(nodes []v1.Node) models.ResourceMetrics {
	total := models.ResourceMetrics{}
	for _, node := range nodes {
		total.CPU += node.Status.Capacity.Cpu().MilliValue()
		total.Memory += node.Status.Capacity.Memory().Value()
		total.Storage += node.Status.Allocatable.Storage().Value()
		if ephemeral, ok := node.Status.Allocatable[v1.ResourceEphemeralStorage]; ok {
			total.EphemeralStorage += ephemeral.Value()
		}
		total.Pods += node.Status.Allocatable.Pods().Value()
		// Collect GPU metrics if available
		if gpuQuantity, ok := node.Status.Capacity["nvidia.com/gpu"]; ok {
			gpuMetric := models.GPUMetrics{
				DeviceID:    fmt.Sprintf("node-%s-gpu", node.Name),
				MemoryTotal: utils.SafeGPUMemory(gpuQuantity.Value()), // Convert to bytes
			}
			total.GPUDevices = append(total.GPUDevices, gpuMetric)
		}
	}
	logrus.Debugf("Calculated total capacity: CPU=%d, Memory=%d, Storage=%d, EphemeralStorage=%d, Pods=%d, GPUs=%d",
		total.CPU, total.Memory, total.Storage, total.EphemeralStorage, total.Pods, len(total.GPUDevices))
	return total
}
func (cc *ClusterCollector) calculateTotalAllocatable(nodes []v1.Node) models.ResourceMetrics {
	total := models.ResourceMetrics{}
	for _, node := range nodes {
		total.CPU += node.Status.Allocatable.Cpu().MilliValue()
		total.Memory += node.Status.Allocatable.Memory().Value()
		total.Storage += node.Status.Allocatable.Storage().Value()
		if ephemeral, ok := node.Status.Allocatable[v1.ResourceEphemeralStorage]; ok {
			total.EphemeralStorage += ephemeral.Value()
		}
		total.Pods += node.Status.Allocatable.Pods().Value()
		// Collect GPU metrics if available
		if gpuQuantity, ok := node.Status.Allocatable["nvidia.com/gpu"]; ok {
			gpuMetric := models.GPUMetrics{
				DeviceID:    fmt.Sprintf("node-%s-gpu", node.Name),
				MemoryTotal: utils.SafeGPUMemory(gpuQuantity.Value()), // Convert to bytes
			}
			total.GPUDevices = append(total.GPUDevices, gpuMetric)
		}
	}
	logrus.Debugf("Calculated total allocatable: CPU=%d, Memory=%d, Storage=%d, EphemeralStorage=%d, Pods=%d, GPUs=%d",
		total.CPU, total.Memory, total.Storage, total.EphemeralStorage, total.Pods, len(total.GPUDevices))
	return total
}
func (cc *ClusterCollector) calculateTotalRequests(pods []v1.Pod) models.ResourceMetrics {
	total := models.ResourceMetrics{}
	for _, pod := range pods {
		for _, container := range pod.Spec.Containers {
			total.CPU += container.Resources.Requests.Cpu().MilliValue()
			total.Memory += container.Resources.Requests.Memory().Value()
			if ephemeral, ok := container.Resources.Requests[v1.ResourceEphemeralStorage]; ok {
				total.EphemeralStorage += ephemeral.Value()
			}
			// Sum GPU requests if available
			if gpuQuantity, ok := container.Resources.Requests["nvidia.com/gpu"]; ok {
				gpuMetric := models.GPUMetrics{
					DeviceID:    fmt.Sprintf("pod-%s-%s-gpu", pod.Namespace, pod.Name),
					MemoryTotal: utils.SafeGPUMemory(gpuQuantity.Value()), // Convert to bytes
				}
				total.GPUDevices = append(total.GPUDevices, gpuMetric)
			}
		}
	}
	total.Pods = int64(len(pods))
	logrus.Debugf("Calculated total requests: CPU=%d, Memory=%d, EphemeralStorage=%d, Pods=%d, GPUs=%d",
		total.CPU, total.Memory, total.EphemeralStorage, total.Pods, len(total.GPUDevices))
	return total
}
func (cc *ClusterCollector) calculateTotalLimits(pods []v1.Pod) models.ResourceMetrics {
	total := models.ResourceMetrics{}
	for _, pod := range pods {
		for _, container := range pod.Spec.Containers {
			total.CPU += container.Resources.Limits.Cpu().MilliValue()
			total.Memory += container.Resources.Limits.Memory().Value()
			if ephemeral, ok := container.Resources.Limits[v1.ResourceEphemeralStorage]; ok {
				total.EphemeralStorage += ephemeral.Value()
			}
			// Sum GPU limits if available
			if gpuQuantity, ok := container.Resources.Limits["nvidia.com/gpu"]; ok {
				gpuMetric := models.GPUMetrics{
					DeviceID:    fmt.Sprintf("pod-%s-%s-gpu", pod.Namespace, pod.Name),
					MemoryTotal: utils.SafeGPUMemory(gpuQuantity.Value()),
				}
				total.GPUDevices = append(total.GPUDevices, gpuMetric)
			}
		}
	}
	total.Pods = int64(len(pods))
	logrus.Debugf("Calculated total limits: CPU=%d, Memory=%d, EphemeralStorage=%d, Pods=%d, GPUs=%d",
		total.CPU, total.Memory, total.EphemeralStorage, total.Pods, len(total.GPUDevices))
	return total
}
func (cc *ClusterCollector) countContainers(pods []v1.Pod) int {
	count := 0
	for _, pod := range pods {
		count += len(pod.Spec.Containers)
		count += len(pod.Spec.InitContainers)
		count += len(pod.Spec.EphemeralContainers)
	}
	return count
}
</file>

<file path="pkg/collectors/collector.go">
// Copyright 2024 Vega Cloud, Inc.
//
// Use of this software is governed by the Business Source License
// included in the file licenses/BSL.txt.
//
// As of the Change Date specified in that file, in accordance with
// the Business Source License, use of this software will be governed
// by the Apache License, Version 2.0, included in the file
// licenses/APL.txt.
// File: pkg/collectors/collector.go
// Package collectors hosts the collection functions
package collectors
import (
	"bytes"
	"context"
	"fmt"
	dto "github.com/prometheus/client_model/go"
	"github.com/prometheus/common/expfmt"
	"github.com/sirupsen/logrus"
	"github.com/vegacloud/kubernetes/metricsagent/pkg/utils"
	"k8s.io/client-go/kubernetes"
)
// Collector defines the interface for all metric collectors
type Collector interface {
	// CollectMetrics collects metrics and returns them as an interface{},
	// which can be type-asserted to the specific metrics type for each collector
	CollectMetrics(ctx context.Context) (interface{}, error)
}
// FetchMetricsViaKubelet fetches and parses metrics from kubelet
func FetchMetricsViaKubelet(ctx context.Context, clientset *kubernetes.Clientset, nodeName, metricsPath string) (map[string]*dto.MetricFamily, error) {
	kubeletClient := clientset.CoreV1().RESTClient().Get().
		Resource("nodes").
		Name(nodeName).
		SubResource("proxy").
		Suffix(metricsPath)
	rawMetrics, err := kubeletClient.Do(ctx).Raw()
	if err != nil {
		return nil, fmt.Errorf("failed to fetch metrics: %w", err)
	}
	var parser expfmt.TextParser
	return parser.TextToMetricFamilies(bytes.NewReader(rawMetrics))
}
// FetchRawStatsViaKubelet fetches raw stats from kubelet
func FetchRawStatsViaKubelet(ctx context.Context, clientset *kubernetes.Clientset, nodeName, statsPath string) ([]byte, error) {
	kubeletClient := clientset.CoreV1().RESTClient().Get().
		Resource("nodes").
		Name(nodeName).
		SubResource("proxy").
		Suffix(statsPath)
	rawStats, err := kubeletClient.Do(ctx).Raw()
	if err != nil {
		return nil, fmt.Errorf("failed to fetch stats: %w", err)
	}
	return rawStats, nil
}
// FetchRawMetricsFromKubelet fetches raw metrics from kubelet
func FetchRawMetricsFromKubelet(ctx context.Context, clientset *kubernetes.Clientset, nodeName, metricsPath string) ([]byte, error) {
	kubeletClient := clientset.CoreV1().RESTClient().Get().
		Resource("nodes").
		Name(nodeName).
		SubResource("proxy").
		Suffix(metricsPath)
	return kubeletClient.Do(ctx).Raw()
}
// VerifyCollectorClient verifies that the collector is using the correct client
func VerifyCollectorClient(ctx context.Context, clientset *kubernetes.Clientset, namespace string, collectorName string) error {
	logger := logrus.WithField("collector", collectorName)
	if err := utils.VerifyClientIdentity(ctx, clientset, namespace); err != nil {
		logger.WithError(err).Error("Collector using incorrect client identity")
		return fmt.Errorf("%s collector: %w", collectorName, err)
	}
	logger.Debug("Verified collector client identity")
	return nil
}
</file>

<file path="pkg/collectors/cronJob.go">
// Copyright 2024 Vega Cloud, Inc.
//
// Use of this software is governed by the Business Source License
// included in the file licenses/BSL.txt.
//
// As of the Change Date specified in that file, in accordance with
// the Business Source License, use of this software will be governed
// by the Apache License, Version 2.0, included in the file
// licenses/APL.txt.
// Package collectors hosts the collection functions
package collectors
import (
	"context"
	"fmt"
	"time"
	"github.com/robfig/cron/v3"
	"github.com/sirupsen/logrus"
	batchv1 "k8s.io/api/batch/v1"
	v1 "k8s.io/api/core/v1"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/client-go/kubernetes"
	"github.com/vegacloud/kubernetes/metricsagent/pkg/config"
	"github.com/vegacloud/kubernetes/metricsagent/pkg/models"
	"github.com/vegacloud/kubernetes/metricsagent/pkg/utils"
)
// CronJobCollector collects metrics from Kubernetes cron jobs.
type CronJobCollector struct {
	clientset *kubernetes.Clientset
	config    *config.Config
	parser    cron.Parser
}
// NewCronJobCollector creates a new CronJobCollector.
func NewCronJobCollector(clientset *kubernetes.Clientset, cfg *config.Config) *CronJobCollector {
	logrus.Debug("CronJobCollector initialized successfully")
	return &CronJobCollector{
		clientset: clientset,
		config:    cfg,
		parser:    cron.NewParser(cron.Minute | cron.Hour | cron.Dom | cron.Month | cron.Dow | cron.Descriptor),
	}
}
// CollectMetrics collects metrics from Kubernetes cron jobs.
func (cjc *CronJobCollector) CollectMetrics(ctx context.Context) (interface{}, error) {
	cronJobs, err := cjc.clientset.BatchV1().CronJobs("").List(ctx, metav1.ListOptions{})
	if err != nil {
		return nil, fmt.Errorf("failed to list cron jobs: %w", err)
	}
	logrus.Debugf("Successfully listed %d cron jobs", len(cronJobs.Items))
	metrics := make([]models.CronJobMetrics, 0, len(cronJobs.Items))
	for _, cj := range cronJobs.Items {
		metric, err := cjc.parseCronJobMetrics(ctx, cj)
		if err != nil {
			logrus.Warnf("Failed to parse metrics for cronjob %s/%s: %v", cj.Namespace, cj.Name, err)
			continue
		}
		metrics = append(metrics, metric)
	}
	logrus.Debugf("Collected metrics for %d cron jobs", len(metrics))
	return metrics, nil
}
// parseCronJobMetrics parses metrics from a Kubernetes cron job.
func (cjc *CronJobCollector) parseCronJobMetrics(ctx context.Context, cj batchv1.CronJob) (models.CronJobMetrics, error) {
	metrics := models.CronJobMetrics{
		Name:      cj.Name,
		Namespace: cj.Namespace,
		Schedule:  cj.Spec.Schedule,
		Labels:    cj.Labels,
		Status: models.CronJobStatus{
			Active:             len(cj.Status.Active),
			LastScheduleTime:   cjc.convertTime(cj.Status.LastScheduleTime),
			LastSuccessfulTime: cjc.convertTime(cj.Status.LastSuccessfulTime),
		},
		Spec: models.CronJobSpec{
			Suspend:                    cjc.getBoolValue(cj.Spec.Suspend),
			Concurrency:                string(cj.Spec.ConcurrencyPolicy),
			StartingDeadlineSeconds:    cjc.getInt64Value(cj.Spec.StartingDeadlineSeconds),
			SuccessfulJobsHistoryLimit: cjc.getInt32Value(cj.Spec.SuccessfulJobsHistoryLimit),
			FailedJobsHistoryLimit:     cjc.getInt32Value(cj.Spec.FailedJobsHistoryLimit),
		},
	}
	// Calculate next scheduled time
	nextSchedule, err := cjc.calculateNextSchedule(cj)
	if err != nil {
		logrus.Warnf("Failed to calculate next schedule for cronjob %s/%s: %v", cj.Namespace, cj.Name, err)
	} else {
		metrics.Status.NextScheduledTime = nextSchedule
	}
	// Get associated jobs metrics
	jobs, err := cjc.getAssociatedJobsMetrics(ctx, cj)
	if err != nil {
		logrus.Warnf("Failed to get associated jobs for cronjob %s/%s: %v", cj.Namespace, cj.Name, err)
	} else {
		metrics.JobMetrics = jobs
		metrics.Status.SuccessRate = cjc.calculateSuccessRate(jobs)
	}
	return metrics, nil
}
// getAssociatedJobsMetrics collects metrics from jobs associated with the CronJob
func (cjc *CronJobCollector) getAssociatedJobsMetrics(ctx context.Context, cj batchv1.CronJob) ([]models.JobMetrics, error) {
	selector := metav1.ListOptions{
		LabelSelector: fmt.Sprintf("job-name=%s", cj.Name),
	}
	jobs, err := cjc.clientset.BatchV1().Jobs(cj.Namespace).List(ctx, selector)
	if err != nil {
		return nil, fmt.Errorf("failed to list jobs: %w", err)
	}
	metrics := make([]models.JobMetrics, 0, len(jobs.Items))
	for _, job := range jobs.Items {
		metrics = append(metrics, cjc.parseJobMetrics(job))
	}
	return metrics, nil
}
// parseJobMetrics parses metrics from a Kubernetes job
func (cjc *CronJobCollector) parseJobMetrics(job batchv1.Job) models.JobMetrics {
	metrics := models.JobMetrics{
		Name:           job.Name,
		Namespace:      job.Namespace,
		StartTime:      cjc.convertTime(job.Status.StartTime),
		CompletionTime: cjc.convertTime(job.Status.CompletionTime),
		Active:         job.Status.Active,
		Succeeded:      job.Status.Succeeded,
		Failed:         job.Status.Failed,
		Status:         cjc.getJobStatus(job.Status),
		Duration:       cjc.calculateJobDuration(job.Status),
		Labels:         job.Labels,
		Resources:      cjc.getJobResourceMetrics(job),
	}
	return metrics
}
// Helper functions
func (cjc *CronJobCollector) calculateNextSchedule(cj batchv1.CronJob) (*time.Time, error) {
	schedule, err := cjc.parser.Parse(cj.Spec.Schedule)
	if err != nil {
		return nil, fmt.Errorf("failed to parse schedule: %w", err)
	}
	var baseTime time.Time
	if cj.Status.LastScheduleTime != nil {
		baseTime = cj.Status.LastScheduleTime.Time
	} else {
		baseTime = time.Now()
	}
	next := schedule.Next(baseTime)
	return &next, nil
}
func (cjc *CronJobCollector) calculateSuccessRate(jobs []models.JobMetrics) float64 {
	if len(jobs) == 0 {
		return 0
	}
	completed := 0
	succeeded := 0
	for _, job := range jobs {
		if job.CompletionTime != nil {
			completed++
			if job.Succeeded > 0 {
				succeeded++
			}
		}
	}
	if completed == 0 {
		return 0
	}
	return float64(succeeded) / float64(completed) * 100
}
func (cjc *CronJobCollector) getJobResourceMetrics(job batchv1.Job) models.ResourceMetrics {
	resources := models.ResourceMetrics{}
	if job.Spec.Template.Spec.Containers == nil {
		return resources
	}
	for _, container := range job.Spec.Template.Spec.Containers {
		if container.Resources.Requests != nil {
			resources.CPU += container.Resources.Requests.Cpu().MilliValue()
			resources.Memory += container.Resources.Requests.Memory().Value()
			if storage, ok := container.Resources.Requests[v1.ResourceStorage]; ok {
				resources.Storage += storage.Value()
			}
			if ephemeral, ok := container.Resources.Requests[v1.ResourceEphemeralStorage]; ok {
				resources.EphemeralStorage += ephemeral.Value()
			}
		}
		if gpuQuantity, ok := container.Resources.Requests["nvidia.com/gpu"]; ok {
			gpuMetric := models.GPUMetrics{
				DeviceID:    fmt.Sprintf("job-%s-%s-gpu", job.Namespace, job.Name),
				MemoryTotal: utils.SafeGPUMemory(gpuQuantity.Value()),
				MemoryUsed:  0,
				OptMetrics: models.OptionalMetrics{
					DutyCycle:   0,
					Temperature: 0,
					PowerUsage:  0,
				},
			}
			resources.GPUDevices = append(resources.GPUDevices, gpuMetric)
		}
	}
	return resources
}
// Utility functions for handling nullable values
func (cjc *CronJobCollector) convertTime(t *metav1.Time) *time.Time {
	if t == nil {
		return nil
	}
	converted := t.Time
	return &converted
}
func (cjc *CronJobCollector) getBoolValue(b *bool) bool {
	if b == nil {
		return false
	}
	return *b
}
func (cjc *CronJobCollector) getInt64Value(i *int64) int64 {
	if i == nil {
		return 0
	}
	return *i
}
func (cjc *CronJobCollector) getInt32Value(i *int32) int32 {
	if i == nil {
		return 0
	}
	return *i
}
func (cjc *CronJobCollector) getJobStatus(status batchv1.JobStatus) string {
	switch {
	case status.Succeeded > 0:
		return "Succeeded"
	case status.Failed > 0:
		return "Failed"
	case status.Active > 0:
		return "Active"
	default:
		return "Pending"
	}
}
func (cjc *CronJobCollector) calculateJobDuration(status batchv1.JobStatus) *time.Duration {
	if status.StartTime == nil {
		return nil
	}
	endTime := time.Now()
	if status.CompletionTime != nil {
		endTime = status.CompletionTime.Time
	}
	duration := endTime.Sub(status.StartTime.Time)
	return &duration
}
</file>

<file path="pkg/collectors/daemonsets.go">
// Copyright 2024 Vega Cloud, Inc.
//
// Use of this software is governed by the Business Source License
// included in the file licenses/BSL.txt.
//
// As of the Change Date specified in that file, in accordance with
// the Business Source License, use of this software will be governed
// by the Apache License, Version 2.0, included in the file
// licenses/APL.txt.
// File: pkg/collectors/daemonsets.go
// Package collectors hosts the collection functions
package collectors
import (
	"context"
	"runtime/debug"
	"github.com/sirupsen/logrus"
	appsv1 "k8s.io/api/apps/v1"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/client-go/kubernetes"
	"github.com/vegacloud/kubernetes/metricsagent/pkg/config"
	"github.com/vegacloud/kubernetes/metricsagent/pkg/models"
)
// DaemonSetCollector collects metrics for daemon sets
type DaemonSetCollector struct {
	clientset *kubernetes.Clientset
	config    *config.Config
}
// NewDaemonSetCollector creates a new DaemonSetCollector instance
func NewDaemonSetCollector(clientset *kubernetes.Clientset, cfg *config.Config) *DaemonSetCollector {
	defer func() {
		if r := recover(); r != nil {
			logrus.WithFields(logrus.Fields{
				"panic":      r,
				"stacktrace": string(debug.Stack()),
			}).Error("Recovered from panic in NewDaemonSetCollector")
			return
		}
	}()
	logrus.Debug("Starting DaemonSetCollector")
	collector := &DaemonSetCollector{
		clientset: clientset,
		config:    cfg,
	}
	logrus.Debug("DaemonSetCollector created successfully")
	return collector
}
// CollectMetrics collects metrics for daemon sets
func (dc *DaemonSetCollector) CollectMetrics(ctx context.Context) (interface{}, error) {
	defer func() {
		if r := recover(); r != nil {
			logrus.WithFields(logrus.Fields{
				"panic":      r,
				"stacktrace": string(debug.Stack()),
			}).Error("Recovered from panic in DaemonSetCollector.CollectMetrics")
		}
	}()
	daemonsets, err := dc.clientset.AppsV1().DaemonSets("").List(ctx, metav1.ListOptions{})
	if err != nil {
		logrus.WithFields(logrus.Fields{
			"error": err,
		}).Error("Failed to list daemonsets")
		return []models.DaemonSetMetrics{}, nil
	}
	metrics := make([]models.DaemonSetMetrics, 0, len(daemonsets.Items))
	for _, ds := range daemonsets.Items {
		logrus.WithFields(logrus.Fields{
			"daemonset": ds.Name,
			"namespace": ds.Namespace,
		}).Debug("Processing daemonset")
		metric := dc.convertDaemonSetToMetrics(&ds)
		metrics = append(metrics, metric)
	}
	logrus.WithField("count", len(metrics)).Debug("Collected daemonset metrics")
	return metrics, nil
}
// convertDaemonSetToMetrics converts a Kubernetes DaemonSet to metrics
func (dc *DaemonSetCollector) convertDaemonSetToMetrics(ds *appsv1.DaemonSet) models.DaemonSetMetrics {
	defer func() {
		if r := recover(); r != nil {
			logrus.WithFields(logrus.Fields{
				"daemonset":  ds.Name,
				"namespace":  ds.Namespace,
				"panic":      r,
				"stacktrace": string(debug.Stack()),
			}).Error("Recovered from panic while converting daemonset to metrics")
		}
	}()
	if ds == nil {
		logrus.Error("Received nil daemonset")
		return models.DaemonSetMetrics{}
	}
	// Initialize empty maps if nil
	if ds.Labels == nil {
		ds.Labels = make(map[string]string)
	}
	if ds.Annotations == nil {
		ds.Annotations = make(map[string]string)
	}
	conditions := make([]models.DaemonSetCondition, 0, len(ds.Status.Conditions))
	for _, condition := range ds.Status.Conditions {
		if condition.LastTransitionTime.IsZero() {
			logrus.WithFields(logrus.Fields{
				"daemonset": ds.Name,
				"namespace": ds.Namespace,
				"condition": condition.Type,
			}).Debug("Skipping condition with zero transition time")
			continue
		}
		conditions = append(conditions, models.DaemonSetCondition{
			Type:               string(condition.Type),
			Status:             string(condition.Status),
			LastTransitionTime: &condition.LastTransitionTime.Time,
			Reason:             condition.Reason,
			Message:            condition.Message,
		})
	}
	metrics := models.DaemonSetMetrics{
		Name:                   ds.Name,
		Namespace:              ds.Namespace,
		DesiredNumberScheduled: ds.Status.DesiredNumberScheduled,
		CurrentNumberScheduled: ds.Status.CurrentNumberScheduled,
		NumberReady:            ds.Status.NumberReady,
		UpdatedNumberScheduled: ds.Status.UpdatedNumberScheduled,
		NumberAvailable:        ds.Status.NumberAvailable,
		NumberUnavailable:      ds.Status.NumberUnavailable,
		NumberMisscheduled:     ds.Status.NumberMisscheduled,
		Labels:                 ds.Labels,
		Annotations:            ds.Annotations,
		CreationTimestamp:      &ds.CreationTimestamp.Time,
		CollisionCount:         ds.Status.CollisionCount,
		Status: models.DaemonSetStatus{
			ObservedGeneration: ds.Status.ObservedGeneration,
		},
		Conditions: conditions,
	}
	logrus.WithFields(logrus.Fields{
		"daemonset": ds.Name,
		"namespace": ds.Namespace,
		"ready":     ds.Status.NumberReady,
		"desired":   ds.Status.DesiredNumberScheduled,
	}).Debug("Converted daemonset to metrics")
	return metrics
}
</file>

<file path="pkg/collectors/hpa.go">
// Copyright 2024 Vega Cloud, Inc.
//
// Use of this software is governed by the Business Source License
// included in the file licenses/BSL.txt.
//
// As of the Change Date specified in that file, in accordance with
// the Business Source License, use of this software will be governed
// by the Apache License, Version 2.0, included in the file
// licenses/APL.txt.
// File: pkg/collectors/hpa.go
// Package collectors hosts the collection functions
package collectors
import (
	"context"
	"runtime/debug"
	"time"
	"github.com/sirupsen/logrus"
	autoscalingv1 "k8s.io/api/autoscaling/v1"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/client-go/kubernetes"
	"github.com/vegacloud/kubernetes/metricsagent/pkg/config"
	"github.com/vegacloud/kubernetes/metricsagent/pkg/models"
)
// HPACollector collects metrics from Kubernetes horizontal pod autoscalers.
type HPACollector struct {
	clientset *kubernetes.Clientset
	config    *config.Config
}
// NewHPACollector creates a new HPACollector.
func NewHPACollector(clientset *kubernetes.Clientset, cfg *config.Config) *HPACollector {
	defer func() {
		if r := recover(); r != nil {
			logrus.WithFields(logrus.Fields{
				"panic":      r,
				"stacktrace": string(debug.Stack()),
			}).Error("Recovered from panic in NewHPACollector")
		}
	}()
	logrus.Debug("Starting HPACollector")
	collector := &HPACollector{
		clientset: clientset,
		config:    cfg,
	}
	logrus.Debug("HPACollector created successfully")
	return collector
}
// CollectMetrics collects metrics from Kubernetes horizontal pod autoscalers.
func (hc *HPACollector) CollectMetrics(ctx context.Context) (interface{}, error) {
	defer func() {
		if r := recover(); r != nil {
			logrus.WithFields(logrus.Fields{
				"panic":      r,
				"stacktrace": string(debug.Stack()),
			}).Error("Recovered from panic in HPACollector.CollectMetrics")
		}
	}()
	metrics, err := hc.CollectHPAMetrics(ctx)
	if err != nil {
		logrus.WithFields(logrus.Fields{
			"error": err,
		}).Error("Failed to collect HPA metrics")
		return []models.HPAMetrics{}, nil
	}
	logrus.WithField("count", len(metrics)).Debug("Successfully collected HPA metrics")
	return metrics, nil
}
// CollectHPAMetrics collects metrics from Kubernetes horizontal pod autoscalers.
func (hc *HPACollector) CollectHPAMetrics(ctx context.Context) ([]models.HPAMetrics, error) {
	defer func() {
		if r := recover(); r != nil {
			logrus.WithFields(logrus.Fields{
				"panic":      r,
				"stacktrace": string(debug.Stack()),
			}).Error("Recovered from panic in HPACollector.CollectHPAMetrics")
		}
	}()
	hpas, err := hc.clientset.AutoscalingV1().HorizontalPodAutoscalers("").List(ctx, metav1.ListOptions{})
	if err != nil {
		logrus.WithFields(logrus.Fields{
			"error": err,
		}).Error("Failed to list HPAs")
		return []models.HPAMetrics{}, nil
	}
	metrics := make([]models.HPAMetrics, 0, len(hpas.Items))
	for _, hpa := range hpas.Items {
		logrus.WithFields(logrus.Fields{
			"hpa":       hpa.Name,
			"namespace": hpa.Namespace,
		}).Debug("Processing HPA")
		metric := hc.parseHPAMetrics(hpa)
		metrics = append(metrics, metric)
	}
	logrus.WithField("count", len(metrics)).Debug("Collected metrics for HPAs")
	return metrics, nil
}
func (hc *HPACollector) parseHPAMetrics(hpa autoscalingv1.HorizontalPodAutoscaler) models.HPAMetrics {
	defer func() {
		if r := recover(); r != nil {
			logrus.WithFields(logrus.Fields{
				"hpa":        hpa.Name,
				"namespace":  hpa.Namespace,
				"panic":      r,
				"stacktrace": string(debug.Stack()),
			}).Error("Recovered from panic while parsing HPA metrics")
		}
	}()
	// Initialize empty maps if nil
	if hpa.Labels == nil {
		hpa.Labels = make(map[string]string)
	}
	if hpa.Annotations == nil {
		hpa.Annotations = make(map[string]string)
	}
	// Safely handle ScaleTargetRef
	scaleTargetRef := models.ScaleTargetRef{
		Kind:       hpa.Spec.ScaleTargetRef.Kind,
		Name:       hpa.Spec.ScaleTargetRef.Name,
		APIVersion: hpa.Spec.ScaleTargetRef.APIVersion,
	}
	// Safely handle LastScaleTime
	var lastScaleTime *time.Time
	if hpa.Status.LastScaleTime != nil {
		t := hpa.Status.LastScaleTime.Time
		lastScaleTime = &t
	}
	metrics := models.HPAMetrics{
		Name:                            hpa.Name,
		Namespace:                       hpa.Namespace,
		ScaleTargetRef:                  scaleTargetRef,
		MinReplicas:                     hpa.Spec.MinReplicas,
		MaxReplicas:                     hpa.Spec.MaxReplicas,
		CurrentReplicas:                 hpa.Status.CurrentReplicas,
		DesiredReplicas:                 hpa.Status.DesiredReplicas,
		CurrentCPUUtilizationPercentage: hpa.Status.CurrentCPUUtilizationPercentage,
		TargetCPUUtilizationPercentage:  hpa.Spec.TargetCPUUtilizationPercentage,
		LastScaleTime:                   lastScaleTime,
		ObservedGeneration:              hpa.Status.ObservedGeneration,
		Labels:                          hpa.Labels,
		Annotations:                     hpa.Annotations,
		Status: models.HPAStatus{
			CurrentReplicas:                 hpa.Status.CurrentReplicas,
			DesiredReplicas:                 hpa.Status.DesiredReplicas,
			CurrentCPUUtilizationPercentage: hpa.Status.CurrentCPUUtilizationPercentage,
			LastScaleTime:                   lastScaleTime,
		},
	}
	logrus.WithFields(logrus.Fields{
		"hpa":             hpa.Name,
		"namespace":       hpa.Namespace,
		"currentReplicas": hpa.Status.CurrentReplicas,
		"desiredReplicas": hpa.Status.DesiredReplicas,
		"targetCPU":       hpa.Spec.TargetCPUUtilizationPercentage,
		"currentCPU":      hpa.Status.CurrentCPUUtilizationPercentage,
	}).Debug("Parsed HPA metrics")
	return metrics
}
</file>

<file path="pkg/collectors/job.go">
// Copyright 2024 Vega Cloud, Inc.
//
// Use of this software is governed by the Business Source License
// included in the file licenses/BSL.txt.
//
// As of the Change Date specified in that file, in accordance with
// the Business Source License, use of this software will be governed
// by the Apache License, Version 2.0, included in the file
// licenses/APL.txt.
// File: pkg/collectors/job.go
// Package collectors hosts the collection functions
package collectors
import (
	"context"
	"runtime/debug"
	"time"
	"github.com/sirupsen/logrus"
	batchv1 "k8s.io/api/batch/v1"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/client-go/kubernetes"
	"github.com/vegacloud/kubernetes/metricsagent/pkg/config"
	"github.com/vegacloud/kubernetes/metricsagent/pkg/models"
)
// JobCollector collects metrics from Kubernetes jobs.
type JobCollector struct {
	clientset *kubernetes.Clientset
	config    *config.Config
}
// NewJobCollector creates a new JobCollector.
func NewJobCollector(clientset *kubernetes.Clientset, cfg *config.Config) *JobCollector {
	defer func() {
		if r := recover(); r != nil {
			logrus.WithFields(logrus.Fields{
				"panic":      r,
				"stacktrace": string(debug.Stack()),
			}).Error("Recovered from panic in NewJobCollector")
		}
	}()
	logrus.Debug("Starting JobCollector")
	collector := &JobCollector{
		clientset: clientset,
		config:    cfg,
	}
	logrus.Debug("JobCollector created successfully")
	return collector
}
// CollectMetrics collects metrics from Kubernetes jobs.
func (jc *JobCollector) CollectMetrics(ctx context.Context) (interface{}, error) {
	defer func() {
		if r := recover(); r != nil {
			logrus.WithFields(logrus.Fields{
				"panic":      r,
				"stacktrace": string(debug.Stack()),
			}).Error("Recovered from panic in JobCollector.CollectMetrics")
		}
	}()
	metrics, err := jc.CollectJobMetrics(ctx)
	if err != nil {
		logrus.WithFields(logrus.Fields{
			"error": err,
		}).Error("Failed to collect job metrics")
		return []models.JobMetrics{}, nil
	}
	logrus.WithField("count", len(metrics)).Debug("Successfully collected job metrics")
	return metrics, nil
}
// CollectJobMetrics collects metrics from Kubernetes jobs.
func (jc *JobCollector) CollectJobMetrics(ctx context.Context) ([]models.JobMetrics, error) {
	defer func() {
		if r := recover(); r != nil {
			logrus.WithFields(logrus.Fields{
				"panic":      r,
				"stacktrace": string(debug.Stack()),
			}).Error("Recovered from panic in JobCollector.CollectJobMetrics")
		}
	}()
	jobs, err := jc.clientset.BatchV1().Jobs("").List(ctx, metav1.ListOptions{})
	if err != nil {
		logrus.WithFields(logrus.Fields{
			"error": err,
		}).Error("Failed to list jobs")
		return []models.JobMetrics{}, nil
	}
	jobMetrics := make([]models.JobMetrics, 0, len(jobs.Items))
	for _, job := range jobs.Items {
		logrus.WithFields(logrus.Fields{
			"job":       job.Name,
			"namespace": job.Namespace,
		}).Debug("Processing job")
		if job.Labels == nil {
			job.Labels = make(map[string]string)
		}
		var duration *time.Duration
		if job.Status.CompletionTime != nil && job.Status.StartTime != nil {
			d := job.Status.CompletionTime.Sub(job.Status.StartTime.Time)
			duration = &d
		}
		status := calculateJobStatus(&job)
		metrics := models.JobMetrics{
			Name:            job.Name,
			Namespace:       job.Namespace,
			Labels:          job.Labels,
			Active:          job.Status.Active,
			Succeeded:       job.Status.Succeeded,
			Failed:          job.Status.Failed,
			Status:          status,
			StartTime:       timePtr(job.Status.StartTime),
			CompletionTime:  timePtr(job.Status.CompletionTime),
			Duration:        duration,
			Parallelism:     job.Spec.Parallelism,
			Completions:     job.Spec.Completions,
			BackoffLimit:    job.Spec.BackoffLimit,
			Suspended:       job.Spec.Suspend != nil && *job.Spec.Suspend,
			CreationTime:    &job.CreationTimestamp.Time,
			Conditions:      convertJobConditions(job.Status.Conditions),
			ResourceMetrics: jc.collectJobResourceMetrics(ctx, &job),
		}
		jobMetrics = append(jobMetrics, metrics)
		logrus.WithFields(logrus.Fields{
			"job":       job.Name,
			"namespace": job.Namespace,
			"status":    status,
			"active":    job.Status.Active,
			"succeeded": job.Status.Succeeded,
			"failed":    job.Status.Failed,
		}).Debug("Collected metrics for job")
	}
	return jobMetrics, nil
}
// Helper functions
func timePtr(t *metav1.Time) *time.Time {
	if t == nil {
		return nil
	}
	tt := t.Time
	return &tt
}
func calculateJobStatus(job *batchv1.Job) string {
	defer func() {
		if r := recover(); r != nil {
			logrus.WithFields(logrus.Fields{
				"job":        job.Name,
				"namespace":  job.Namespace,
				"panic":      r,
				"stacktrace": string(debug.Stack()),
			}).Error("Recovered from panic while calculating job status")
		}
	}()
	if job == nil {
		logrus.Error("Received nil job in calculateJobStatus")
		return "Unknown"
	}
	if job.Status.Succeeded > 0 {
		return "Completed"
	}
	if job.Status.Failed > 0 {
		return "Failed"
	}
	if job.Status.Active > 0 {
		return "Active"
	}
	if job.Spec.Suspend != nil && *job.Spec.Suspend {
		return "Suspended"
	}
	return "Pending"
}
func convertJobConditions(conditions []batchv1.JobCondition) []models.JobCondition {
	defer func() {
		if r := recover(); r != nil {
			logrus.WithFields(logrus.Fields{
				"panic":      r,
				"stacktrace": string(debug.Stack()),
			}).Error("Recovered from panic while converting job conditions")
		}
	}()
	result := make([]models.JobCondition, 0, len(conditions))
	for _, c := range conditions {
		condition := models.JobCondition{
			Type:               string(c.Type),
			Status:             string(c.Status),
			LastProbeTime:      timePtr(&c.LastProbeTime),
			LastTransitionTime: timePtr(&c.LastTransitionTime),
			Reason:             c.Reason,
			Message:            c.Message,
		}
		result = append(result, condition)
	}
	return result
}
func (jc *JobCollector) collectJobResourceMetrics(ctx context.Context, job *batchv1.Job) models.ResourceMetrics {
	defer func() {
		if r := recover(); r != nil {
			logrus.WithFields(logrus.Fields{
				"job":        job.Name,
				"namespace":  job.Namespace,
				"panic":      r,
				"stacktrace": string(debug.Stack()),
			}).Error("Recovered from panic while collecting job resource metrics")
		}
	}()
	if job == nil {
		logrus.Error("Received nil job in collectJobResourceMetrics")
		return models.ResourceMetrics{}
	}
	selector := metav1.LabelSelector{MatchLabels: job.Spec.Selector.MatchLabels}
	labelSelector, err := metav1.LabelSelectorAsSelector(&selector)
	if err != nil {
		logrus.WithFields(logrus.Fields{
			"job":       job.Name,
			"namespace": job.Namespace,
			"error":     err,
		}).Error("Failed to create selector for job")
		return models.ResourceMetrics{}
	}
	pods, err := jc.clientset.CoreV1().Pods(job.Namespace).List(ctx, metav1.ListOptions{
		LabelSelector: labelSelector.String(),
	})
	if err != nil {
		logrus.WithFields(logrus.Fields{
			"job":       job.Name,
			"namespace": job.Namespace,
			"error":     err,
		}).Error("Failed to list pods for job")
		return models.ResourceMetrics{}
	}
	metrics := models.ResourceMetrics{}
	for _, pod := range pods.Items {
		for _, container := range pod.Spec.Containers {
			metrics.CPU += container.Resources.Requests.Cpu().MilliValue()
			metrics.Memory += container.Resources.Requests.Memory().Value()
			if container.Resources.Requests.Storage() != nil {
				metrics.Storage += container.Resources.Requests.Storage().Value()
			}
		}
	}
	logrus.WithFields(logrus.Fields{
		"job":       job.Name,
		"namespace": job.Namespace,
		"cpu":       metrics.CPU,
		"memory":    metrics.Memory,
		"storage":   metrics.Storage,
	}).Debug("Collected resource metrics for job")
	return metrics
}
</file>

<file path="pkg/collectors/namespace.go">
// Copyright 2024 Vega Cloud, Inc.
//
// Use of this software is governed by the Business Source License
// included in the file licenses/BSL.txt.
//
// As of the Change Date specified in that file, in accordance with
// the Business Source License, use of this software will be governed
// by the Apache License, Version 2.0, included in the file
// licenses/APL.txt.
// File: pkg/collectors/namespace.go
// Package collectors hosts the collection functions
package collectors
import (
	"context"
	"runtime/debug"
	"strings"
	"github.com/sirupsen/logrus"
	v1 "k8s.io/api/core/v1"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/client-go/kubernetes"
	"github.com/vegacloud/kubernetes/metricsagent/pkg/config"
	"github.com/vegacloud/kubernetes/metricsagent/pkg/models"
)
// NamespaceCollector collects metrics from Kubernetes namespaces.
type NamespaceCollector struct {
	clientset *kubernetes.Clientset
	config    *config.Config
}
// NewNamespaceCollector creates a new NamespaceCollector.
func NewNamespaceCollector(clientset *kubernetes.Clientset, cfg *config.Config) *NamespaceCollector {
	defer func() {
		if r := recover(); r != nil {
			logrus.WithFields(logrus.Fields{
				"panic":      r,
				"stacktrace": string(debug.Stack()),
			}).Error("Recovered from panic in NewNamespaceCollector")
		}
	}()
	logrus.Debug("Creating new NamespaceCollector")
	return &NamespaceCollector{
		clientset: clientset,
		config:    cfg,
	}
}
// CollectMetrics collects metrics from Kubernetes namespaces.
func (nc *NamespaceCollector) CollectMetrics(ctx context.Context) (interface{}, error) {
	defer func() {
		if r := recover(); r != nil {
			logrus.WithFields(logrus.Fields{
				"panic":      r,
				"stacktrace": string(debug.Stack()),
			}).Error("Recovered from panic in NamespaceCollector.CollectMetrics")
		}
	}()
	logrus.Debug("Collecting namespace metrics")
	metrics, err := nc.CollectNamespaceMetrics(ctx)
	if err != nil {
		logrus.WithError(err).Error("Failed to collect namespace metrics")
		return []models.NamespaceMetrics{}, nil
	}
	return metrics, nil
}
// CollectNamespaceMetrics collects metrics from Kubernetes namespaces.
func (nc *NamespaceCollector) CollectNamespaceMetrics(ctx context.Context) ([]models.NamespaceMetrics, error) {
	defer func() {
		if r := recover(); r != nil {
			logrus.WithFields(logrus.Fields{
				"panic":      r,
				"stacktrace": string(debug.Stack()),
			}).Error("Recovered from panic in CollectNamespaceMetrics")
		}
	}()
	namespaces, err := nc.clientset.CoreV1().Namespaces().List(ctx, metav1.ListOptions{})
	if err != nil {
		logrus.WithError(err).Error("Failed to list namespaces")
		return []models.NamespaceMetrics{}, nil
	}
	namespaceMetrics := make([]models.NamespaceMetrics, 0, len(namespaces.Items))
	for _, ns := range namespaces.Items {
		logrus.WithField("namespace", ns.Name).Debug("Processing namespace")
		metrics, err := nc.collectSingleNamespaceMetrics(ctx, ns)
		if err != nil {
			logrus.WithFields(logrus.Fields{
				"namespace": ns.Name,
				"error":     err,
			}).Error("Failed to collect metrics for namespace")
			continue
		}
		namespaceMetrics = append(namespaceMetrics, metrics)
	}
	logrus.WithField("count", len(namespaceMetrics)).Debug("Completed namespace metrics collection")
	return namespaceMetrics, nil
}
// collectSingleNamespaceMetrics collects metrics from a single Kubernetes namespace.
func (nc *NamespaceCollector) collectSingleNamespaceMetrics(ctx context.Context, ns v1.Namespace) (models.NamespaceMetrics, error) {
	defer func() {
		if r := recover(); r != nil {
			logrus.WithFields(logrus.Fields{
				"namespace":  ns.Name,
				"panic":      r,
				"stacktrace": string(debug.Stack()),
			}).Error("Recovered from panic in collectSingleNamespaceMetrics")
		}
	}()
	if ns.Labels == nil {
		ns.Labels = make(map[string]string)
	}
	if ns.Annotations == nil {
		ns.Annotations = make(map[string]string)
	}
	metrics := models.NamespaceMetrics{
		Name:              ns.Name,
		Status:            string(ns.Status.Phase),
		Phase:             string(ns.Status.Phase),
		CreationTimestamp: ns.CreationTimestamp.Time,
		DeletionTimestamp: nil,
		Finalizers:        ns.Finalizers,
		Labels:            ns.Labels,
		Annotations:       ns.Annotations,
	}
	// Set deletion timestamp if exists
	if ns.DeletionTimestamp != nil {
		deletionTime := ns.DeletionTimestamp.Time
		metrics.DeletionTimestamp = &deletionTime
	}
	// Convert conditions safely
	metrics.Conditions = make([]models.NamespaceCondition, 0, len(ns.Status.Conditions))
	for _, condition := range ns.Status.Conditions {
		if condition.LastTransitionTime.IsZero() {
			logrus.WithFields(logrus.Fields{
				"namespace": ns.Name,
				"condition": condition.Type,
			}).Debug("Skipping condition with zero transition time")
			continue
		}
		metrics.Conditions = append(metrics.Conditions, models.NamespaceCondition{
			Type:               string(condition.Type),
			Status:             string(condition.Status),
			LastTransitionTime: &condition.LastTransitionTime.Time,
			Reason:             condition.Reason,
			Message:            condition.Message,
		})
	}
	// Collect ResourceQuotas with error handling
	quotas, err := nc.clientset.CoreV1().ResourceQuotas(ns.Name).List(ctx, metav1.ListOptions{})
	if err != nil {
		logrus.WithFields(logrus.Fields{
			"namespace": ns.Name,
			"error":     err,
		}).Error("Failed to list resource quotas")
	} else {
		for _, quota := range quotas.Items {
			metrics.ResourceQuotas = append(metrics.ResourceQuotas, nc.parseResourceQuota(quota))
		}
	}
	// Collect LimitRanges with error handling
	limitRanges, err := nc.clientset.CoreV1().LimitRanges(ns.Name).List(ctx, metav1.ListOptions{})
	if err != nil {
		logrus.WithFields(logrus.Fields{
			"namespace": ns.Name,
			"error":     err,
		}).Error("Failed to list limit ranges")
	} else {
		for _, lr := range limitRanges.Items {
			metrics.LimitRanges = append(metrics.LimitRanges, nc.parseLimitRange(lr))
		}
	}
	// Collect usage metrics with error handling
	usage, err := nc.collectNamespaceUsage(ctx, ns.Name)
	if err != nil {
		logrus.WithFields(logrus.Fields{
			"namespace": ns.Name,
			"error":     err,
		}).Error("Failed to collect usage metrics")
	} else {
		metrics.Usage = usage
	}
	logrus.WithFields(logrus.Fields{
		"namespace":       ns.Name,
		"quotasCount":     len(metrics.ResourceQuotas),
		"limitsCount":     len(metrics.LimitRanges),
		"conditionsCount": len(metrics.Conditions),
	}).Debug("Collected namespace metrics")
	return metrics, nil
}
// parseResourceQuota parses metrics from a Kubernetes resource quota.
func (nc *NamespaceCollector) parseResourceQuota(quota v1.ResourceQuota) models.ResourceQuotaMetrics {
	defer func() {
		if r := recover(); r != nil {
			logrus.WithFields(logrus.Fields{
				"quota":      quota.Name,
				"namespace":  quota.Namespace,
				"panic":      r,
				"stacktrace": string(debug.Stack()),
			}).Error("Recovered from panic in parseResourceQuota")
		}
	}()
	metrics := models.ResourceQuotaMetrics{
		Name: quota.Name,
	}
	// Parse basic resources
	for resourceName, hard := range quota.Status.Hard {
		used := quota.Status.Used[resourceName]
		metrics.Resources = append(metrics.Resources, models.ResourceMetric{
			ResourceName: string(resourceName),
			Hard:         hard.String(),
			Used:         used.String(),
		})
	}
	// Parse quota scopes
	if len(quota.Spec.Scopes) > 0 {
		for _, scope := range quota.Spec.Scopes {
			scopeMetric := models.QuotaScopeMetrics{
				ScopeName: string(scope),
			}
			if quota.Spec.ScopeSelector != nil && quota.Spec.ScopeSelector.MatchExpressions != nil {
				for _, expr := range quota.Spec.ScopeSelector.MatchExpressions {
					scopeMetric.MatchScopes = append(scopeMetric.MatchScopes, string(expr.Operator))
				}
			}
			metrics.Scopes = append(metrics.Scopes, scopeMetric)
		}
	}
	// Parse priority class quotas
	for resourceName, hard := range quota.Status.Hard {
		if isPriorityClassResource(string(resourceName)) {
			priorityClass := extractPriorityClass(string(resourceName))
			metrics.PriorityQuotas = append(metrics.PriorityQuotas, models.PriorityClassQuotaMetrics{
				PriorityClass: priorityClass,
				Hard:          map[string]string{string(resourceName): hard.ToUnstructured().(string)},
				Used:          map[string]string{string(resourceName): quota.Status.Used[resourceName].ToUnstructured().(string)},
			})
		}
	}
	return metrics
}
// Helper functions
func isPriorityClassResource(resource string) bool {
	return strings.HasPrefix(resource, "count/pods.") && strings.Contains(resource, "priorityclass")
}
func extractPriorityClass(resource string) string {
	parts := strings.Split(resource, ".")
	if len(parts) > 1 {
		return parts[len(parts)-1]
	}
	return ""
}
func (nc *NamespaceCollector) parseLimitRange(lr v1.LimitRange) models.LimitRangeMetrics {
	defer func() {
		if r := recover(); r != nil {
			logrus.WithFields(logrus.Fields{
				"limitRange": lr.Name,
				"namespace":  lr.Namespace,
				"panic":      r,
				"stacktrace": string(debug.Stack()),
			}).Error("Recovered from panic in parseLimitRange")
		}
	}()
	metrics := models.LimitRangeMetrics{
		Name: lr.Name,
	}
	for _, item := range lr.Spec.Limits {
		limit := models.LimitRangeItem{
			Type: string(item.Type),
		}
		if item.Max != nil {
			limit.Max = make(map[string]string)
			for k, v := range item.Max {
				limit.Max[string(k)] = v.String()
			}
		}
		if item.Min != nil {
			limit.Min = make(map[string]string)
			for k, v := range item.Min {
				limit.Min[string(k)] = v.String()
			}
		}
		if item.Default != nil {
			limit.Default = make(map[string]string)
			for k, v := range item.Default {
				limit.Default[string(k)] = v.String()
			}
		}
		if item.DefaultRequest != nil {
			limit.DefaultRequest = make(map[string]string)
			for k, v := range item.DefaultRequest {
				limit.DefaultRequest[string(k)] = v.String()
			}
		}
		metrics.Limits = append(metrics.Limits, limit)
	}
	logrus.Debugf("Parsed limit range %s", lr.Name)
	return metrics
}
func (nc *NamespaceCollector) collectNamespaceUsage(ctx context.Context, namespace string) (models.ResourceUsage, error) {
	defer func() {
		if r := recover(); r != nil {
			logrus.WithFields(logrus.Fields{
				"namespace":  namespace,
				"panic":      r,
				"stacktrace": string(debug.Stack()),
			}).Error("Recovered from panic in collectNamespaceUsage")
		}
	}()
	usage := models.ResourceUsage{}
	pods, err := nc.clientset.CoreV1().Pods(namespace).List(ctx, metav1.ListOptions{})
	if err != nil {
		logrus.WithFields(logrus.Fields{
			"namespace": namespace,
			"error":     err,
		}).Error("Failed to list pods")
		return usage, nil
	}
	for _, pod := range pods.Items {
		for _, container := range pod.Spec.Containers {
			usage.CPU += container.Resources.Requests.Cpu().MilliValue()
			usage.Memory += container.Resources.Requests.Memory().Value()
		}
	}
	pvcs, err := nc.clientset.CoreV1().PersistentVolumeClaims(namespace).List(ctx, metav1.ListOptions{})
	if err != nil {
		logrus.WithFields(logrus.Fields{
			"namespace": namespace,
			"error":     err,
		}).Error("Failed to list PVCs")
		return usage, nil
	}
	for _, pvc := range pvcs.Items {
		if pvc.Spec.Resources.Requests != nil {
			if storage, ok := pvc.Spec.Resources.Requests[v1.ResourceStorage]; ok {
				usage.Storage += storage.Value()
			}
		}
	}
	usage.Pods = int64(len(pods.Items))
	logrus.WithFields(logrus.Fields{
		"namespace": namespace,
		"cpu":       usage.CPU,
		"memory":    usage.Memory,
		"storage":   usage.Storage,
		"pods":      usage.Pods,
	}).Debug("Collected namespace usage metrics")
	return usage, nil
}
</file>

<file path="pkg/collectors/networking.go">
// Copyright 2024 Vega Cloud, Inc.
//
// Use of this software is governed by the Business Source License
// included in the file licenses/BSL.txt.
//
// As of the Change Date specified in that file, in accordance with
// the Business Source License, use of this software will be governed
// by the Apache License, Version 2.0, included in the file
// licenses/APL.txt.
// File: pkg/collectors/networking.go
// Package collectors hosts the collection functions
package collectors
import (
	"context"
	"fmt"
	"reflect"
	"runtime/debug"
	"github.com/sirupsen/logrus"
	corev1 "k8s.io/api/core/v1"
	networkingv1 "k8s.io/api/networking/v1"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/client-go/kubernetes"
	"github.com/vegacloud/kubernetes/metricsagent/pkg/config"
	"github.com/vegacloud/kubernetes/metricsagent/pkg/models"
	"github.com/vegacloud/kubernetes/metricsagent/pkg/utils"
)
// NetworkingCollector collects metrics from Kubernetes networking resources.
type NetworkingCollector struct {
	clientset *kubernetes.Clientset
	config    *config.Config
}
// NewNetworkingCollector creates a new NetworkingCollector.
func NewNetworkingCollector(clientset *kubernetes.Clientset, cfg *config.Config) *NetworkingCollector {
	defer func() {
		if r := recover(); r != nil {
			logrus.WithFields(logrus.Fields{
				"panic":      r,
				"stacktrace": string(debug.Stack()),
			}).Error("Recovered from panic in NewNetworkingCollector")
		}
	}()
	logrus.Debug("Starting NetworkingCollector")
	collector := &NetworkingCollector{
		clientset: clientset,
		config:    cfg,
	}
	logrus.Debug("NetworkingCollector created successfully")
	return collector
}
// CollectMetrics collects metrics from Kubernetes networking resources.
func (nc *NetworkingCollector) CollectMetrics(ctx context.Context) (interface{}, error) {
	defer func() {
		if r := recover(); r != nil {
			logrus.WithFields(logrus.Fields{
				"panic":      r,
				"stacktrace": string(debug.Stack()),
			}).Error("Recovered from panic in NetworkingCollector.CollectMetrics")
		}
	}()
	metrics, err := nc.CollectNetworkingMetrics(ctx)
	if err != nil {
		logrus.WithError(err).Error("Failed to collect networking metrics")
		return &models.NetworkingMetrics{}, nil
	}
	return metrics, nil
}
// CollectNetworkingMetrics collects metrics from Kubernetes networking resources.
func (nc *NetworkingCollector) CollectNetworkingMetrics(ctx context.Context) ([]models.NetworkingMetrics, error) {
	defer func() {
		if r := recover(); r != nil {
			logrus.WithFields(logrus.Fields{
				"panic":      r,
				"stacktrace": string(debug.Stack()),
			}).Error("Recovered from panic in CollectNetworkingMetrics")
		}
	}()
	metrics := make([]models.NetworkingMetrics, 0)
	networkMetrics := models.NetworkingMetrics{}
	services, err := nc.collectServiceMetrics(ctx)
	if err != nil {
		logrus.WithError(err).Error("Failed to collect service metrics")
	} else {
		networkMetrics.Services = services
	}
	ingresses, err := nc.collectIngressMetrics(ctx)
	if err != nil {
		logrus.WithError(err).Error("Failed to collect ingress metrics")
	} else {
		networkMetrics.Ingresses = ingresses
	}
	networkPolicies, err := nc.collectNetworkPolicyMetrics(ctx)
	if err != nil {
		logrus.WithError(err).Error("Failed to collect network policy metrics")
	} else {
		networkMetrics.NetworkPolicies = networkPolicies
	}
	metrics = append(metrics, networkMetrics)
	return metrics, nil
}
func (nc *NetworkingCollector) collectServiceMetrics(ctx context.Context) ([]models.ServiceMetrics, error) {
	defer func() {
		if r := recover(); r != nil {
			logrus.WithFields(logrus.Fields{
				"panic":      r,
				"stacktrace": string(debug.Stack()),
			}).Error("Recovered from panic in collectServiceMetrics")
		}
	}()
	services, err := nc.clientset.CoreV1().Services("").List(ctx, metav1.ListOptions{})
	if err != nil {
		logrus.WithError(err).Error("Failed to list services")
		return []models.ServiceMetrics{}, nil
	}
	metrics := make([]models.ServiceMetrics, 0, len(services.Items))
	for _, svc := range services.Items {
		logrus.WithFields(logrus.Fields{
			"service":   svc.Name,
			"namespace": svc.Namespace,
		}).Debug("Processing service")
		metrics = append(metrics, nc.parseServiceMetrics(svc))
	}
	logrus.WithField("count", len(metrics)).Debug("Collected service metrics")
	return metrics, nil
}
func (nc *NetworkingCollector) parseServiceMetrics(svc corev1.Service) models.ServiceMetrics {
	defer func() {
		if r := recover(); r != nil {
			logrus.WithFields(logrus.Fields{
				"service":    svc.Name,
				"namespace":  svc.Namespace,
				"panic":      r,
				"stacktrace": string(debug.Stack()),
			}).Error("Recovered from panic in parseServiceMetrics")
		}
	}()
	if svc.Labels == nil {
		svc.Labels = make(map[string]string)
	}
	if svc.Annotations == nil {
		svc.Annotations = make(map[string]string)
	}
	metrics := models.ServiceMetrics{
		Name:                  svc.Name,
		Namespace:             svc.Namespace,
		Type:                  string(svc.Spec.Type),
		ClusterIP:             svc.Spec.ClusterIP,
		ExternalIP:            svc.Spec.ExternalIPs,
		Labels:                svc.Labels,
		Annotations:           svc.Annotations,
		SessionAffinity:       string(svc.Spec.SessionAffinity),
		ExternalTrafficPolicy: string(svc.Spec.ExternalTrafficPolicy),
		HealthCheckNodePort:   svc.Spec.HealthCheckNodePort,
		IPFamilies:            make([]string, 0),
	}
	// Safely handle IPFamilyPolicy
	if svc.Spec.IPFamilyPolicy != nil {
		metrics.IPFamilyPolicy = string(*svc.Spec.IPFamilyPolicy)
	}
	// Safely handle IPFamilies
	for _, family := range svc.Spec.IPFamilies {
		metrics.IPFamilies = append(metrics.IPFamilies, string(family))
	}
	// Safely handle LoadBalancerIP
	if svc.Spec.LoadBalancerIP != "" {
		metrics.LoadBalancerIP = svc.Spec.LoadBalancerIP
	}
	// Parse status safely
	metrics.Status.LoadBalancer = models.LoadBalancerStatus{
		Ingress: make([]models.LoadBalancerIngress, len(svc.Status.LoadBalancer.Ingress)),
	}
	for i, ing := range svc.Status.LoadBalancer.Ingress {
		metrics.Status.LoadBalancer.Ingress[i] = models.LoadBalancerIngress{
			IP:       ing.IP,
			Hostname: ing.Hostname,
		}
	}
	// Parse conditions safely
	for _, cond := range svc.Status.Conditions {
		if cond.LastTransitionTime.IsZero() {
			logrus.WithFields(logrus.Fields{
				"service":   svc.Name,
				"namespace": svc.Namespace,
				"condition": cond.Type,
			}).Debug("Skipping condition with zero transition time")
			continue
		}
		metrics.Status.Conditions = append(metrics.Status.Conditions, models.ServiceCondition{
			Type:               string(cond.Type),
			Status:             string(cond.Status),
			LastTransitionTime: &cond.LastTransitionTime.Time,
			Reason:             cond.Reason,
			Message:            cond.Message,
		})
	}
	// Parse ports safely
	for _, port := range svc.Spec.Ports {
		metrics.Ports = append(metrics.Ports, models.ServicePort{
			Name:       port.Name,
			Protocol:   string(port.Protocol),
			Port:       port.Port,
			TargetPort: port.TargetPort.String(),
			NodePort:   port.NodePort,
		})
	}
	metrics.Selector = svc.Spec.Selector
	logrus.WithFields(logrus.Fields{
		"service":   svc.Name,
		"namespace": svc.Namespace,
		"type":      metrics.Type,
		"ports":     len(metrics.Ports),
	}).Debug("Parsed service metrics")
	return metrics
}
func (nc *NetworkingCollector) collectIngressMetrics(ctx context.Context) ([]models.IngressMetrics, error) {
	ingresses, err := nc.clientset.NetworkingV1().Ingresses("").List(ctx, metav1.ListOptions{})
	if err != nil {
		return nil, fmt.Errorf("failed to list ingresses: %w", err)
	}
	logrus.Debugf("Successfully listed %d ingresses", len(ingresses.Items))
	metrics := make([]models.IngressMetrics, 0, len(ingresses.Items))
	for _, ing := range ingresses.Items {
		metrics = append(metrics, nc.parseIngressMetrics(ing))
	}
	return metrics, nil
}
func (nc *NetworkingCollector) parseIngressMetrics(ing networkingv1.Ingress) models.IngressMetrics {
	metrics := models.IngressMetrics{
		Name:      ing.Name,
		Namespace: ing.Namespace,
		ClassName: func() string {
			if ing.Spec.IngressClassName != nil {
				return *ing.Spec.IngressClassName
			}
			return ""
		}(),
		Labels:            ing.Labels,
		Annotations:       ing.Annotations,
		CreationTimestamp: &ing.CreationTimestamp.Time,
	}
	// Parse status
	for _, ing := range ing.Status.LoadBalancer.Ingress {
		if ing.IP != "" {
			metrics.LoadBalancerIngress = append(metrics.LoadBalancerIngress, ing.IP)
		}
		if ing.Hostname != "" {
			metrics.LoadBalancerIngress = append(metrics.LoadBalancerIngress, ing.Hostname)
		}
	}
	for _, rule := range ing.Spec.Rules {
		ingressRule := models.IngressRule{
			Host: rule.Host,
		}
		if rule.HTTP != nil {
			for _, path := range rule.HTTP.Paths {
				ingressRule.Paths = append(ingressRule.Paths, models.IngressPath{
					Path:     path.Path,
					PathType: string(*path.PathType),
					Backend: models.IngressBackend{
						Service: models.IngressServiceBackend{
							Name: path.Backend.Service.Name,
							Port: path.Backend.Service.Port.Number,
						},
					},
				})
			}
		}
		metrics.Rules = append(metrics.Rules, ingressRule)
	}
	for _, tls := range ing.Spec.TLS {
		metrics.TLS = append(metrics.TLS, models.IngressTLS{
			Hosts:      tls.Hosts,
			SecretName: tls.SecretName,
		})
	}
	logrus.Debugf("Parsed ingress metrics for ingress %s/%s", ing.Namespace, ing.Name)
	return metrics
}
func (nc *NetworkingCollector) collectNetworkPolicyMetrics(ctx context.Context) ([]models.NetworkPolicyMetrics, error) {
	networkPolicies, err := nc.clientset.NetworkingV1().NetworkPolicies("").List(ctx, metav1.ListOptions{})
	if err != nil {
		return nil, fmt.Errorf("failed to list network policies: %w", err)
	}
	logrus.Debugf("Successfully listed %d network policies", len(networkPolicies.Items))
	metrics := make([]models.NetworkPolicyMetrics, 0, len(networkPolicies.Items))
	var parseErrors []error
	for _, policy := range networkPolicies.Items {
		metric, err := nc.parseNetworkPolicyMetrics(policy)
		if err != nil {
			logrus.WithFields(logrus.Fields{
				"policy":    policy.Name,
				"namespace": policy.Namespace,
				"error":     err,
			}).Warn("Failed to parse network policy metrics")
			parseErrors = append(parseErrors, err)
			continue
		}
		metrics = append(metrics, metric)
	}
	if len(parseErrors) > 0 {
		logrus.WithField("error_count", len(parseErrors)).Warn("Some network policies failed to parse")
	}
	return metrics, nil
}
func validatePolicy(policy networkingv1.NetworkPolicy) error {
	mustHave := []string{"Name", "Namespace", "Labels", "Annotations", "Spec"}
	val := reflect.ValueOf(policy)
	for _, field := range mustHave {
		if err := utils.HasField(val.Interface(), field); err != nil {
			return fmt.Errorf("missing required field: %s", field)
		}
	}
	return nil
}
func (nc *NetworkingCollector) parseNetworkPolicyMetrics(policy networkingv1.NetworkPolicy) (models.NetworkPolicyMetrics, error) {
	if err := validatePolicy(policy); err != nil {
		return models.NetworkPolicyMetrics{}, fmt.Errorf("invalid network policy: %w", err)
	}
	// Initialize metrics with required fields
	metrics := models.NetworkPolicyMetrics{
		Name:        policy.Name,
		Namespace:   policy.Namespace,
		Labels:      policy.Labels,
		Annotations: policy.Annotations,
	}
	// Handle PodSelector
	if err := utils.HasField(policy.Spec, "PodSelector"); err == nil {
		metrics.PodSelector = policy.Spec.PodSelector.MatchLabels
	}
	// Handle PolicyTypes
	if err := utils.HasField(policy.Spec, "PolicyTypes"); err == nil {
		for _, pType := range policy.Spec.PolicyTypes {
			metrics.PolicyTypes = append(metrics.PolicyTypes, string(pType))
		}
	}
	// Handle Ingress rules
	if err := utils.HasField(policy.Spec, "Ingress"); err == nil {
		for _, rule := range policy.Spec.Ingress {
			ingressRule := models.NetworkPolicyIngressRule{}
			// Parse ports
			for _, port := range rule.Ports {
				if port.Protocol == nil || port.Port == nil {
					continue
				}
				ingressRule.Ports = append(ingressRule.Ports, models.NetworkPolicyPort{
					Protocol: string(*port.Protocol),
					Port:     port.Port.IntVal,
				})
			}
			// Parse from rules
			for _, from := range rule.From {
				peer := parseNetworkPolicyPeer(from)
				ingressRule.From = append(ingressRule.From, peer)
			}
			metrics.Ingress = append(metrics.Ingress, ingressRule)
		}
	}
	// Handle Egress rules
	if err := utils.HasField(policy.Spec, "Egress"); err == nil {
		for _, rule := range policy.Spec.Egress {
			egressRule := models.NetworkPolicyEgressRule{}
			// Parse ports
			for _, port := range rule.Ports {
				if port.Protocol == nil || port.Port == nil {
					continue
				}
				egressRule.Ports = append(egressRule.Ports, models.NetworkPolicyPort{
					Protocol: string(*port.Protocol),
					Port:     port.Port.IntVal,
				})
			}
			// Parse to rules
			for _, to := range rule.To {
				peer := parseNetworkPolicyPeer(to)
				egressRule.To = append(egressRule.To, peer)
			}
			metrics.Egress = append(metrics.Egress, egressRule)
		}
	}
	return metrics, nil
}
// Helper function to parse network policy peer
func parseNetworkPolicyPeer(peer networkingv1.NetworkPolicyPeer) models.NetworkPolicyPeer {
	result := models.NetworkPolicyPeer{}
	if peer.PodSelector != nil {
		result.PodSelector = peer.PodSelector.MatchLabels
	}
	if peer.NamespaceSelector != nil {
		result.NamespaceSelector = peer.NamespaceSelector.MatchLabels
	}
	if peer.IPBlock != nil {
		result.IPBlock = &models.IPBlock{
			CIDR:   peer.IPBlock.CIDR,
			Except: peer.IPBlock.Except,
		}
	}
	return result
}
</file>

<file path="pkg/collectors/persistentvolume.go">
// Copyright 2024 Vega Cloud, Inc.
//
// Use of this software is governed by the Business Source License
// included in the file licenses/BSL.txt.
//
// As of the Change Date specified in that file, in accordance with
// the Business Source License, use of this software will be governed
// by the Apache License, Version 2.0, included in the file
// licenses/APL.txt.
// File: pkg/collectors/persistentvolume.go
// Package collectors hosts the collection functions
package collectors
import (
	"context"
	"fmt"
	"runtime/debug"
	v1 "k8s.io/api/core/v1"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/client-go/kubernetes"
	"github.com/sirupsen/logrus"
	"github.com/vegacloud/kubernetes/metricsagent/pkg/config"
	"github.com/vegacloud/kubernetes/metricsagent/pkg/models"
)
// PersistentVolumeCollector collects metrics from Kubernetes persistent volumes.
type PersistentVolumeCollector struct {
	clientset *kubernetes.Clientset
	config    *config.Config
}
// NewPersistentVolumeCollector creates a new PersistentVolumeCollector.
func NewPersistentVolumeCollector(clientset *kubernetes.Clientset, cfg *config.Config) *PersistentVolumeCollector {
	defer func() {
		if r := recover(); r != nil {
			logrus.WithFields(logrus.Fields{
				"panic":      r,
				"stacktrace": string(debug.Stack()),
			}).Error("Recovered from panic in NewPersistentVolumeCollector")
		}
	}()
	logrus.Debug("Creating new PersistentVolumeCollector")
	collector := &PersistentVolumeCollector{
		clientset: clientset,
		config:    cfg,
	}
	logrus.Debug("PersistentVolumeCollector created successfully")
	return collector
}
// CollectMetrics collects metrics from Kubernetes persistent volumes.
func (pvc *PersistentVolumeCollector) CollectMetrics(ctx context.Context) (interface{}, error) {
	defer func() {
		if r := recover(); r != nil {
			logrus.WithFields(logrus.Fields{
				"panic":      r,
				"stacktrace": string(debug.Stack()),
			}).Error("Recovered from panic in PersistentVolumeCollector.CollectMetrics")
		}
	}()
	pvs, err := pvc.clientset.CoreV1().PersistentVolumes().List(ctx, metav1.ListOptions{})
	if err != nil {
		logrus.WithError(err).Error("Failed to list persistent volumes")
		return []models.PVMetric{}, nil
	}
	logrus.WithField("count", len(pvs.Items)).Debug("Successfully listed persistent volumes")
	metrics := pvc.collectPVMetrics(pvs.Items)
	logrus.WithField("count", len(metrics)).Debug("Successfully collected persistent volume metrics")
	return metrics, nil
}
// collectPVMetrics collects metrics from Kubernetes persistent volumes.
func (pvc *PersistentVolumeCollector) collectPVMetrics(pvs []v1.PersistentVolume) []models.PVMetric {
	defer func() {
		if r := recover(); r != nil {
			logrus.WithFields(logrus.Fields{
				"panic":      r,
				"stacktrace": string(debug.Stack()),
			}).Error("Recovered from panic in collectPVMetrics")
		}
	}()
	pvMetrics := make([]models.PVMetric, 0, len(pvs))
	for _, pv := range pvs {
		logrus.WithFields(logrus.Fields{
			"pv": pv.Name,
		}).Debug("Processing persistent volume")
		if pv.Labels == nil {
			pv.Labels = make(map[string]string)
		}
		if pv.Annotations == nil {
			pv.Annotations = make(map[string]string)
		}
		// Safely collect access modes
		accessModes := make([]string, 0)
		for _, mode := range pv.Spec.AccessModes {
			accessModes = append(accessModes, string(mode))
		}
		// Safely handle volume mode
		var volumeMode string
		if pv.Spec.VolumeMode != nil {
			volumeMode = string(*pv.Spec.VolumeMode)
		}
		metric := models.PVMetric{
			Name:          pv.Name,
			Capacity:      pv.Spec.Capacity.Storage().Value(),
			Phase:         string(pv.Status.Phase),
			StorageClass:  pv.Spec.StorageClassName,
			Labels:        pv.Labels,
			AccessModes:   accessModes,
			ReclaimPolicy: string(pv.Spec.PersistentVolumeReclaimPolicy),
			VolumeMode:    volumeMode,
			Status: models.PVStatus{
				Phase:   string(pv.Status.Phase),
				Message: pv.Status.Message,
				Reason:  pv.Status.Reason,
			},
			MountOptions: pv.Spec.MountOptions,
		}
		// Safely get storage class details
		if pv.Spec.StorageClassName != "" {
			sc, err := pvc.clientset.StorageV1().StorageClasses().Get(
				context.Background(),
				pv.Spec.StorageClassName,
				metav1.GetOptions{},
			)
			if err != nil {
				logrus.WithFields(logrus.Fields{
					"pv":           pv.Name,
					"storageClass": pv.Spec.StorageClassName,
					"error":        err,
				}).Error("Failed to get storage class details")
			} else if sc.VolumeBindingMode != nil {
				metric.VolumeBindingMode = string(*sc.VolumeBindingMode)
			}
		}
		// Safely handle claim reference
		if pv.Spec.ClaimRef != nil {
			metric.BoundPVC = fmt.Sprintf("%s/%s", pv.Spec.ClaimRef.Namespace, pv.Spec.ClaimRef.Name)
		}
		// Safely handle annotations
		if ann := pv.Annotations; ann != nil {
			if provisioner, ok := ann["pv.kubernetes.io/provisioned-by"]; ok {
				metric.StorageProvisioner = provisioner
			}
		}
		logrus.WithFields(logrus.Fields{
			"pv":           pv.Name,
			"phase":        metric.Phase,
			"capacity":     metric.Capacity,
			"storageClass": metric.StorageClass,
			"boundPVC":     metric.BoundPVC,
		}).Debug("Collected metrics for persistent volume")
		pvMetrics = append(pvMetrics, metric)
	}
	return pvMetrics
}
</file>

<file path="pkg/collectors/persistentvolumeclaim.go">
// Copyright 2024 Vega Cloud, Inc.
//
// Use of this software is governed by the Business Source License
// included in the file licenses/BSL.txt.
//
// As of the Change Date specified in that file, in accordance with
// the Business Source License, use of this software will be governed
// by the Apache License, Version 2.0, included in the file
// licenses/APL.txt.
// Package collectors hosts the collection functions
package collectors
import (
	"context"
	"runtime/debug"
	"github.com/sirupsen/logrus"
	v1 "k8s.io/api/core/v1"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/client-go/kubernetes"
	"github.com/vegacloud/kubernetes/metricsagent/pkg/config"
	"github.com/vegacloud/kubernetes/metricsagent/pkg/models"
)
// PersistentVolumeClaimCollector collects metrics from Kubernetes persistent volume claims.
type PersistentVolumeClaimCollector struct {
	clientset *kubernetes.Clientset
	config    *config.Config
}
// NewPersistentVolumeClaimCollector creates a new PersistentVolumeClaimCollector.
func NewPersistentVolumeClaimCollector(clientset *kubernetes.Clientset, cfg *config.Config) *PersistentVolumeClaimCollector {
	defer func() {
		if r := recover(); r != nil {
			logrus.WithFields(logrus.Fields{
				"panic":      r,
				"stacktrace": string(debug.Stack()),
			}).Error("Recovered from panic in NewPersistentVolumeClaimCollector")
		}
	}()
	logrus.Debug("Creating new PersistentVolumeClaimCollector")
	collector := &PersistentVolumeClaimCollector{
		clientset: clientset,
		config:    cfg,
	}
	logrus.Debug("PersistentVolumeClaimCollector created successfully")
	return collector
}
// CollectMetrics collects metrics from Kubernetes persistent volume claims.
func (pvcc *PersistentVolumeClaimCollector) CollectMetrics(ctx context.Context) (interface{}, error) {
	defer func() {
		if r := recover(); r != nil {
			logrus.WithFields(logrus.Fields{
				"panic":      r,
				"stacktrace": string(debug.Stack()),
			}).Error("Recovered from panic in PersistentVolumeClaimCollector.CollectMetrics")
		}
	}()
	pvcs, err := pvcc.clientset.CoreV1().PersistentVolumeClaims("").List(ctx, metav1.ListOptions{})
	if err != nil {
		logrus.WithError(err).Error("Failed to list persistent volume claims")
		return []models.PVCMetric{}, nil
	}
	logrus.WithField("count", len(pvcs.Items)).Debug("Successfully listed persistent volume claims")
	metrics := pvcc.collectPVCMetrics(pvcs.Items)
	logrus.WithField("count", len(metrics)).Debug("Successfully collected PVC metrics")
	return metrics, nil
}
// collectPVCMetrics collects metrics from Kubernetes persistent volume claims.
func (pvcc *PersistentVolumeClaimCollector) collectPVCMetrics(pvcs []v1.PersistentVolumeClaim) []models.PVCMetric {
	defer func() {
		if r := recover(); r != nil {
			logrus.WithFields(logrus.Fields{
				"panic":      r,
				"stacktrace": string(debug.Stack()),
			}).Error("Recovered from panic in collectPVCMetrics")
		}
	}()
	pvcMetrics := make([]models.PVCMetric, 0, len(pvcs))
	for _, claim := range pvcs {
		logrus.WithFields(logrus.Fields{
			"pvc":       claim.Name,
			"namespace": claim.Namespace,
		}).Debug("Processing persistent volume claim")
		if claim.Labels == nil {
			claim.Labels = make(map[string]string)
		}
		if claim.Annotations == nil {
			claim.Annotations = make(map[string]string)
		}
		// Safely collect access modes
		accessModes := make([]string, 0)
		for _, mode := range claim.Spec.AccessModes {
			accessModes = append(accessModes, string(mode))
		}
		// Safely collect conditions
		conditions := make([]models.PVCCondition, 0)
		for _, cond := range claim.Status.Conditions {
			if cond.LastTransitionTime.IsZero() {
				logrus.WithFields(logrus.Fields{
					"pvc":       claim.Name,
					"namespace": claim.Namespace,
					"condition": cond.Type,
				}).Debug("Skipping condition with zero transition time")
				continue
			}
			conditions = append(conditions, models.PVCCondition{
				Type:               string(cond.Type),
				Status:             string(cond.Status),
				LastTransitionTime: &cond.LastTransitionTime.Time,
				Reason:             cond.Reason,
				Message:            cond.Message,
			})
		}
		// Safely handle volume mode
		var volumeMode string
		if claim.Spec.VolumeMode != nil {
			volumeMode = string(*claim.Spec.VolumeMode)
		}
		metric := models.PVCMetric{
			Name:             claim.Name,
			Namespace:        claim.Namespace,
			Phase:            string(claim.Status.Phase),
			Capacity:         claim.Status.Capacity.Storage().Value(),
			RequestedStorage: claim.Spec.Resources.Requests.Storage().Value(),
			Labels:           claim.Labels,
			AccessModes:      accessModes,
			VolumeMode:       volumeMode,
			VolumeName:       claim.Spec.VolumeName,
			Status: models.PVCStatus{
				Phase:      string(claim.Status.Phase),
				Conditions: conditions,
			},
		}
		// Safely handle storage class
		if claim.Spec.StorageClassName != nil {
			metric.StorageClass = *claim.Spec.StorageClassName
			sc, err := pvcc.clientset.StorageV1().StorageClasses().Get(
				context.Background(),
				*claim.Spec.StorageClassName,
				metav1.GetOptions{},
			)
			if err != nil {
				logrus.WithFields(logrus.Fields{
					"pvc":          claim.Name,
					"namespace":    claim.Namespace,
					"storageClass": *claim.Spec.StorageClassName,
					"error":        err,
				}).Error("Failed to get storage class details")
			} else if sc.VolumeBindingMode != nil {
				metric.VolumeBindingMode = string(*sc.VolumeBindingMode)
			}
		}
		// Safely handle bound PV
		if claim.Spec.VolumeName != "" {
			metric.BoundPV = claim.Spec.VolumeName
			boundPV, err := pvcc.clientset.CoreV1().PersistentVolumes().Get(
				context.Background(),
				claim.Spec.VolumeName,
				metav1.GetOptions{},
			)
			if err != nil {
				logrus.WithFields(logrus.Fields{
					"pvc":       claim.Name,
					"namespace": claim.Namespace,
					"boundPV":   claim.Spec.VolumeName,
					"error":     err,
				}).Error("Failed to get bound PV details")
			} else {
				metric.MountOptions = boundPV.Spec.MountOptions
			}
		}
		// Safely handle annotations
		if ann := claim.Annotations; ann != nil {
			if provisioner, ok := ann["volume.kubernetes.io/storage-provisioner"]; ok {
				metric.StorageProvisioner = provisioner
			}
		}
		// Handle volume expansion metrics
		if claim.Spec.Resources.Requests.Storage() != nil {
			expansion := &models.VolumeExpansionMetrics{
				CurrentSize:   claim.Status.Capacity.Storage().Value(),
				RequestedSize: claim.Spec.Resources.Requests.Storage().Value(),
				InProgress:    false,
			}
			for _, condition := range claim.Status.Conditions {
				if condition.Type == v1.PersistentVolumeClaimResizing {
					expansion.InProgress = true
					expansion.LastResizeTime = &condition.LastTransitionTime.Time
					expansion.ResizeStatus = string(condition.Status)
					expansion.FailureMessage = condition.Message
					break
				}
			}
			metric.Expansion = expansion
		}
		logrus.WithFields(logrus.Fields{
			"pvc":              claim.Name,
			"namespace":        claim.Namespace,
			"phase":            metric.Phase,
			"capacity":         metric.Capacity,
			"requestedStorage": metric.RequestedStorage,
			"storageClass":     metric.StorageClass,
			"boundPV":          metric.BoundPV,
		}).Debug("Collected metrics for persistent volume claim")
		pvcMetrics = append(pvcMetrics, metric)
	}
	return pvcMetrics
}
</file>

<file path="pkg/collectors/replicaset.go">
// Copyright 2024 Vega Cloud, Inc.
//
// Use of this software is governed by the Business Source License
// included in the file licenses/BSL.txt.
//
// As of the Change Date specified in that file, in accordance with
// the Business Source License, use of this software will be governed
// by the Apache License, Version 2.0, included in the file
// licenses/APL.txt.
// Package collectors hosts the collection functions
package collectors
import (
	"context"
	"runtime/debug"
	"github.com/sirupsen/logrus"
	appsv1 "k8s.io/api/apps/v1"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/client-go/kubernetes"
	"github.com/vegacloud/kubernetes/metricsagent/pkg/config"
	"github.com/vegacloud/kubernetes/metricsagent/pkg/models"
)
// ReplicaSetCollector collects metrics for ReplicaSets
type ReplicaSetCollector struct {
	clientset *kubernetes.Clientset
	config    *config.Config
}
// NewReplicaSetCollector creates a new ReplicaSetCollector instance
func NewReplicaSetCollector(clientset *kubernetes.Clientset, cfg *config.Config) *ReplicaSetCollector {
	defer func() {
		if r := recover(); r != nil {
			logrus.WithFields(logrus.Fields{
				"panic":      r,
				"stacktrace": string(debug.Stack()),
			}).Error("Recovered from panic in NewReplicaSetCollector")
		}
	}()
	logrus.Debug("Creating new ReplicaSetCollector")
	collector := &ReplicaSetCollector{
		clientset: clientset,
		config:    cfg,
	}
	logrus.Debug("ReplicaSetCollector created successfully")
	return collector
}
// CollectMetrics collects metrics for all ReplicaSets in the cluster
func (rsc *ReplicaSetCollector) CollectMetrics(ctx context.Context) (interface{}, error) {
	defer func() {
		if r := recover(); r != nil {
			logrus.WithFields(logrus.Fields{
				"panic":      r,
				"stacktrace": string(debug.Stack()),
			}).Error("Recovered from panic in ReplicaSetCollector.CollectMetrics")
		}
	}()
	metrics, err := rsc.CollectReplicaSetMetrics(ctx)
	if err != nil {
		logrus.WithError(err).Error("Failed to collect replicaset metrics")
		return []models.ReplicaSetMetrics{}, nil
	}
	logrus.WithField("count", len(metrics)).Debug("Successfully collected replicaset metrics")
	return metrics, nil
}
// CollectReplicaSetMetrics collects metrics for all ReplicaSets in the cluster
func (rsc *ReplicaSetCollector) CollectReplicaSetMetrics(ctx context.Context) ([]models.ReplicaSetMetrics, error) {
	defer func() {
		if r := recover(); r != nil {
			logrus.WithFields(logrus.Fields{
				"panic":      r,
				"stacktrace": string(debug.Stack()),
			}).Error("Recovered from panic in CollectReplicaSetMetrics")
		}
	}()
	replicaSets, err := rsc.clientset.AppsV1().ReplicaSets("").List(ctx, metav1.ListOptions{})
	if err != nil {
		logrus.WithError(err).Error("Failed to list ReplicaSets")
		return []models.ReplicaSetMetrics{}, nil
	}
	logrus.WithField("count", len(replicaSets.Items)).Debug("Successfully listed ReplicaSets")
	metrics := make([]models.ReplicaSetMetrics, 0, len(replicaSets.Items))
	for _, rs := range replicaSets.Items {
		logrus.WithFields(logrus.Fields{
			"replicaset": rs.Name,
			"namespace":  rs.Namespace,
		}).Debug("Processing ReplicaSet")
		metrics = append(metrics, rsc.parseReplicaSetMetrics(rs))
	}
	return metrics, nil
}
// parseReplicaSetMetrics parses metrics for a single ReplicaSet
func (rsc *ReplicaSetCollector) parseReplicaSetMetrics(rs appsv1.ReplicaSet) models.ReplicaSetMetrics {
	defer func() {
		if r := recover(); r != nil {
			logrus.WithFields(logrus.Fields{
				"replicaset": rs.Name,
				"namespace":  rs.Namespace,
				"panic":      r,
				"stacktrace": string(debug.Stack()),
			}).Error("Recovered from panic in parseReplicaSetMetrics")
		}
	}()
	if rs.Labels == nil {
		rs.Labels = make(map[string]string)
	}
	if rs.Annotations == nil {
		rs.Annotations = make(map[string]string)
	}
	conditions := make([]models.RSCondition, 0, len(rs.Status.Conditions))
	for _, condition := range rs.Status.Conditions {
		if condition.LastTransitionTime.IsZero() {
			logrus.WithFields(logrus.Fields{
				"replicaset": rs.Name,
				"namespace":  rs.Namespace,
				"condition":  condition.Type,
			}).Debug("Skipping condition with zero transition time")
			continue
		}
		conditions = append(conditions, models.RSCondition{
			Type:               string(condition.Type),
			Status:             string(condition.Status),
			LastTransitionTime: &condition.LastTransitionTime.Time,
			Reason:             condition.Reason,
			Message:            condition.Message,
		})
	}
	metrics := models.ReplicaSetMetrics{
		Name:                 rs.Name,
		Namespace:            rs.Namespace,
		Replicas:             *rs.Spec.Replicas,
		ReadyReplicas:        rs.Status.ReadyReplicas,
		AvailableReplicas:    rs.Status.AvailableReplicas,
		CurrentReplicas:      rs.Status.Replicas,
		FullyLabeledReplicas: rs.Status.FullyLabeledReplicas,
		ObservedGeneration:   rs.Status.ObservedGeneration,
		Conditions:           conditions,
		Labels:               rs.Labels,
		Annotations:          rs.Annotations,
		CreationTimestamp:    &rs.CreationTimestamp.Time,
	}
	logrus.WithFields(logrus.Fields{
		"replicaset": rs.Name,
		"namespace":  rs.Namespace,
		"replicas":   metrics.Replicas,
		"ready":      metrics.ReadyReplicas,
		"available":  metrics.AvailableReplicas,
		"conditions": len(metrics.Conditions),
	}).Debug("Collected metrics for ReplicaSet")
	return metrics
}
</file>

<file path="pkg/collectors/replicationController..go">
// Copyright 2024 Vega Cloud, Inc.
//
// Use of this software is governed by the Business Source License
// included in the file licenses/BSL.txt.
//
// As of the Change Date specified in that file, in accordance with
// the Business Source License, use of this software will be governed
// by the Apache License, Version 2.0, included in the file
// licenses/APL.txt.
// Package collectors hosts the collection functions
package collectors
import (
	"context"
	"runtime/debug"
	"github.com/sirupsen/logrus"
	v1 "k8s.io/api/core/v1"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/client-go/kubernetes"
	"github.com/vegacloud/kubernetes/metricsagent/pkg/config"
	"github.com/vegacloud/kubernetes/metricsagent/pkg/models"
)
// ReplicationControllerCollector collects metrics from Kubernetes replication controllers.
type ReplicationControllerCollector struct {
	clientset *kubernetes.Clientset
	config    *config.Config
}
// NewReplicationControllerCollector creates a new ReplicationControllerCollector.
func NewReplicationControllerCollector(clientset *kubernetes.Clientset,
	cfg *config.Config) *ReplicationControllerCollector {
	defer func() {
		if r := recover(); r != nil {
			logrus.WithFields(logrus.Fields{
				"panic":      r,
				"stacktrace": string(debug.Stack()),
			}).Error("Recovered from panic in NewReplicationControllerCollector")
		}
	}()
	logrus.Debug("Creating new ReplicationControllerCollector")
	collector := &ReplicationControllerCollector{
		clientset: clientset,
		config:    cfg,
	}
	logrus.Debug("ReplicationControllerCollector created successfully")
	return collector
}
// CollectMetrics collects metrics from Kubernetes replication controllers.
func (rcc *ReplicationControllerCollector) CollectMetrics(ctx context.Context) (interface{}, error) {
	defer func() {
		if r := recover(); r != nil {
			logrus.WithFields(logrus.Fields{
				"panic":      r,
				"stacktrace": string(debug.Stack()),
			}).Error("Recovered from panic in ReplicationControllerCollector.CollectMetrics")
		}
	}()
	metrics, err := rcc.CollectReplicationControllerMetrics(ctx)
	if err != nil {
		logrus.WithError(err).Error("Failed to collect replication controller metrics")
		return []models.ReplicationControllerMetrics{}, nil
	}
	logrus.WithField("count", len(metrics)).Debug("Successfully collected replication controller metrics")
	return metrics, nil
}
// CollectReplicationControllerMetrics collects metrics from Kubernetes replication controllers.
func (rcc *ReplicationControllerCollector) CollectReplicationControllerMetrics(
	ctx context.Context) ([]models.ReplicationControllerMetrics, error) {
	defer func() {
		if r := recover(); r != nil {
			logrus.WithFields(logrus.Fields{
				"panic":      r,
				"stacktrace": string(debug.Stack()),
			}).Error("Recovered from panic in CollectReplicationControllerMetrics")
		}
	}()
	rcs, err := rcc.clientset.CoreV1().ReplicationControllers("").List(ctx, metav1.ListOptions{})
	if err != nil {
		logrus.WithError(err).Error("Failed to list replication controllers")
		return []models.ReplicationControllerMetrics{}, nil
	}
	logrus.WithField("count", len(rcs.Items)).Debug("Successfully listed replication controllers")
	metrics := make([]models.ReplicationControllerMetrics, 0, len(rcs.Items))
	for _, rc := range rcs.Items {
		logrus.WithFields(logrus.Fields{
			"rc":        rc.Name,
			"namespace": rc.Namespace,
		}).Debug("Processing replication controller")
		metrics = append(metrics, rcc.parseReplicationControllerMetrics(rc))
	}
	return metrics, nil
}
func (rcc *ReplicationControllerCollector) parseReplicationControllerMetrics(
	rc v1.ReplicationController) models.ReplicationControllerMetrics {
	defer func() {
		if r := recover(); r != nil {
			logrus.WithFields(logrus.Fields{
				"rc":         rc.Name,
				"namespace":  rc.Namespace,
				"panic":      r,
				"stacktrace": string(debug.Stack()),
			}).Error("Recovered from panic in parseReplicationControllerMetrics")
		}
	}()
	if rc.Labels == nil {
		rc.Labels = make(map[string]string)
	}
	if rc.Annotations == nil {
		rc.Annotations = make(map[string]string)
	}
	conditions := make([]models.RCCondition, 0, len(rc.Status.Conditions))
	for _, condition := range rc.Status.Conditions {
		if condition.LastTransitionTime.IsZero() {
			logrus.WithFields(logrus.Fields{
				"rc":        rc.Name,
				"namespace": rc.Namespace,
				"condition": condition.Type,
			}).Debug("Skipping condition with zero transition time")
			continue
		}
		conditions = append(conditions, models.RCCondition{
			Type:               string(condition.Type),
			Status:             string(condition.Status),
			LastTransitionTime: &condition.LastTransitionTime.Time,
			Reason:             condition.Reason,
			Message:            condition.Message,
		})
	}
	metrics := models.ReplicationControllerMetrics{
		Name:                 rc.Name,
		Namespace:            rc.Namespace,
		Replicas:             rc.Status.Replicas,
		ReadyReplicas:        rc.Status.ReadyReplicas,
		AvailableReplicas:    rc.Status.AvailableReplicas,
		Labels:               rc.Labels,
		ObservedGeneration:   rc.Status.ObservedGeneration,
		FullyLabeledReplicas: rc.Status.FullyLabeledReplicas,
		Conditions:           conditions,
		Annotations:          rc.Annotations,
		CreationTimestamp:    &rc.CreationTimestamp.Time,
	}
	logrus.WithFields(logrus.Fields{
		"rc":         rc.Name,
		"namespace":  rc.Namespace,
		"replicas":   metrics.Replicas,
		"ready":      metrics.ReadyReplicas,
		"available":  metrics.AvailableReplicas,
		"conditions": len(metrics.Conditions),
	}).Debug("Collected metrics for replication controller")
	return metrics
}
</file>

<file path="pkg/collectors/storageclass.go">
// Copyright 2024 Vega Cloud, Inc.
//
// Use of this software is governed by the Business Source License
// included in the file licenses/BSL.txt.
//
// As of the Change Date specified in that file, in accordance with
// the Business Source License, use of this software will be governed
// by the Apache License, Version 2.0, included in the file
// licenses/APL.txt.
package collectors
import (
	"context"
	"fmt"
	"runtime/debug"
	"strings"
	"github.com/sirupsen/logrus"
	v1 "k8s.io/api/core/v1"
	storagev1 "k8s.io/api/storage/v1"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/client-go/kubernetes"
	"github.com/vegacloud/kubernetes/metricsagent/pkg/config"
	"github.com/vegacloud/kubernetes/metricsagent/pkg/models"
	"github.com/vegacloud/kubernetes/metricsagent/pkg/utils"
)
// StorageClassCollector collects metrics from Kubernetes storage classes
type StorageClassCollector struct {
	clientset *kubernetes.Clientset
	config    *config.Config
}
// NewStorageClassCollector creates a new StorageClassCollector
func NewStorageClassCollector(clientset *kubernetes.Clientset, cfg *config.Config) *StorageClassCollector {
	logrus.Debug("StorageClassCollector created successfully")
	return &StorageClassCollector{
		clientset: clientset,
		config:    cfg,
	}
}
// CollectMetrics collects metrics from Kubernetes storage classes
func (sc *StorageClassCollector) CollectMetrics(ctx context.Context) (interface{}, error) {
	defer func() {
		if r := recover(); r != nil {
			logrus.Errorf("Recovered from panic in StorageClassCollector: %v", r)
		}
	}()
	storageClasses, err := sc.clientset.StorageV1().StorageClasses().List(ctx, metav1.ListOptions{})
	if err != nil {
		logrus.WithError(err).Error("Failed to list storage classes")
		return []models.StorageClassMetrics{}, nil
	}
	metrics := make([]models.StorageClassMetrics, 0, len(storageClasses.Items))
	for _, storageClass := range storageClasses.Items {
		metric := sc.parseStorageClassMetrics(ctx, storageClass)
		metrics = append(metrics, metric)
	}
	logrus.Debugf("Successfully collected metrics for %d storage classes", len(metrics))
	return metrics, nil
}
func (sc *StorageClassCollector) parseStorageClassMetrics(ctx context.Context, storageClass storagev1.StorageClass) models.StorageClassMetrics {
	defer func() {
		if r := recover(); r != nil {
			logrus.WithFields(logrus.Fields{
				"storageClass": storageClass.Name,
				"panic":        r,
			}).Error("Recovered from panic while parsing storage class metrics")
		}
	}()
	if storageClass.Labels == nil {
		storageClass.Labels = make(map[string]string)
	}
	if storageClass.Annotations == nil {
		storageClass.Annotations = make(map[string]string)
	}
	metrics := models.StorageClassMetrics{
		Name:              storageClass.Name,
		Provisioner:       storageClass.Provisioner,
		ReclaimPolicy:     "", // Will be set below if not nil
		VolumeBindingMode: "", // Will be set below if not nil
		Labels:            storageClass.Labels,
		Annotations:       storageClass.Annotations,
		Parameters:        storageClass.Parameters,
		MountOptions:      storageClass.MountOptions,
		CreationTimestamp: &storageClass.CreationTimestamp.Time,
	}
	// Safely set ReclaimPolicy
	if storageClass.ReclaimPolicy != nil {
		metrics.ReclaimPolicy = string(*storageClass.ReclaimPolicy)
	}
	// Safely set VolumeBindingMode
	if storageClass.VolumeBindingMode != nil {
		metrics.VolumeBindingMode = string(*storageClass.VolumeBindingMode)
	}
	// Safely set AllowVolumeExpansion
	metrics.AllowVolumeExpansion = storageClass.AllowVolumeExpansion != nil && *storageClass.AllowVolumeExpansion
	// Check if this is the default storage class
	metrics.IsDefault = false
	for key, value := range storageClass.Annotations {
		if (key == "storageclass.kubernetes.io/is-default-class" ||
			key == "storageclass.beta.kubernetes.io/is-default-class") &&
			value == "true" {
			metrics.IsDefault = true
			break
		}
	}
	// Collect CSI driver metrics with better error logging
	if csiDriver, err := sc.collectCSIDriverMetrics(ctx, storageClass.Provisioner); err != nil {
		logrus.WithFields(logrus.Fields{
			"storageClass": storageClass.Name,
			"provisioner":  storageClass.Provisioner,
			"error":        err,
		}).Error("Failed to collect CSI driver metrics")
	} else {
		metrics.CSIDriver = csiDriver
	}
	// Collect storage pool metrics with better error logging
	if storagePools, err := sc.collectStoragePoolMetrics(ctx, storageClass.Name); err != nil {
		logrus.WithFields(logrus.Fields{
			"storageClass": storageClass.Name,
			"error":        err,
		}).Error("Failed to collect storage pool metrics")
	} else {
		metrics.StoragePools = storagePools
	}
	// Collect capacity metrics with better error logging
	if capacityMetrics, err := sc.collectCapacityMetrics(ctx, storageClass.Name); err != nil {
		logrus.WithFields(logrus.Fields{
			"storageClass": storageClass.Name,
			"error":        err,
		}).Error("Failed to collect capacity metrics")
	} else {
		metrics.TotalCapacity = capacityMetrics.TotalCapacity
		metrics.AllocatedCapacity = capacityMetrics.AllocatedCapacity
		metrics.AvailableCapacity = capacityMetrics.AvailableCapacity
		metrics.CapacityUtilization = capacityMetrics.CapacityUtilization
		metrics.ProvisionedPVCs = capacityMetrics.ProvisionedPVCs
		metrics.ProvisioningRate = capacityMetrics.ProvisioningRate
	}
	logrus.Debugf("Parsed metrics for storage class %s", storageClass.Name)
	return metrics
}
func (sc *StorageClassCollector) collectCSIDriverMetrics(ctx context.Context, provisioner string) (*models.CSIDriverMetrics, error) {
	defer func() {
		if r := recover(); r != nil {
			logrus.WithFields(logrus.Fields{
				"provisioner": provisioner,
				"panic":       r,
			}).Error("Recovered from panic while collecting CSI driver metrics")
		}
	}()
	csiDrivers, err := sc.clientset.StorageV1().CSIDrivers().List(ctx, metav1.ListOptions{})
	if err != nil {
		logrus.Errorf("Failed to list CSI drivers: %v", err)
		return &models.CSIDriverMetrics{
			Name:      provisioner,
			Available: false,
		}, nil
	}
	for _, driver := range csiDrivers.Items {
		if driver.Name == provisioner {
			metrics := &models.CSIDriverMetrics{
				Name:               driver.Name,
				Available:          true,
				VolumeSnapshotting: driver.Spec.VolumeLifecycleModes != nil,
				VolumeCloning:      driver.Spec.VolumeLifecycleModes != nil,
				VolumeExpansion:    driver.Spec.RequiresRepublish != nil && *driver.Spec.RequiresRepublish,
				NodePluginPods:     make(map[string]string),
				ControllerPods:     make(map[string]string),
			}
			if pods, err := sc.clientset.CoreV1().Pods("").List(ctx, metav1.ListOptions{
				LabelSelector: fmt.Sprintf("app=%s", driver.Name),
			}); err == nil {
				for _, pod := range pods.Items {
					if pod.Spec.NodeName == "" {
						continue
					}
					if strings.Contains(pod.Name, "node") {
						metrics.NodePluginPods[pod.Spec.NodeName] = string(pod.Status.Phase)
					} else if strings.Contains(pod.Name, "controller") {
						metrics.ControllerPods[pod.Namespace] = string(pod.Status.Phase)
					}
				}
			}
			return metrics, nil
		}
	}
	// Return empty metrics if CSI driver not found
	return &models.CSIDriverMetrics{
		Name:      provisioner,
		Available: false,
	}, nil
}
func (sc *StorageClassCollector) collectStoragePoolMetrics(ctx context.Context, storageClassName string) ([]models.StoragePoolMetrics, error) {
	defer func() {
		if r := recover(); r != nil {
			logrus.WithFields(logrus.Fields{
				"storageClass": storageClassName,
				"panic":        r,
				"stacktrace":   string(debug.Stack()),
			}).Error("Recovered from panic while collecting storage pool metrics")
		}
	}()
	pvs, err := sc.clientset.CoreV1().PersistentVolumes().List(ctx, metav1.ListOptions{})
	if err != nil {
		logrus.WithFields(logrus.Fields{
			"storageClass": storageClassName,
			"error":        err,
		}).Error("Failed to list PVs for storage pools")
		return []models.StoragePoolMetrics{}, nil
	}
	poolMap := make(map[string]*models.StoragePoolMetrics)
	for _, pv := range pvs.Items {
		if pv.Spec.StorageClassName != storageClassName {
			continue
		}
		if pv.Spec.CSI == nil {
			logrus.WithFields(logrus.Fields{
				"storageClass": storageClassName,
				"pvName":       pv.Name,
			}).Debug("Skipping PV without CSI spec")
			continue
		}
		poolName := pv.Labels["storage-pool"]
		if poolName == "" {
			poolName = "default"
		}
		if pool, exists := poolMap[poolName]; exists {
			pool.UsedCapacity += pv.Spec.Capacity.Storage().Value()
			pool.VolumeCount++
		} else {
			poolMap[poolName] = &models.StoragePoolMetrics{
				Name:         poolName,
				Provider:     pv.Spec.CSI.Driver,
				StorageClass: storageClassName,
				UsedCapacity: pv.Spec.Capacity.Storage().Value(),
				VolumeCount:  1,
			}
		}
	}
	pools := make([]models.StoragePoolMetrics, 0, len(poolMap))
	for _, pool := range poolMap {
		if pool.TotalCapacity > 0 {
			pool.UtilizationPct = float64(pool.UsedCapacity) / float64(pool.TotalCapacity) * 100
			pool.AvailableSpace = pool.TotalCapacity - pool.UsedCapacity
		} else {
			logrus.WithFields(logrus.Fields{
				"storageClass": storageClassName,
				"poolName":     pool.Name,
			}).Debug("Pool has zero total capacity")
			pool.UtilizationPct = 0
			pool.AvailableSpace = 0
		}
		pools = append(pools, *pool)
	}
	return pools, nil
}
func (sc *StorageClassCollector) collectCapacityMetrics(ctx context.Context, storageClassName string) (*models.StorageClassMetrics, error) {
	defer func() {
		if r := recover(); r != nil {
			logrus.WithFields(logrus.Fields{
				"storageClass": storageClassName,
				"panic":        r,
				"stacktrace":   string(debug.Stack()),
			}).Error("Recovered from panic while collecting capacity metrics")
		}
	}()
	metrics := &models.StorageClassMetrics{}
	pvcs, err := sc.clientset.CoreV1().PersistentVolumeClaims("").List(ctx, metav1.ListOptions{})
	if err != nil {
		logrus.WithFields(logrus.Fields{
			"storageClass": storageClassName,
			"error":        err,
		}).Error("Failed to list PVCs for capacity metrics")
		return &models.StorageClassMetrics{}, nil
	}
	var totalRequested int64
	provisionedCount := 0
	for _, pvc := range pvcs.Items {
		if pvc.Spec.StorageClassName == nil {
			logrus.WithFields(logrus.Fields{
				"pvcName":      pvc.Name,
				"pvcNamespace": pvc.Namespace,
			}).Debug("Skipping PVC without storage class name")
			continue
		}
		if *pvc.Spec.StorageClassName == storageClassName {
			if pvc.Spec.Resources.Requests != nil {
				storage := pvc.Spec.Resources.Requests.Storage()
				if storage != nil {
					totalRequested += storage.Value()
				} else {
					logrus.WithFields(logrus.Fields{
						"pvcName":      pvc.Name,
						"pvcNamespace": pvc.Namespace,
						"storageClass": storageClassName,
					}).Debug("PVC has nil storage request")
				}
			}
			if pvc.Status.Phase == v1.ClaimBound {
				provisionedCount++
			}
		}
	}
	metrics.AllocatedCapacity = totalRequested
	metrics.ProvisionedPVCs = utils.SafeInt32Conversion(provisionedCount)
	logrus.WithFields(logrus.Fields{
		"storageClass":     storageClassName,
		"totalRequested":   totalRequested,
		"provisionedCount": provisionedCount,
	}).Debug("Collected capacity metrics")
	return metrics, nil
}
</file>

<file path="pkg/collectors/workload.go">
// Copyright 2024 Vega Cloud, Inc.
//
// Use of this software is governed by the Business Source License
// included in the file licenses/BSL.txt.
//
// As of the Change Date specified in that file, in accordance with
// the Business Source License, use of this software will be governed
// by the Apache License, Version 2.0, included in the file
// licenses/APL.txt.
// File: pkg/collectors/workload.go
// Package collectors hosts the collection functions
package collectors
import (
	"context"
	"fmt"
	"runtime/debug"
	"time"
	"github.com/sirupsen/logrus"
	appsv1 "k8s.io/api/apps/v1"
	batchv1 "k8s.io/api/batch/v1"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/client-go/kubernetes"
	"github.com/vegacloud/kubernetes/metricsagent/pkg/config"
	"github.com/vegacloud/kubernetes/metricsagent/pkg/models"
	v1 "k8s.io/api/core/v1"
)
// WorkloadCollector collects metrics from Kubernetes workloads.
type WorkloadCollector struct {
	clientset *kubernetes.Clientset
	config    *config.Config
}
// NewWorkloadCollector creates a new WorkloadCollector.
func NewWorkloadCollector(clientset *kubernetes.Clientset, cfg *config.Config) *WorkloadCollector {
	defer func() {
		if r := recover(); r != nil {
			logrus.WithFields(logrus.Fields{
				"panic":      r,
				"stacktrace": string(debug.Stack()),
			}).Error("Recovered from panic in NewWorkloadCollector")
		}
	}()
	logrus.Debug("Creating new WorkloadCollector")
	collector := &WorkloadCollector{
		clientset: clientset,
		config:    cfg,
	}
	logrus.Debug("WorkloadCollector created successfully")
	return collector
}
// CollectMetrics collects metrics from Kubernetes workloads.
func (wc *WorkloadCollector) CollectMetrics(ctx context.Context) (interface{}, error) {
	defer func() {
		if r := recover(); r != nil {
			logrus.WithFields(logrus.Fields{
				"panic":      r,
				"stacktrace": string(debug.Stack()),
			}).Error("Recovered from panic in WorkloadCollector.CollectMetrics")
		}
	}()
	metrics, err := wc.CollectWorkloadMetrics(ctx)
	if err != nil {
		logrus.WithError(err).Error("Failed to collect workload metrics")
		return &models.WorkloadMetrics{}, nil
	}
	return metrics, nil
}
// CollectWorkloadMetrics collects metrics from Kubernetes workloads.
func (wc *WorkloadCollector) CollectWorkloadMetrics(ctx context.Context) ([]models.WorkloadMetrics, error) {
	defer func() {
		if r := recover(); r != nil {
			logrus.WithFields(logrus.Fields{
				"panic":      r,
				"stacktrace": string(debug.Stack()),
			}).Error("Recovered from panic in CollectWorkloadMetrics")
		}
	}()
	metrics := make([]models.WorkloadMetrics, 0)
	workloadMetrics := models.WorkloadMetrics{}
	// Collect deployment metrics
	deployments, err := wc.collectDeploymentMetrics(ctx)
	if err != nil {
		logrus.WithError(err).Warn("Failed to collect deployment metrics")
	} else {
		workloadMetrics.Deployments = deployments
		logrus.WithField("count", len(deployments)).Debug("Successfully collected deployment metrics")
	}
	// Collect statefulset metrics
	statefulSets, err := wc.collectStatefulSetMetrics(ctx)
	if err != nil {
		logrus.WithError(err).Warn("Failed to collect statefulset metrics")
	} else {
		workloadMetrics.StatefulSets = statefulSets
		logrus.WithField("count", len(statefulSets)).Debug("Successfully collected statefulset metrics")
	}
	// Collect daemonset metrics
	daemonSets, err := wc.collectDaemonSetMetrics(ctx)
	if err != nil {
		logrus.WithError(err).Warn("Failed to collect daemonset metrics")
	} else {
		workloadMetrics.DaemonSets = daemonSets
		logrus.WithField("count", len(daemonSets)).Debug("Successfully collected daemonset metrics")
	}
	// Collect job metrics
	jobs, err := wc.collectJobMetrics(ctx)
	if err != nil {
		logrus.WithError(err).Warn("Failed to collect job metrics")
	} else {
		workloadMetrics.Jobs = jobs
		logrus.WithField("count", len(jobs)).Debug("Successfully collected job metrics")
	}
	metrics = append(metrics, workloadMetrics)
	return metrics, nil
}
// collectDeploymentMetrics collects metrics from Kubernetes deployments.
func (wc *WorkloadCollector) collectDeploymentMetrics(ctx context.Context) ([]models.DeploymentMetrics, error) {
	defer func() {
		if r := recover(); r != nil {
			logrus.WithFields(logrus.Fields{
				"panic":      r,
				"stacktrace": string(debug.Stack()),
			}).Error("Recovered from panic in collectDeploymentMetrics")
		}
	}()
	deployments, err := wc.clientset.AppsV1().Deployments("").List(ctx, metav1.ListOptions{})
	if err != nil {
		return nil, err
	}
	metrics := make([]models.DeploymentMetrics, 0, len(deployments.Items))
	for _, d := range deployments.Items {
		logrus.WithFields(logrus.Fields{
			"deployment": d.Name,
			"namespace":  d.Namespace,
		}).Debug("Processing deployment")
		metrics = append(metrics, wc.parseDeploymentMetrics(d))
	}
	return metrics, nil
}
func (wc *WorkloadCollector) parseDeploymentMetrics(d appsv1.Deployment) models.DeploymentMetrics {
	defer func() {
		if r := recover(); r != nil {
			logrus.WithFields(logrus.Fields{
				"deployment": d.Name,
				"namespace":  d.Namespace,
				"panic":      r,
				"stacktrace": string(debug.Stack()),
			}).Error("Recovered from panic in parseDeploymentMetrics")
		}
	}()
	if d.Labels == nil {
		d.Labels = make(map[string]string)
	}
	conditions := make([]string, 0)
	for _, condition := range d.Status.Conditions {
		conditions = append(conditions, string(condition.Type))
	}
	metrics := models.DeploymentMetrics{
		Name:               d.Name,
		Namespace:          d.Namespace,
		Replicas:           *d.Spec.Replicas,
		ReadyReplicas:      d.Status.ReadyReplicas,
		UpdatedReplicas:    d.Status.UpdatedReplicas,
		AvailableReplicas:  d.Status.AvailableReplicas,
		Labels:             d.Labels,
		CollisionCount:     d.Status.CollisionCount,
		Conditions:         conditions,
		Generation:         d.Generation,
		ObservedGeneration: d.Status.ObservedGeneration,
	}
	logrus.WithFields(logrus.Fields{
		"deployment": d.Name,
		"namespace":  d.Namespace,
		"replicas":   metrics.Replicas,
		"ready":      metrics.ReadyReplicas,
		"available":  metrics.AvailableReplicas,
	}).Debug("Collected metrics for deployment")
	return metrics
}
func (wc *WorkloadCollector) collectStatefulSetMetrics(ctx context.Context) ([]models.StatefulSetMetrics, error) {
	statefulSets, err := wc.clientset.AppsV1().StatefulSets("").List(ctx, metav1.ListOptions{})
	if err != nil {
		return nil, fmt.Errorf("failed to list statefulsets: %w", err)
	}
	metrics := make([]models.StatefulSetMetrics, 0, len(statefulSets.Items))
	for _, s := range statefulSets.Items {
		metrics = append(metrics, wc.parseStatefulSetMetrics(s))
	}
	logrus.Debugf("Collected metrics for %d statefulsets", len(metrics))
	return metrics, nil
}
func (wc *WorkloadCollector) parseStatefulSetMetrics(s appsv1.StatefulSet) models.StatefulSetMetrics {
	if s.Labels == nil {
		s.Labels = make(map[string]string)
	}
	conditions := make([]string, 0)
	for _, condition := range s.Status.Conditions {
		conditions = append(conditions, string(condition.Type))
	}
	return models.StatefulSetMetrics{
		Name:               s.Name,
		Namespace:          s.Namespace,
		Replicas:           *s.Spec.Replicas,
		ReadyReplicas:      s.Status.ReadyReplicas,
		CurrentReplicas:    s.Status.CurrentReplicas,
		UpdatedReplicas:    s.Status.UpdatedReplicas,
		AvailableReplicas:  s.Status.AvailableReplicas,
		Labels:             s.Labels,
		CollisionCount:     s.Status.CollisionCount,
		Conditions:         conditions,
		Generation:         s.Generation,
		ObservedGeneration: s.Status.ObservedGeneration,
	}
}
func (wc *WorkloadCollector) collectDaemonSetMetrics(ctx context.Context) ([]models.DaemonSetMetrics, error) {
	daemonSets, err := wc.clientset.AppsV1().DaemonSets("").List(ctx, metav1.ListOptions{})
	if err != nil {
		return nil, fmt.Errorf("failed to list daemonsets: %w", err)
	}
	metrics := make([]models.DaemonSetMetrics, 0, len(daemonSets.Items))
	for _, d := range daemonSets.Items {
		metrics = append(metrics, wc.parseDaemonSetMetrics(d))
	}
	logrus.Debugf("Collected metrics for %d daemonsets", len(metrics))
	return metrics, nil
}
func (wc *WorkloadCollector) parseDaemonSetMetrics(d appsv1.DaemonSet) models.DaemonSetMetrics {
	if d.Labels == nil {
		d.Labels = make(map[string]string)
	}
	conditions := make([]models.DaemonSetCondition, 0)
	for _, condition := range d.Status.Conditions {
		conditions = append(conditions, models.DaemonSetCondition{
			Type:               string(condition.Type),
			Status:             string(condition.Status),
			LastTransitionTime: &condition.LastTransitionTime.Time,
			Reason:             condition.Reason,
			Message:            condition.Message,
		})
	}
	return models.DaemonSetMetrics{
		Name:                   d.Name,
		Namespace:              d.Namespace,
		DesiredNumberScheduled: d.Status.DesiredNumberScheduled,
		CurrentNumberScheduled: d.Status.CurrentNumberScheduled,
		NumberReady:            d.Status.NumberReady,
		UpdatedNumberScheduled: d.Status.UpdatedNumberScheduled,
		NumberAvailable:        d.Status.NumberAvailable,
		NumberUnavailable:      d.Status.NumberUnavailable,
		NumberMisscheduled:     d.Status.NumberMisscheduled,
		Labels:                 d.Labels,
		Generation:             d.Generation,
		ObservedGeneration:     d.Status.ObservedGeneration,
		Conditions:             conditions,
	}
}
func (wc *WorkloadCollector) collectJobMetrics(ctx context.Context) ([]models.JobMetrics, error) {
	jobs, err := wc.clientset.BatchV1().Jobs("").List(ctx, metav1.ListOptions{})
	if err != nil {
		return nil, fmt.Errorf("failed to list jobs: %w", err)
	}
	metrics := make([]models.JobMetrics, 0, len(jobs.Items))
	for _, j := range jobs.Items {
		metrics = append(metrics, wc.parseJobMetrics(j))
	}
	logrus.Debugf("Collected metrics for %d jobs", len(metrics))
	return metrics, nil
}
func (wc *WorkloadCollector) parseJobMetrics(j batchv1.Job) models.JobMetrics {
	if j.Labels == nil {
		j.Labels = make(map[string]string)
	}
	conditions := make([]models.JobCondition, 0)
	for _, condition := range j.Status.Conditions {
		conditions = append(conditions, models.JobCondition{
			Type:               string(condition.Type),
			Status:             string(condition.Status),
			LastProbeTime:      &condition.LastProbeTime.Time,
			LastTransitionTime: &condition.LastTransitionTime.Time,
			Reason:             condition.Reason,
			Message:            condition.Message,
		})
	}
	metrics := models.JobMetrics{
		Name:             j.Name,
		Namespace:        j.Namespace,
		Labels:           j.Labels,
		Active:           j.Status.Active,
		Succeeded:        j.Status.Succeeded,
		Failed:           j.Status.Failed,
		Status:           getJobStatus(j.Status),
		CompletedIndexes: j.Status.CompletedIndexes,
		Conditions:       conditions,
		Generation:       j.Generation,
	}
	// Add existing time-related fields
	if j.Status.StartTime != nil {
		metrics.StartTime = &j.Status.StartTime.Time
	}
	if j.Status.CompletionTime != nil {
		metrics.CompletionTime = &j.Status.CompletionTime.Time
	}
	if metrics.StartTime != nil {
		endTime := time.Now()
		if metrics.CompletionTime != nil {
			endTime = *metrics.CompletionTime
		}
		duration := endTime.Sub(*metrics.StartTime)
		metrics.Duration = &duration
	}
	metrics.ResourceMetrics = wc.getJobResourceMetrics(j)
	return metrics
}
// Helper function to get job status
func getJobStatus(status batchv1.JobStatus) string {
	switch {
	case status.Succeeded > 0:
		return "Succeeded"
	case status.Failed > 0:
		return "Failed"
	case status.Active > 0:
		return "Active"
	default:
		return "Pending"
	}
}
// Helper function to get resource metrics for a job
func (wc *WorkloadCollector) getJobResourceMetrics(job batchv1.Job) models.ResourceMetrics {
	metrics := models.ResourceMetrics{}
	if job.Spec.Template.Spec.Containers == nil {
		return metrics
	}
	for _, container := range job.Spec.Template.Spec.Containers {
		if container.Resources.Requests != nil {
			metrics.CPU += container.Resources.Requests.Cpu().MilliValue()
			metrics.Memory += container.Resources.Requests.Memory().Value()
			if storage := container.Resources.Requests.Storage(); storage != nil {
				metrics.Storage += storage.Value()
			}
			if ephemeral, ok := container.Resources.Requests[v1.ResourceEphemeralStorage]; ok {
				metrics.EphemeralStorage += ephemeral.Value()
			}
		}
	}
	return metrics
}
</file>

<file path="pkg/config/config.go">
// Copyright 2024 Vega Cloud, Inc.
//
// Use of this software is governed by the Business Source License
// included in the file licenses/BSL.txt.
//
// As of the Change Date specified in that file, in accordance with
// the Business Source License, use of this software will be governed
// by the Apache License, Version 2.0, included in the file
// licenses/APL.txt.
// Package config provides configuration parameters for the agent
package config
import (
	_ "embed"
	"time"
)
// Config holds configuration parameters for the agent
type Config struct {
	AgentID                  string        `mapstructure:"agent_id"`
	VegaClientID             string        `mapstructure:"client_id"`
	VegaClientSecret         string        `mapstructure:"client_secret"`
	VegaClusterName          string        `mapstructure:"cluster_name"`
	VegaOrgSlug              string        `mapstructure:"org_slug"`
	VegaPollInterval         time.Duration `mapstructure:"poll_interval"`
	VegaUploadRegion         string        `mapstructure:"upload_region"`
	VegaParseMetricData      bool          `mapstructure:"parse_metric_data"`
	VegaInsecure             bool          `mapstructure:"insecure"`
	VegaWorkDir              string        `mapstructure:"work_dir"`
	VegaCollectionRetryLimit int           `mapstructure:"collection_retry_limit"`
	VegaBearerTokenPath      string        `mapstructure:"bearer_token_path"`
	VegaNamespace            string        `mapstructure:"namespace"`
	MetricsCollectorAPI      string        `mapstructure:"metrics_collector_api"`
	AuthServiceURL           string        `mapstructure:"auth_service_url"`
	StartCollectionNow       bool          `mapstructure:"start_collection_now"`
	SaveLocal                bool          `mapstructure:"save_local"`
	VegaMaxConcurrency       int           `mapstructure:"max_concurrency"`
	ShouldAgentCheckIn       bool          `mapstructure:"should_agent_check_in"`
	LogLevel                 string        `mapstructure:"log_level"`
	SchemaVersion            string        `mapstructure:"schema_version"`
	AgentVersion             string        `mapstructure:"agent_version"`
	ClusterVersion           string        `mapstructure:"cluster_version"`
	ClusterProvider          string        `mapstructure:"cluster_provider"`
	QPS                      float32       `mapstructure:"qps"`
	Burst                    int           `mapstructure:"burst"`
	Timeout                  time.Duration `mapstructure:"timeout"`
}
// VERSION contains the current version of the agent from the embedded VERSION file
//
//go:embed VERSION
var VERSION string
// SCHEMAVERSION contains the current schema version from the embedded SCHEMAVERSION file
//
//go:embed SCHEMAVERSION
var SCHEMAVERSION string
// Default configuration values
const (
	DefaultPollInterval             = "60m"
	DefaultMaxConcurrency           = 8
	DefaultS3Region                 = "us-west-2"
	DefaultBearerTokenPath          = "/var/run/secrets/kubernetes.io/serviceaccount/token" // #nosec G101
	DefaultLogLevel                 = "INFO"
	DefaultVegaInsecure             = false
	DefaultStartCollectionNow       = false
	DefaultVegaCollectionRetryLimit = 3
	DefaultWorkDir                  = "/tmp"
	DefaultMetricsCollectorAPI      = "https://api.vegacloud.io/metrics"
	DefaultAuthServiceURL           = "https://auth.vegacloud.io"
	DefaultVegaNamespace            = "vegacloud"
	DefaultShouldAgentCheckIn       = true
	DefaultSaveLocal                = false
	DefaultQPS                      = 100
	DefaultBurst                    = 100
	DefaultTimeout                  = 10 * time.Second
)
// Default versions from embedded files
var (
	DefaultSchemaVersion = SCHEMAVERSION
	DefaultAgentVersion  = VERSION
)
</file>

<file path="pkg/config/SCHEMAVERSION">
1.2.0
</file>

<file path="pkg/config/VERSION">
1.1.3
</file>

<file path="pkg/health/health.go">
// Package health provides a simple health check server that responds with 200 OK to /health.
// Copyright 2024 Vega Cloud, Inc.
//
// Use of this software is governed by the Business Source License
// included in the file licenses/BSL.txt.
//
// As of the Change Date specified in that file, in accordance with
// the Business Source License, use of this software will be governed
// by the Apache License, Version 2.0, included in the file
// licenses/APL.txt.
package health
import (
	"context"
	"net/http"
	"time"
)
// ServerHealthCheck starts a simple web server that responds with 200 OK to /health.
// It accepts a context that can be used to cancel the server.
func ServerHealthCheck(ctx context.Context) error {
	mux := http.NewServeMux()
	mux.HandleFunc("/health", func(w http.ResponseWriter, _ *http.Request) {
		w.WriteHeader(http.StatusOK)
		_, err := w.Write([]byte("OK"))
		if err != nil {
			return
		}
	})
	server := &http.Server{
		Addr:              ":80",
		Handler:           mux,
		ReadHeaderTimeout: 30 * time.Second, // Set ReadHeaderTimeout to mitigate Slowloris attacks
	}
	// Channel to receive server errors
	errChan := make(chan error, 1)
	// Start the server in a goroutine
	go func() {
		if err := server.ListenAndServe(); err != nil && err != http.ErrServerClosed {
			errChan <- err
		}
	}()
	// Wait for context cancellation
	<-ctx.Done()
	// Shutdown the server with a timeout
	shutdownCtx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
	defer cancel()
	if err := server.Shutdown(shutdownCtx); err != nil {
		return err
	}
	// Return any server error that occurred
	select {
	case err := <-errChan:
		return err
	default:
		return nil
	}
}
</file>

<file path="pkg/models/metrics.go">
// Copyright 2024 Vega Cloud, Inc.
//
// Use of this software is governed by the Business Source License
// included in the file licenses/BSL.txt.
//
// As of the Change Date specified in that file, in accordance with
// the Business Source License, use of this software will be governed
// by the Apache License, Version 2.0, included in the file
// licenses/APL.txt.
// Package models provides the data models for the metrics API
// File: pkg/models/metrics.go
// Package models provides the data models for the metrics API
package models
import (
	"time"
)
// EnhancedNodeMetrics represents detailed metrics for a single node
type EnhancedNodeMetrics struct {
	Name              string                      `json:"name"`
	Capacity          ResourceMetrics             `json:"capacity"`
	Allocatable       ResourceMetrics             `json:"allocatable"`
	Usage             ResourceMetrics             `json:"usage"`
	Conditions        NodeConditions              `json:"conditions"`
	Labels            map[string]string           `json:"labels"`
	Annotations       map[string]string           `json:"annotations"`
	DetailedMetrics   NodeDetailedMetrics         `json:"detailedMetrics"`
	HardwareTopology  *HardwareTopology           `json:"hardwareTopology,omitempty"`
	PowerMetrics      *PowerMetrics               `json:"powerMetrics,omitempty"`
	Taints            []NodeTaint                 `json:"taints,omitempty"`
	Lease             *NodeLease                  `json:"lease,omitempty"`
	ExtendedResources map[string]ExtendedResource `json:"extendedResources,omitempty"`
	NodeMetrics       NodeMetrics                 `json:"nodeMetrics"`
	CPU               CPUMetrics                  `json:"cpu,omitempty"`
	Memory            MemoryMetrics               `json:"memory,omitempty"`
	Network           NetworkMetrics              `json:"network,omitempty"`
	Disk              DiskMetrics                 `json:"disk,omitempty"`
	Filesystem        FSMetrics                   `json:"filesystem,omitempty"`
	VolumeHealth      []VolumeHealthMetrics       `json:"volumeHealth,omitempty"`
	VolumeAttachments []VolumeAttachmentMetrics   `json:"volumeAttachments,omitempty"`
	NodeInfo          NodeInfo                    `json:"nodeInfo"` // Add this line
}
// EnhancedPodMetrics represents detailed metrics for a single pod
type EnhancedPodMetrics struct {
	PodMetrics          PodMetrics                  `json:"podMetrics"`
	QoSClass            string                      `json:"qosClass"`
	Conditions          PodConditions               `json:"conditions"`
	Requests            ResourceMetrics             `json:"requests"`
	Limits              ResourceMetrics             `json:"limits"`
	Containers          []ContainerMetrics          `json:"containers"`
	TotalRestarts       int32                       `json:"totalRestarts"`
	StartTime           *time.Time                  `json:"startTime,omitempty"`
	CompletionTime      *time.Time                  `json:"completionTime,omitempty"`
	Priority            *int32                      `json:"priority,omitempty"`
	PriorityClassName   string                      `json:"priorityClassName,omitempty"`
	NodeName            string                      `json:"nodeName"`
	HostIP              string                      `json:"hostIP"`
	PodIPs              []string                    `json:"podIPs"`
	NominatedNodeName   string                      `json:"nominatedNodeName,omitempty"`
	ReadinessGates      []PodReadinessGate          `json:"readinessGates,omitempty"`
	Annotations         map[string]string           `json:"annotations"`
	VolumeMounts        []VolumeMountMetrics        `json:"volumeMounts"`
	ImagePullPolicy     string                      `json:"imagePullPolicy"`
	ServiceAccountName  string                      `json:"serviceAccountName"`
	DisruptionBudget    *PodDisruptionBudgetMetrics `json:"disruptionBudget,omitempty"`
	TopologySpread      []TopologySpreadConstraint  `json:"topologySpread,omitempty"`
	Overhead            *PodOverheadMetrics         `json:"overhead,omitempty"`
	SchedulingGates     []PodSchedulingGate         `json:"schedulingGates,omitempty"`
	Affinity            *AffinityMetrics            `json:"affinity,omitempty"`
	InitContainers      []InitContainerMetrics      `json:"initContainers,omitempty"`
	EphemeralContainers []EphemeralContainerMetrics `json:"ephemeralContainers,omitempty"`
	QoSDetails          *QoSMetrics                 `json:"qosDetails,omitempty"`
}
// NodeMetrics represents the metrics for a single node
type NodeMetrics struct {
	Name              string                    `json:"name"`
	Capacity          ResourceMetrics           `json:"capacity"`
	Allocatable       ResourceMetrics           `json:"allocatable"`
	Usage             ResourceMetrics           `json:"usage"`
	CPU               CPUMetrics                `json:"cpu,omitempty"`
	Memory            MemoryMetrics             `json:"memory,omitempty"`
	Network           NetworkMetrics            `json:"network,omitempty"`
	Disk              DiskMetrics               `json:"disk,omitempty"`
	Filesystem        FSMetrics                 `json:"filesystem,omitempty"`
	VolumeHealth      []VolumeHealthMetrics     `json:"volumeHealth,omitempty"`
	VolumeAttachments []VolumeAttachmentMetrics `json:"volumeAttachments,omitempty"`
}
// ResourceMetrics represents resource usage or capacity based on kubelet /metrics/resource
type ResourceMetrics struct {
	// CPU usage in millicores (m)
	CPU int64 `json:"cpu"`
	// Memory usage in bytes
	Memory int64 `json:"memory"`
	// Storage usage in bytes
	Storage int64 `json:"storage,omitempty"`
	// Ephemeral storage usage in bytes
	EphemeralStorage int64 `json:"ephemeralStorage,omitempty"`
	// Number of pods
	Pods int64 `json:"pods,omitempty"`
	// GPU devices if available
	GPUDevices []GPUMetrics `json:"gpuDevices,omitempty"`
}
// NodeConditions represents the conditions of a node
type NodeConditions struct {
	Ready          bool `json:"ready"`
	MemoryPressure bool `json:"memoryPressure"`
	DiskPressure   bool `json:"diskPressure"`
	PIDPressure    bool `json:"pidPressure"`
}
// PodMetrics represents the metrics for a single pod
type PodMetrics struct {
	Name          string             `json:"name"`
	Namespace     string             `json:"namespace"`
	Phase         string             `json:"phase"`
	QoSClass      string             `json:"qosClass"`
	Requests      ResourceMetrics    `json:"requests"`
	Limits        ResourceMetrics    `json:"limits"`
	Usage         ResourceMetrics    `json:"usage"`
	Containers    []ContainerMetrics `json:"containers"`
	Conditions    PodConditions      `json:"conditions"`
	TotalRestarts int32              `json:"totalRestarts"`
	Labels        map[string]string  `json:"labels"`
}
// PodConditions represents the conditions of a pod
type PodConditions struct {
	PodScheduled    bool `json:"podScheduled"`
	Initialized     bool `json:"initialized"`
	ContainersReady bool `json:"containersReady"`
	Ready           bool `json:"ready"`
}
// ClusterMetrics represents cluster-wide metrics
type ClusterMetrics struct {
	TotalCapacity     ResourceMetrics              `json:"totalCapacity"`
	TotalAllocatable  ResourceMetrics              `json:"totalAllocatable"`
	TotalRequests     ResourceMetrics              `json:"totalRequests"`
	TotalLimits       ResourceMetrics              `json:"totalLimits"`
	TotalUsage        ResourceMetrics              `json:"totalUsage"`
	NodeCount         int                          `json:"nodeCount"`
	PodCount          int                          `json:"podCount"`
	ContainerCount    int                          `json:"containerCount"`
	KubernetesVersion string                       `json:"kubernetesVersion"`
	ClusterProvider   string                       `json:"clusterProvider"`
	NodeLabels        map[string]map[string]string `json:"nodeLabels"` // New field for node labels
	PodLabels         map[string]map[string]string `json:"podLabels"`  // New field for pod labels
	// ContainerLabels  map[string]map[string]string `json:"containerLabels"`
}
// PersistentVolumeMetrics represents metrics for persistent volumes
// Deprecated: Use separate PVMetric and PVCMetric instead
// type PersistentVolumeMetrics struct {
//     PVs  []PVMetric  `json:"pvs"`
//     PVCs []PVCMetric `json:"pvcs"`
// }
// PVMetric represents metrics for a single persistent volume
type PVMetric struct {
	Name               string                  `json:"name"`
	Capacity           int64                   `json:"capacity"` // in bytes
	Phase              string                  `json:"phase"`
	StorageClass       string                  `json:"storageClass"`
	BoundPVC           string                  `json:"boundPVC,omitempty"`
	Labels             map[string]string       `json:"labels"`
	AccessModes        []string                `json:"accessModes"`
	ReclaimPolicy      string                  `json:"reclaimPolicy"`
	VolumeMode         string                  `json:"volumeMode"`
	StorageProvisioner string                  `json:"storageProvisioner,omitempty"`
	MountPoint         string                  `json:"mountPoint,omitempty"`
	Status             PVStatus                `json:"status"`
	MountOptions       []string                `json:"mountOptions,omitempty"`
	VolumeBindingMode  string                  `json:"volumeBindingMode,omitempty"`
	Snapshots          []VolumeSnapshotMetrics `json:"snapshots,omitempty"`
}
// PVCMetric represents metrics for a single persistent volume claim
type PVCMetric struct {
	Name               string                  `json:"name"`
	Namespace          string                  `json:"namespace"`
	Phase              string                  `json:"phase"`
	Capacity           int64                   `json:"capacity"`         // in bytes
	RequestedStorage   int64                   `json:"requestedStorage"` // in bytes
	StorageClass       string                  `json:"storageClass"`
	BoundPV            string                  `json:"boundPV,omitempty"`
	Labels             map[string]string       `json:"labels"`
	AccessModes        []string                `json:"accessModes"`
	VolumeMode         string                  `json:"volumeMode"`
	Status             PVCStatus               `json:"status"`
	VolumeName         string                  `json:"volumeName,omitempty"`
	StorageProvisioner string                  `json:"storageProvisioner,omitempty"`
	MountOptions       []string                `json:"mountOptions,omitempty"`
	VolumeBindingMode  string                  `json:"volumeBindingMode,omitempty"`
	Expansion          *VolumeExpansionMetrics `json:"expansion,omitempty"`
}
// PVStatus represents the status of a persistent volume
type PVStatus struct {
	Phase               string     `json:"phase"`
	Message             string     `json:"message,omitempty"`
	Reason              string     `json:"reason,omitempty"`
	LastPhaseTransition *time.Time `json:"lastPhaseTransition,omitempty"`
}
// PVCStatus represents the status of a persistent volume claim
type PVCStatus struct {
	Phase               string         `json:"phase"`
	Message             string         `json:"message,omitempty"`
	Reason              string         `json:"reason,omitempty"`
	LastPhaseTransition *time.Time     `json:"lastPhaseTransition,omitempty"`
	Conditions          []PVCCondition `json:"conditions"`
}
// PVCCondition represents a condition of a PVC
type PVCCondition struct {
	Type               string     `json:"type"`
	Status             string     `json:"status"`
	Reason             string     `json:"reason,omitempty"`
	Message            string     `json:"message,omitempty"`
	LastTransitionTime *time.Time `json:"lastTransitionTime,omitempty"`
}
// NamespaceMetrics represents metrics for a single namespace
type NamespaceMetrics struct {
	Name              string                 `json:"name"`
	Status            string                 `json:"status"`
	Phase             string                 `json:"phase"`
	CreationTimestamp time.Time              `json:"creationTimestamp"`
	DeletionTimestamp *time.Time             `json:"deletionTimestamp,omitempty"`
	Finalizers        []string               `json:"finalizers"`
	Conditions        []NamespaceCondition   `json:"conditions"`
	ResourceQuotas    []ResourceQuotaMetrics `json:"resourceQuotas"`
	LimitRanges       []LimitRangeMetrics    `json:"limitRanges"`
	Usage             ResourceUsage          `json:"usage"`
	Labels            map[string]string      `json:"labels"`
	Annotations       map[string]string      `json:"annotations"`
}
// NamespaceCondition represents the current condition of a namespace
type NamespaceCondition struct {
	Type               string     `json:"type"`
	Status             string     `json:"status"`
	LastTransitionTime *time.Time `json:"lastTransitionTime,omitempty"`
	Reason             string     `json:"reason,omitempty"`
	Message            string     `json:"message,omitempty"`
}
// ResourceQuotaMetrics represents metrics for a resource quota
type ResourceQuotaMetrics struct {
	Name      string           `json:"name"`
	Resources []ResourceMetric `json:"resources"`
	// New detailed quota fields
	Scopes          []QuotaScopeMetrics         `json:"scopes,omitempty"`
	PriorityQuotas  []PriorityClassQuotaMetrics `json:"priorityQuotas,omitempty"`
	StatusHistory   []QuotaStatusHistory        `json:"statusHistory,omitempty"`
	LastUpdateTime  time.Time                   `json:"lastUpdateTime,omitempty"`
	EnforcementMode string                      `json:"enforcementMode,omitempty"`
}
// ResourceMetric represents a single resource metric
type ResourceMetric struct {
	ResourceName string `json:"resourceName"`
	Hard         string `json:"hard"`
	Used         string `json:"used"`
}
// LimitRangeMetrics represents metrics for a limit range
type LimitRangeMetrics struct {
	Name   string           `json:"name"`
	Limits []LimitRangeItem `json:"limits"`
}
// LimitRangeItem represents a single limit range item
type LimitRangeItem struct {
	Type           string            `json:"type"`
	Max            map[string]string `json:"max,omitempty"`
	Min            map[string]string `json:"min,omitempty"`
	Default        map[string]string `json:"default,omitempty"`
	DefaultRequest map[string]string `json:"defaultRequest,omitempty"`
}
// ResourceUsage represents resource usage for a namespace
type ResourceUsage struct {
	CPU     int64 `json:"cpu"`     // in millicores
	Memory  int64 `json:"memory"`  // in bytes
	Storage int64 `json:"storage"` // in bytes
	Pods    int64 `json:"pods"`
}
// WorkloadMetrics represents metrics for various workloads
type WorkloadMetrics struct {
	Deployments  []DeploymentMetrics  `json:"deployments"`
	StatefulSets []StatefulSetMetrics `json:"statefulSets"`
	DaemonSets   []DaemonSetMetrics   `json:"daemonSets"`
	Jobs         []JobMetrics         `json:"jobs"`
}
// DeploymentMetrics represents metrics for a Kubernetes Deployment
type DeploymentMetrics struct {
	Name               string            `json:"name"`
	Namespace          string            `json:"namespace"`
	Labels             map[string]string `json:"labels"`
	Replicas           int32             `json:"replicas"`
	ReadyReplicas      int32             `json:"readyReplicas"`
	UpdatedReplicas    int32             `json:"updatedReplicas"`
	AvailableReplicas  int32             `json:"availableReplicas"`
	CollisionCount     *int32            `json:"collisionCount"`
	Conditions         []string          `json:"conditions"`
	Generation         int64             `json:"generation"`
	ObservedGeneration int64             `json:"observedGeneration"`
}
// StatefulSetMetrics represents metrics for a Kubernetes StatefulSet
type StatefulSetMetrics struct {
	Name               string            `json:"name"`
	Namespace          string            `json:"namespace"`
	Labels             map[string]string `json:"labels"`
	Replicas           int32             `json:"replicas"`
	ReadyReplicas      int32             `json:"readyReplicas"`
	CurrentReplicas    int32             `json:"currentReplicas"`
	UpdatedReplicas    int32             `json:"updatedReplicas"`
	AvailableReplicas  int32             `json:"availableReplicas"`
	CollisionCount     *int32            `json:"collisionCount"`
	Conditions         []string          `json:"conditions"`
	Generation         int64             `json:"generation"`
	ObservedGeneration int64             `json:"observedGeneration"`
}
// DaemonSetMetrics represents metrics for a Kubernetes DaemonSet
type DaemonSetMetrics struct {
	Name                   string               `json:"name"`
	Namespace              string               `json:"namespace"`
	Labels                 map[string]string    `json:"labels"`
	DesiredNumberScheduled int32                `json:"desiredNumberScheduled"`
	CurrentNumberScheduled int32                `json:"currentNumberScheduled"`
	NumberReady            int32                `json:"numberReady"`
	UpdatedNumberScheduled int32                `json:"updatedNumberScheduled"`
	NumberAvailable        int32                `json:"numberAvailable"`
	NumberUnavailable      int32                `json:"numberUnavailable"`
	NumberMisscheduled     int32                `json:"numberMisscheduled"`
	Generation             int64                `json:"generation"`
	ObservedGeneration     int64                `json:"observedGeneration"`
	Conditions             []DaemonSetCondition `json:"conditions"`
	Status                 DaemonSetStatus      `json:"status"`
	CreationTimestamp      *time.Time           `json:"creationTimestamp"`
	CollisionCount         *int32               `json:"collisionCount"`
	Annotations            map[string]string    `json:"annotations"`
}
// JobMetrics represents metrics for a Kubernetes Job
type JobMetrics struct {
	Name               string            `json:"name"`
	Namespace          string            `json:"namespace"`
	Labels             map[string]string `json:"labels"`
	Active             int32             `json:"active"`
	Succeeded          int32             `json:"succeeded"`
	Failed             int32             `json:"failed"`
	Status             string            `json:"status"`
	StartTime          *time.Time        `json:"startTime,omitempty"`
	CompletionTime     *time.Time        `json:"completionTime,omitempty"`
	Duration           *time.Duration    `json:"duration,omitempty"`
	ResourceMetrics    ResourceMetrics   `json:"resourceMetrics"`
	CompletedIndexes   string            `json:"completedIndexes,omitempty"`
	Conditions         []JobCondition    `json:"conditions"`
	Generation         int64             `json:"generation"`
	ObservedGeneration int64             `json:"observedGeneration"`
	Suspended          bool              `json:"suspended"`
	CreationTime       *time.Time        `json:"creationTime"`
	Parallelism        *int32            `json:"parallelism,omitempty"`
	Completions        *int32            `json:"completions,omitempty"`
	BackoffLimit       *int32            `json:"backoffLimit,omitempty"`
	Resources          ResourceMetrics   `json:"resources,omitempty"`
}
// NetworkingMetrics represents metrics for networking resources
type NetworkingMetrics struct {
	Services        []ServiceMetrics       `json:"services"`
	Ingresses       []IngressMetrics       `json:"ingresses"`
	NetworkPolicies []NetworkPolicyMetrics `json:"networkPolicies"`
}
// ServiceMetrics represents metrics for a service
type ServiceMetrics struct {
	Name                  string            `json:"name"`
	Namespace             string            `json:"namespace"`
	Type                  string            `json:"type"`
	ClusterIP             string            `json:"clusterIP"`
	ExternalIP            []string          `json:"externalIP,omitempty"`
	LoadBalancerIP        string            `json:"loadBalancerIP,omitempty"`
	LoadBalancerIngress   []string          `json:"loadBalancerIngress,omitempty"`
	Ports                 []ServicePort     `json:"ports"`
	Selector              map[string]string `json:"selector,omitempty"`
	Labels                map[string]string `json:"labels"`
	SessionAffinity       string            `json:"sessionAffinity,omitempty"`
	ExternalTrafficPolicy string            `json:"externalTrafficPolicy,omitempty"`
	HealthCheckNodePort   int32             `json:"healthCheckNodePort,omitempty"`
	IPFamilies            []string          `json:"ipFamilies,omitempty"`
	IPFamilyPolicy        string            `json:"ipFamilyPolicy,omitempty"`
	Status                ServiceStatus     `json:"status"`
	Annotations           map[string]string `json:"annotations"`
}
// ServicePort represents a port exposed by a service
type ServicePort struct {
	Name       string `json:"name,omitempty"`
	Protocol   string `json:"protocol"`
	Port       int32  `json:"port"`
	TargetPort string `json:"targetPort"`
	NodePort   int32  `json:"nodePort,omitempty"`
}
// IngressMetrics represents metrics for an ingress
type IngressMetrics struct {
	Name                string            `json:"name"`
	Namespace           string            `json:"namespace"`
	ClassName           string            `json:"className,omitempty"`
	Rules               []IngressRule     `json:"rules"`
	TLS                 []IngressTLS      `json:"tls,omitempty"`
	LoadBalancerIngress []string          `json:"loadBalancerIngress,omitempty"`
	Labels              map[string]string `json:"labels"`
	Annotations         map[string]string `json:"annotations"`
	Status              IngressStatus     `json:"status"`
	CreationTimestamp   *time.Time        `json:"creationTimestamp"`
}
// IngressRule represents a rule in an ingress
type IngressRule struct {
	Host  string        `json:"host,omitempty"`
	Paths []IngressPath `json:"paths"`
}
// IngressPath represents a path in an ingress rule
type IngressPath struct {
	Path     string         `json:"path"`
	PathType string         `json:"pathType"`
	Backend  IngressBackend `json:"backend"`
}
// IngressBackend represents a backend for an ingress path
type IngressBackend struct {
	Service IngressServiceBackend `json:"service"`
}
// IngressServiceBackend represents a service backend for an ingress
type IngressServiceBackend struct {
	Name string `json:"name"`
	Port int32  `json:"port"`
}
// IngressTLS represents TLS configuration for an ingress
type IngressTLS struct {
	Hosts      []string `json:"hosts"`
	SecretName string   `json:"secretName"`
}
// CronJobMetrics represents metrics for a CronJob
type CronJobMetrics struct {
	Name       string            `json:"name"`
	Namespace  string            `json:"namespace"`
	Schedule   string            `json:"schedule"`
	Labels     map[string]string `json:"labels"`
	Status     CronJobStatus     `json:"status"`
	Spec       CronJobSpec       `json:"spec"`
	JobMetrics []JobMetrics      `json:"jobs,omitempty"`
}
// CronJobStatus represents the status of a CronJob
type CronJobStatus struct {
	LastScheduleTime   *time.Time `json:"lastScheduleTime,omitempty"`
	LastSuccessfulTime *time.Time `json:"lastSuccessfulTime,omitempty"`
	NextScheduledTime  *time.Time `json:"nextScheduledTime,omitempty"`
	Active             int        `json:"active"`
	SuccessRate        float64    `json:"successRate"`
}
// CronJobSpec represents the specification of a CronJob
type CronJobSpec struct {
	Suspend                    bool   `json:"suspend"`
	Concurrency                string `json:"concurrencyPolicy"`
	StartingDeadlineSeconds    int64  `json:"startingDeadlineSeconds"`
	SuccessfulJobsHistoryLimit int32  `json:"successfulJobsHistoryLimit"`
	FailedJobsHistoryLimit     int32  `json:"failedJobsHistoryLimit"`
}
// HPAMetrics represents metrics for a horizontal pod autoscaler
type HPAMetrics struct {
	Name                            string            `json:"name"`
	Namespace                       string            `json:"namespace"`
	ScaleTargetRef                  ScaleTargetRef    `json:"scaleTargetRef"`
	MinReplicas                     *int32            `json:"minReplicas,omitempty"`
	MaxReplicas                     int32             `json:"maxReplicas"`
	CurrentReplicas                 int32             `json:"currentReplicas"`
	DesiredReplicas                 int32             `json:"desiredReplicas"`
	CurrentCPUUtilizationPercentage *int32            `json:"currentCPUUtilizationPercentage,omitempty"`
	TargetCPUUtilizationPercentage  *int32            `json:"targetCPUUtilizationPercentage,omitempty"`
	LastScaleTime                   *time.Time        `json:"lastScaleTime,omitempty"`
	ObservedGeneration              *int64            `json:"observedGeneration,omitempty"`
	Status                          HPAStatus         `json:"status"`
	Labels                          map[string]string `json:"labels"`
	Annotations                     map[string]string `json:"annotations"`
}
// ScaleTargetRef represents the target reference for scaling
type ScaleTargetRef struct {
	Kind       string `json:"kind"`
	Name       string `json:"name"`
	APIVersion string `json:"apiVersion"`
}
// HPAStatus represents the status of the HPA
type HPAStatus struct {
	CurrentReplicas                 int32      `json:"currentReplicas"`
	DesiredReplicas                 int32      `json:"desiredReplicas"`
	CurrentCPUUtilizationPercentage *int32     `json:"currentCPUUtilizationPercentage,omitempty"`
	LastScaleTime                   *time.Time `json:"lastScaleTime,omitempty"`
}
// ReplicaSetMetrics represents metrics for a replica set
type ReplicaSetMetrics struct {
	Name                 string            `json:"name"`
	Namespace            string            `json:"namespace"`
	Replicas             int32             `json:"replicas"`
	ReadyReplicas        int32             `json:"readyReplicas"`
	AvailableReplicas    int32             `json:"availableReplicas"`
	CurrentReplicas      int32             `json:"currentReplicas"`
	FullyLabeledReplicas int32             `json:"fullyLabeledReplicas"`
	ObservedGeneration   int64             `json:"observedGeneration"`
	Conditions           []RSCondition     `json:"conditions"`
	Labels               map[string]string `json:"labels"`
	Annotations          map[string]string `json:"annotations"`
	CreationTimestamp    *time.Time        `json:"creationTimestamp"`
}
// RSCondition represents a condition of a ReplicaSet
type RSCondition struct {
	Type               string     `json:"type"`
	Status             string     `json:"status"`
	LastTransitionTime *time.Time `json:"lastTransitionTime,omitempty"`
	Reason             string     `json:"reason,omitempty"`
	Message            string     `json:"message,omitempty"`
}
// ReplicationControllerMetrics represents metrics for a replication controller
type ReplicationControllerMetrics struct {
	Name              string            `json:"name"`
	Namespace         string            `json:"namespace"`
	Replicas          int32             `json:"replicas"`
	ReadyReplicas     int32             `json:"readyReplicas"`
	AvailableReplicas int32             `json:"availableReplicas"`
	Labels            map[string]string `json:"labels"`
	// Adding missing fields
	ObservedGeneration   int64             `json:"observedGeneration"`
	FullyLabeledReplicas int32             `json:"fullyLabeledReplicas"`
	Conditions           []RCCondition     `json:"conditions"`
	Annotations          map[string]string `json:"annotations"`
	CreationTimestamp    *time.Time        `json:"creationTimestamp"`
}
// RCCondition represents a condition of a ReplicationController
type RCCondition struct {
	Type               string     `json:"type"`
	Status             string     `json:"status"`
	LastTransitionTime *time.Time `json:"lastTransitionTime,omitempty"`
	Reason             string     `json:"reason,omitempty"`
	Message            string     `json:"message,omitempty"`
}
// NodeDetailedMetrics represents detailed metrics collected for a node
type NodeDetailedMetrics struct {
	CPU        CPUMetrics     `json:"cpu"`
	Memory     MemoryMetrics  `json:"memory"`
	Network    NetworkMetrics `json:"network"`
	DiskIO     DiskMetrics    `json:"diskIO"`
	Filesystem FSMetrics      `json:"filesystem"`
	Process    ProcessMetrics `json:"process"`
	Runtime    RuntimeMetrics `json:"runtime"`
	System     SystemMetrics  `json:"system"`
	Volume     VolumeMetrics  `json:"volume"`
	Container  ContainerStats `json:"container"`
}
// CPUMetrics represents CPU metrics from cadvisor
type CPUMetrics struct {
	// Usage values in nanoseconds
	UsageTotal     uint64            `json:"usageTotal"`
	UsageUser      uint64            `json:"usageUser"`
	UsageSystem    uint64            `json:"usageSystem"`
	SystemTime     uint64            `json:"systemTime"`
	UserTime       uint64            `json:"userTime"`
	LoadAverage    LoadAverageStats  `json:"loadAverage"`
	SchedulerStats SchedulerMetrics  `json:"schedulerStats"`
	Throttling     ThrottlingMetrics `json:"throttling"`
	// Per-core CPU metrics
	PerCoreUsage map[string]uint64 `json:"perCoreUsage,omitempty"`
	// Add new fields for detailed CPU metrics
	CPUPressure float64    `json:"cpuPressure,omitempty"`
	SchedStats  SchedStats `json:"schedStats,omitempty"`
}
// LoadAverageStats represents CPU load averages
type LoadAverageStats struct {
	Load1  float64 `json:"load1"`
	Load5  float64 `json:"load5"`
	Load15 float64 `json:"load15"`
}
// SchedulerMetrics represents CPU scheduler statistics
type SchedulerMetrics struct {
	RunQueueLength   uint64 `json:"runQueueLength"`
	ContextSwitches  uint64 `json:"contextSwitches"`
	ProcessesCreated uint64 `json:"processesCreated"`
	ProcessesRunning uint64 `json:"processesRunning"`
	ProcessesBlocked uint64 `json:"processesBlocked"`
}
// ThrottlingMetrics represents CPU throttling information
type ThrottlingMetrics struct {
	Periods          uint64 `json:"periods"`
	ThrottledPeriods uint64 `json:"throttledPeriods"`
	ThrottledTime    uint64 `json:"throttledTime"`
}
// MemoryMetrics represents memory statistics
type MemoryMetrics struct {
	// All values in bytes
	Total           uint64  `json:"total"`
	Available       uint64  `json:"available"`
	Used            uint64  `json:"used"`
	WorkingSet      uint64  `json:"workingSet"`
	RSS             uint64  `json:"rss"`
	Cache           uint64  `json:"cache"`
	Swap            uint64  `json:"swap"`
	PageFaults      uint64  `json:"pageFaults"`
	KernelUsage     uint64  `json:"kernelUsage,omitempty"`
	OOMEvents       uint64  `json:"oomEvents"`
	OOMKills        uint64  `json:"oomKills"`
	PressureLevel   float64 `json:"pressureLevel"`
	SwapInBytes     uint64  `json:"swapInBytes"`
	SwapOutBytes    uint64  `json:"swapOutBytes"`
	MajorPageFaults uint64  `json:"majorPageFaults"`
	MinorPageFaults uint64  `json:"minorPageFaults"`
}
// NetworkMetrics represents network statistics
// Note: Metric availability depends on CNI plugin and network configuration
type NetworkMetrics struct {
	// Basic network metrics - generally available
	Summary NetworkSummary `json:"summary"`
	// Detailed interface metrics - availability varies by platform and CNI
	Interfaces []InterfaceStats `json:"interfaces,omitempty"`
}
// InterfaceStats represents per-interface network statistics
type InterfaceStats struct {
	InterfaceName string `json:"interfaceName"`
	RxBytes       uint64 `json:"rxBytes"`
	TxBytes       uint64 `json:"txBytes"`
	RxPackets     uint64 `json:"rxPackets"`
	TxPackets     uint64 `json:"txPackets"`
	RxErrors      uint64 `json:"rxErrors"`
	TxErrors      uint64 `json:"txErrors"`
	RxDropped     uint64 `json:"rxDropped"`
	TxDropped     uint64 `json:"txDropped"`
}
// NetworkSummary represents aggregated network statistics
type NetworkSummary struct {
	RxBytesTotal          uint64
	TxBytesTotal          uint64
	ContainerRxBytesTotal uint64
	ContainerTxBytesTotal uint64
}
// FSMetrics represents filesystem metrics
type FSMetrics struct {
	// Capacity and usage information
	TotalBytes     uint64 `json:"totalBytes"`
	UsedBytes      uint64 `json:"usedBytes"`
	AvailableBytes uint64 `json:"availableBytes"`
	// Inode information
	TotalInodes uint64 `json:"totalInodes"`
	UsedInodes  uint64 `json:"usedInodes"`
	FreeInodes  uint64 `json:"freeInodes"`
	// Per-device statistics
	DeviceStats map[string]FSStats `json:"deviceStats"`
	// Add inode metrics
	Inodes InodeStats `json:"inodes"`
}
// FSStats represents per-device filesystem statistics
type FSStats struct {
	Major       uint64 `json:"major"`
	Minor       uint64 `json:"minor"`
	ReadOps     uint64 `json:"readOps"`
	WriteOps    uint64 `json:"writeOps"`
	ReadBytes   uint64 `json:"readBytes"`
	WriteBytes  uint64 `json:"writeBytes"`
	ReadTimeMs  uint64 `json:"readTimeMs"`
	WriteTimeMs uint64 `json:"writeTimeMs"`
	IoTimeMs    uint64 `json:"ioTimeMs"`
}
// ContainerStats represents container-specific metrics
type ContainerStats struct {
	RunningCount int                         `json:"runningCount"`
	TotalCount   int                         `json:"totalCount"`
	PerContainer map[string]ContainerMetrics `json:"perContainer"`
}
// GPUMetrics represents GPU device metrics if available
type GPUMetrics struct {
	DeviceID    string          `json:"deviceId"`
	MemoryTotal uint64          `json:"memoryTotal"`
	MemoryUsed  uint64          `json:"memoryUsed"`
	OptMetrics  OptionalMetrics `json:"optionalMetrics,omitempty"`
}
// OptionalMetrics represents optional metrics for GPU devices
type OptionalMetrics struct {
	DutyCycle   float64 `json:"dutyCycle"`
	Temperature float64 `json:"temperature"`
	PowerUsage  float64 `json:"powerUsage"`
}
// ProcessMetrics represents process-related metrics
type ProcessMetrics struct {
	ProcessCount int `json:"processCount"`
	ThreadCount  int `json:"threadCount,omitempty"`
	FDCount      int `json:"fdCount,omitempty"`
}
// RuntimeMetrics represents container runtime metrics
type RuntimeMetrics struct {
	Operations map[string]RuntimeOperation `json:"operations"`
}
// RuntimeOperation represents a runtime operation metric
type RuntimeOperation struct {
	Type   string `json:"type"`
	Count  uint64 `json:"count"`
	Errors uint64 `json:"errors"`
}
// ImageStats represents container image statistics
type ImageStats struct {
	// Total number of images
	TotalCount int `json:"totalCount"`
	// Total size of all images in bytes
	TotalSizeBytes uint64 `json:"totalSizeBytes"`
}
// ContainerMetrics represents metrics for a single container
// Note: Some metrics may not be available depending on the container runtime
type ContainerMetrics struct {
	// Required fields - always available
	Name      string    `json:"name"`
	ID        string    `json:"id"`
	State     string    `json:"state"`
	StartTime time.Time `json:"startTime"`
	// Basic resource usage - generally available
	UsageNanos int64 `json:"usageNanos"` // CPU usage in nanoseconds
	UsageBytes int64 `json:"usageBytes"` // Memory usage in bytes
	// Detailed metrics - availability varies by runtime and platform
	CPU struct {
		UsageTotal  uint64 `json:"usageTotal"`
		UsageUser   uint64 `json:"usageUser,omitempty"`
		UsageSystem uint64 `json:"usageSystem,omitempty"`
		Throttling  *struct {
			Periods          uint64 `json:"periods"`
			ThrottledPeriods uint64 `json:"throttledPeriods"`
			ThrottledTime uint64 `json:"throttledTime"`
		} `json:"throttling,omitempty"`
	} `json:"cpu"`
	// Optional fields - may not be available in all environments
	LastTerminationReason string          `json:"lastTerminationReason,omitempty"`
	BlockIO               *BlockIOMetrics `json:"blockIO,omitempty"`
	RestartCount          int32           `json:"restartCount"`
	Ready                 bool            `json:"ready"`
	Memory                MemoryMetrics   `json:"memory"`
}
// BlockIOMetrics represents block I/O metrics
type BlockIOMetrics struct {
	// Read operations
	ReadOps uint64 `json:"readOps"`
	// Write operations
	WriteOps uint64 `json:"writeOps"`
	// Bytes read
	ReadBytes uint64 `json:"readBytes"`
	// Bytes written
	WriteBytes uint64 `json:"writeBytes"`
}
// DiskMetrics represents disk I/O metrics
type DiskMetrics struct {
	ReadBytes  int64           // Total bytes read across all devices
	WriteBytes int64           // Total bytes written across all devices
	Devices    []NodeDiskStats // Per-device statistics
}
// ServiceStatus represents the status of a Kubernetes service
type ServiceStatus struct {
	LoadBalancer LoadBalancerStatus `json:"loadBalancer"`
	Conditions   []ServiceCondition `json:"conditions"`
}
// ServiceCondition represents the current condition of a Kubernetes service
type ServiceCondition struct {
	Type               string     `json:"type"`
	Status             string     `json:"status"`
	LastTransitionTime *time.Time `json:"lastTransitionTime,omitempty"`
	Reason             string     `json:"reason,omitempty"`
	Message            string     `json:"message,omitempty"`
}
// LoadBalancerStatus represents the status of a Kubernetes load balancer
type LoadBalancerStatus struct {
	Ingress []LoadBalancerIngress `json:"ingress,omitempty"`
}
// LoadBalancerIngress represents the ingress point for a Kubernetes load balancer
type LoadBalancerIngress struct {
	IP       string `json:"ip,omitempty"`
	Hostname string `json:"hostname,omitempty"`
}
// IngressStatus represents the status of a Kubernetes ingress
type IngressStatus struct {
	LoadBalancer LoadBalancerStatus `json:"loadBalancer"`
}
// IngressCondition represents the current condition of a Kubernetes ingress
type IngressCondition struct {
	Type               string     `json:"type"`
	Status             string     `json:"status"`
	LastTransitionTime *time.Time `json:"lastTransitionTime,omitempty"`
	Reason             string     `json:"reason,omitempty"`
	Message            string     `json:"message,omitempty"`
}
// SystemMetrics represents system-level metrics
// Note: Availability of these metrics depends on the host system configuration
type SystemMetrics struct {
	UptimeSeconds   float64 `json:"uptimeSeconds"`
	NumCPUs         int64   `json:"numCPUs"`
	NumProcs        uint64  `json:"numProcs"`
	BootTimeSeconds float64 `json:"bootTimeSeconds"`
	// Platform-specific fields - may not be available in all environments
	KernelVersion string `json:"kernelVersion,omitempty"`
	OSVersion     string `json:"osVersion,omitempty"`
	// These IDs may not be available on all platforms
	MachineID  string `json:"machineID,omitempty"`
	SystemUUID string `json:"systemUUID,omitempty"`
	BootID     string `json:"bootID,omitempty"`
}
// KubeletMetrics represents kubelet-related metrics
// Note: Metric availability depends on Kubelet version and configuration
type KubeletMetrics struct {
	// Basic metrics - generally available
	PodStartLatency LatencyMetric `json:"podStartLatency"`
	// Advanced metrics - may not be available in all configurations
	OperationLatency  map[string]LatencyMetric   `json:"operationLatency,omitempty"`
	CGroupManager     *CGroupManagerMetrics      `json:"cgroupManager,omitempty"`
	PLEGLatency       *LatencyMetric             `json:"plegLatency,omitempty"`
	RuntimeOperations map[string]RuntimeOpMetric `json:"runtimeOperations,omitempty"`
	EvictionStats     *EvictionStats             `json:"evictionStats,omitempty"`
}
// LatencyMetric represents latency metrics
type LatencyMetric struct {
	P50   float64 `json:"p50"`
	P90   float64 `json:"p90"`
	P99   float64 `json:"p99"`
	Count int64   `json:"count"`
}
// CGroupManagerMetrics represents cgroup manager metrics
type CGroupManagerMetrics struct {
	Operations uint64        `json:"operations"`
	Errors     uint64        `json:"errors"`
	Latency    LatencyMetric `json:"latency"`
}
// RuntimeOpMetric represents runtime operation metrics
type RuntimeOpMetric struct {
	Count    uint64  `json:"count"`
	Errors   uint64  `json:"errors"`
	Duration float64 `json:"duration"`
}
// EvictionStats represents eviction statistics
type EvictionStats struct {
	ThresholdMet      bool       `json:"thresholdMet"`
	HardEvictionCount uint64     `json:"hardEvictionCount"`
	SoftEvictionCount uint64     `json:"softEvictionCount"`
	LastEvictionTime  *time.Time `json:"lastEvictionTime,omitempty"`
}
// VolumeMetrics represents volume-related metrics
type VolumeMetrics struct {
	AttachDetachCount  uint64                   `json:"attachDetachCount"`
	InUseCount         uint64                   `json:"inUseCount"`
	OperationLatency   map[string]LatencyMetric `json:"operationLatency"`
	TotalCapacityBytes uint64                   `json:"totalCapacityBytes"`
	AvailableBytes     uint64                   `json:"availableBytes"`
	UsedBytes          uint64                   `json:"usedBytes"`
}
// PodReadinessGate represents a readiness gate for a pod
type PodReadinessGate struct {
	ConditionType string `json:"conditionType"`
	Status        bool   `json:"status"`
}
// JobCondition represents a condition of a Job
type JobCondition struct {
	Type               string     `json:"type"`
	Status             string     `json:"status"`
	LastProbeTime      *time.Time `json:"lastProbeTime,omitempty"`
	LastTransitionTime *time.Time `json:"lastTransitionTime,omitempty"`
	Reason             string     `json:"reason,omitempty"`
	Message            string     `json:"message,omitempty"`
}
// DaemonSetStatus represents the status of a DaemonSet
type DaemonSetStatus struct {
	ObservedGeneration int64 `json:"observedGeneration"`
}
// DaemonSetCondition represents a condition of a DaemonSet
type DaemonSetCondition struct {
	Type               string     `json:"type"`
	Status             string     `json:"status"`
	LastTransitionTime *time.Time `json:"lastTransitionTime,omitempty"`
	Reason             string     `json:"reason,omitempty"`
	Message            string     `json:"message,omitempty"`
}
// NodeInfo represents node information
type NodeInfo struct {
	Architecture            string `json:"architecture"`
	ContainerRuntimeVersion string `json:"containerRuntimeVersion"`
	KernelVersion           string `json:"kernelVersion"`
	OSImage                 string `json:"osImage"`
	KubeletVersion          string `json:"kubeletVersion"`
}
// NodeNetworkStats represents network metrics for a node
type NodeNetworkStats struct {
	InterfaceName string `json:"interfaceName"`
	RxBytes       uint64 `json:"rxBytes"`
	RxPackets     uint64 `json:"rxPackets"`
	RxErrors      uint64 `json:"rxErrors"`
	RxDropped     uint64 `json:"rxDropped"`
	TxBytes       uint64 `json:"txBytes"`
	TxPackets     uint64 `json:"txPackets"`
	TxErrors      uint64 `json:"txErrors"`
	TxDropped     uint64 `json:"txDropped"`
}
// NodeDiskStats represents disk metrics for a node
type NodeDiskStats struct {
	Device         string `json:"device"`
	ReadOps        uint64 `json:"readOps"`
	WriteOps       uint64 `json:"writeOps"`
	ReadBytes      uint64 `json:"readBytes"`
	WriteBytes     uint64 `json:"writeBytes"`
	ReadLatency    uint64 `json:"readLatency"`
	WriteLatency   uint64 `json:"writeLatency"`
	IoInProgress   uint64 `json:"ioInProgress"`
	IoTime         uint64 `json:"ioTime"`
	WeightedIoTime uint64 `json:"weightedIoTime"`
}
// InodeStats represents inode metrics
type InodeStats struct {
	Total uint64 `json:"total"`
	Used  uint64 `json:"used"`
	Free  uint64 `json:"free"`
}
// VolumeMountMetrics represents volume mount metrics
type VolumeMountMetrics struct {
	Name             string `json:"name"`
	MountPath        string `json:"mountPath"`
	ReadOnly         bool   `json:"readOnly,omitempty"`
	SubPath          string `json:"subPath,omitempty"`
	SubPathExpr      string `json:"subPathExpr,omitempty"`
	MountPropagation string `json:"mountPropagation,omitempty"`
}
// NetworkPolicyMetrics represents metrics for networking resources
type NetworkPolicyMetrics struct {
	Name        string                     `json:"name"`
	Namespace   string                     `json:"namespace"`
	Labels      map[string]string          `json:"labels"`
	Annotations map[string]string          `json:"annotations"`
	PodSelector map[string]string          `json:"podSelector"`
	Ingress     []NetworkPolicyIngressRule `json:"ingress"`
	Egress      []NetworkPolicyEgressRule  `json:"egress"`
	PolicyTypes []string                   `json:"policyTypes"`
}
// NetworkPolicyIngressRule represents an ingress rule in a network policy
type NetworkPolicyIngressRule struct {
	Ports []NetworkPolicyPort `json:"ports"`
	From  []NetworkPolicyPeer `json:"from"`
}
// NetworkPolicyEgressRule represents an egress rule in a network policy
type NetworkPolicyEgressRule struct {
	Ports []NetworkPolicyPort `json:"ports"`
	To    []NetworkPolicyPeer `json:"to"`
}
// NetworkPolicyPort represents a port in a network policy
type NetworkPolicyPort struct {
	Protocol string `json:"protocol"`
	Port     int32  `json:"port"`
}
// NetworkPolicyPeer represents a peer in a network policy
type NetworkPolicyPeer struct {
	PodSelector       map[string]string `json:"podSelector,omitempty"`
	NamespaceSelector map[string]string `json:"namespaceSelector,omitempty"`
	IPBlock           *IPBlock          `json:"ipBlock,omitempty"`
}
// IPBlock represents an IP block in a network policy
type IPBlock struct {
	CIDR   string   `json:"cidr"`
	Except []string `json:"except,omitempty"`
}
// StorageClassMetrics represents metrics for storage classes
type StorageClassMetrics struct {
	Name                 string            `json:"name"`
	Provisioner          string            `json:"provisioner"`
	ReclaimPolicy        string            `json:"reclaimPolicy"`
	VolumeBindingMode    string            `json:"volumeBindingMode"`
	AllowVolumeExpansion bool              `json:"allowVolumeExpansion"`
	Labels               map[string]string `json:"labels"`
	Annotations          map[string]string `json:"annotations"`
	IsDefault            bool              `json:"isDefault"`
	Parameters           map[string]string `json:"parameters"`
	MountOptions         []string          `json:"mountOptions,omitempty"`
	CreationTimestamp    *time.Time        `json:"creationTimestamp"`
	// New fields for CSI and capacity metrics
	CSIDriver           *CSIDriverMetrics    `json:"csiDriver,omitempty"`
	StoragePools        []StoragePoolMetrics `json:"storagePools,omitempty"`
	TotalCapacity       int64                `json:"totalCapacity,omitempty"`
	AllocatedCapacity   int64                `json:"allocatedCapacity,omitempty"`
	AvailableCapacity   int64                `json:"availableCapacity,omitempty"`
	CapacityUtilization float64              `json:"capacityUtilization,omitempty"`
	ProvisionedPVCs     int32                `json:"provisionedPVCs,omitempty"`
	ProvisioningRate    float64              `json:"provisioningRate,omitempty"`
}
// HardwareTopology represents the hardware topology of a node
type HardwareTopology struct {
	Sockets int64 `json:"sockets,omitempty"`
	Cores   int64 `json:"cores,omitempty"`
	Threads int64 `json:"threads,omitempty"`
	// NUMA topology
	NUMANodes []NUMANode `json:"numaNodes,omitempty"`
}
// NUMANode represents NUMA node information
type NUMANode struct {
	ID       int32    `json:"id"`
	Memory   uint64   `json:"memory,omitempty"`   // Memory in bytes
	CPUList  []int32  `json:"cpuList,omitempty"`  // List of CPU IDs
	Distance []uint32 `json:"distance,omitempty"` // NUMA distance array
}
// PowerMetrics represents power management information
type PowerMetrics struct {
	CurrentWatts float64 `json:"currentWatts,omitempty"`
	MaxWatts     float64 `json:"maxWatts,omitempty"`
	// Power capping information
	PowerCap     *float64 `json:"powerCap,omitempty"`
	PowerProfile string   `json:"powerProfile,omitempty"`
}
// NodeTaint represents a Kubernetes node taint
type NodeTaint struct {
	Key       string     `json:"key"`
	Value     string     `json:"value,omitempty"`
	Effect    string     `json:"effect"`
	TimeAdded *time.Time `json:"timeAdded,omitempty"`
}
// NodeLease represents node lease information
type NodeLease struct {
	HolderIdentity       string     `json:"holderIdentity"`
	LeaseDurationSeconds int32      `json:"leaseDurationSeconds"`
	AcquireTime          *time.Time `json:"acquireTime,omitempty"`
	RenewTime            *time.Time `json:"renewTime,omitempty"`
}
// ExtendedResource represents custom resource information
type ExtendedResource struct {
	Name        string `json:"name"`
	Capacity    string `json:"capacity"`
	Allocatable string `json:"allocatable"`
	Used        string `json:"used,omitempty"`
}
// PodDisruptionBudgetMetrics represents PDB metrics
type PodDisruptionBudgetMetrics struct {
	MinAvailable       string `json:"minAvailable,omitempty"`
	MaxUnavailable     string `json:"maxUnavailable,omitempty"`
	CurrentHealthy     int32  `json:"currentHealthy"`
	DesiredHealthy     int32  `json:"desiredHealthy"`
	DisruptionsAllowed int32  `json:"disruptionsAllowed"`
	ExpectedPods       int32  `json:"expectedPods"`
}
// TopologySpreadConstraint represents pod topology spread constraints
type TopologySpreadConstraint struct {
	MaxSkew           int32  `json:"maxSkew"`
	TopologyKey       string `json:"topologyKey"`
	WhenUnsatisfiable string `json:"whenUnsatisfiable"`
	LabelSelector     string `json:"labelSelector,omitempty"`
	MinDomains        *int32 `json:"minDomains,omitempty"`
}
// PodOverheadMetrics represents pod overhead metrics
type PodOverheadMetrics struct {
	CPU    string `json:"cpu,omitempty"`
	Memory string `json:"memory,omitempty"`
}
// PodSchedulingGate represents pod scheduling gates
type PodSchedulingGate struct {
	Name   string     `json:"name"`
	Active bool       `json:"active"`
	Since  *time.Time `json:"since,omitempty"`
}
// AffinityMetrics represents pod affinity/anti-affinity rules
type AffinityMetrics struct {
	NodeAffinity    []NodeAffinityTerm `json:"nodeAffinity,omitempty"`
	PodAffinity     []PodAffinityTerm  `json:"podAffinity,omitempty"`
	PodAntiAffinity []PodAffinityTerm  `json:"podAntiAffinity,omitempty"`
}
// NodeAffinityTerm represents a node affinity requirement
type NodeAffinityTerm struct {
	Key      string   `json:"key"`
	Operator string   `json:"operator"`
	Values   []string `json:"values,omitempty"`
}
// PodAffinityTerm represents a pod affinity/anti-affinity requirement
type PodAffinityTerm struct {
	LabelSelector string   `json:"labelSelector"`
	Namespaces    []string `json:"namespaces,omitempty"`
	TopologyKey   string   `json:"topologyKey"`
}
// InitContainerMetrics represents init container specific metrics
type InitContainerMetrics struct {
	ContainerMetrics
	CompletionTime *time.Time `json:"completionTime,omitempty"`
	Duration       float64    `json:"duration,omitempty"`
}
// EphemeralContainerMetrics represents ephemeral container metrics
type EphemeralContainerMetrics struct {
	ContainerMetrics
	TargetContainerName string     `json:"targetContainerName"`
	StartTime           *time.Time `json:"startTime,omitempty"`
}
// QoSMetrics represents detailed QoS metrics
type QoSMetrics struct {
	Class            string  `json:"class"`
	CPUGuaranteed    bool    `json:"cpuGuaranteed"`
	MemoryGuaranteed bool    `json:"memoryGuaranteed"`
	BurstableLimit   float64 `json:"burstableLimit,omitempty"`
}
// CSIDriverMetrics represents CSI driver metrics
type CSIDriverMetrics struct {
	Name               string            `json:"name"`
	Version            string            `json:"version,omitempty"`
	Available          bool              `json:"available"`
	VolumeSnapshotting bool              `json:"volumeSnapshotting,omitempty"`
	VolumeCloning      bool              `json:"volumeCloning,omitempty"`
	VolumeExpansion    bool              `json:"volumeExpansion,omitempty"`
	NodePluginPods     map[string]string `json:"nodePluginPods,omitempty"`
	ControllerPods     map[string]string `json:"controllerPods,omitempty"`
	OperationStats     map[string]int64  `json:"operationStats,omitempty"`
}
// StoragePoolMetrics represents storage pool metrics
type StoragePoolMetrics struct {
	Name           string  `json:"name"`
	Provider       string  `json:"provider"`
	TotalCapacity  int64   `json:"totalCapacity"`
	UsedCapacity   int64   `json:"usedCapacity"`
	AvailableSpace int64   `json:"availableSpace"`
	VolumeCount    int32   `json:"volumeCount,omitempty"`
	UtilizationPct float64 `json:"utilizationPct,omitempty"`
	Health         string  `json:"health,omitempty"`
	StorageClass   string  `json:"storageClass"`
}
// VolumeHealthMetrics represents volume health status
type VolumeHealthMetrics struct {
	VolumeName     string    `json:"volumeName"`
	PodName        string    `json:"podName,omitempty"`
	Namespace      string    `json:"namespace,omitempty"`
	State          string    `json:"state"`
	LastCheckTime  time.Time `json:"lastCheckTime"`
	ErrorMessage   string    `json:"errorMessage,omitempty"`
	RepairRequired bool      `json:"repairRequired,omitempty"`
	IoPerformance  string    `json:"ioPerformance,omitempty"`
	FsIntegrity    bool      `json:"fsIntegrity,omitempty"`
}
// VolumeAttachmentMetrics represents volume attachment status
type VolumeAttachmentMetrics struct {
	VolumeName      string    `json:"volumeName"`
	PodName         string    `json:"podName,omitempty"`
	Namespace       string    `json:"namespace,omitempty"`
	AttachTime      time.Time `json:"attachTime"`
	DevicePath      string    `json:"devicePath,omitempty"`
	AttachmentState string    `json:"attachmentState"`
	ReadOnly        bool      `json:"readOnly"`
	MountPoint      string    `json:"mountPoint,omitempty"`
	AttachError     string    `json:"attachError,omitempty"`
}
// NodeVolumeMetrics represents node volume metrics
type NodeVolumeMetrics struct {
	// Existing fields
	InUseCount       uint64                   `json:"inUseCount"`
	OperationLatency map[string]LatencyMetric `json:"operationLatency,omitempty"`
	// New fields
	VolumeHealth      []VolumeHealthMetrics     `json:"volumeHealth,omitempty"`
	VolumeAttachments []VolumeAttachmentMetrics `json:"volumeAttachments,omitempty"`
	AttachLimit       int32                     `json:"attachLimit,omitempty"`
	AttachCount       int32                     `json:"attachCount"`
	AttachErrors      uint64                    `json:"attachErrors,omitempty"`
	DetachErrors      uint64                    `json:"detachErrors,omitempty"`
}
// VolumeSnapshotMetrics represents snapshot information for a volume
type VolumeSnapshotMetrics struct {
	Name         string     `json:"name"`
	Namespace    string     `json:"namespace,omitempty"`
	SourcePVName string     `json:"sourcePVName"`
	CreationTime time.Time  `json:"creationTime"`
	Size         int64      `json:"size"`
	ReadyToUse   bool       `json:"readyToUse"`
	RestoreSize  int64      `json:"restoreSize,omitempty"`
	DeletionTime *time.Time `json:"deletionTime,omitempty"`
	Error        string     `json:"error,omitempty"`
}
// VolumeExpansionMetrics represents volume expansion metrics
type VolumeExpansionMetrics struct {
	CurrentSize    int64      `json:"currentSize"`
	RequestedSize  int64      `json:"requestedSize"`
	InProgress     bool       `json:"inProgress"`
	LastResizeTime *time.Time `json:"lastResizeTime,omitempty"`
	ResizeStatus   string     `json:"resizeStatus,omitempty"`
	FailureMessage string     `json:"failureMessage,omitempty"`
}
// QuotaScopeMetrics represents quota scope information
type QuotaScopeMetrics struct {
	ScopeName   string            `json:"scopeName"`
	Resources   []string          `json:"resources,omitempty"`
	MatchLabels map[string]string `json:"matchLabels,omitempty"`
	MatchScopes []string          `json:"matchScopes,omitempty"`
}
// PriorityClassQuotaMetrics represents quota metrics for priority classes
type PriorityClassQuotaMetrics struct {
	PriorityClass string            `json:"priorityClass"`
	Hard          map[string]string `json:"hard,omitempty"`
	Used          map[string]string `json:"used,omitempty"`
}
// QuotaStatusHistory represents historical quota status
type QuotaStatusHistory struct {
	Timestamp time.Time `json:"timestamp"`
	Resource  string    `json:"resource"`
	Hard      string    `json:"hard"`
	Used      string    `json:"used"`
}
// CustomResourceQuota represents quotas for custom resources
// type CustomResourceQuota struct {
// 	Group    string `json:"group"`
// 	Resource string `json:"resource"`
// 	Version  string `json:"version"`
// 	Hard     string `json:"hard,omitempty"`
// 	Used     string `json:"used,omitempty"`
// }
// SchedStats represents scheduler statistics
type SchedStats struct {
	RunQueueLength   uint64 `json:"runQueueLength"`
	WaitingProcesses uint64 `json:"waitingProcesses"`
	SleepingTasks    uint64 `json:"sleepingTasks"`
}
// PSIMetrics represents metrics for the container runtime
type PSIMetrics struct {
	CPU struct {
		Some float64 `json:"some"`
		Full float64 `json:"full"`
	} `json:"cpu"`
	Memory struct {
		Some float64 `json:"some"`
		Full float64 `json:"full"`
	} `json:"memory"`
	IO struct {
		Some float64 `json:"some"`
		Full float64 `json:"full"`
	} `json:"io"`
}
</file>

<file path="pkg/utils/auth.go">
// Package utils provides utility functions for the agent
// Copyright 2024 Vega Cloud, Inc.
//
// Use of this software is governed by the Business Source License
// included in the file licenses/BSL.txt.
//
// As of the Change Date specified in that file, in accordance with
// the Business Source License, use of this software will be governed
// by the Apache License, Version 2.0, included in the file
// licenses/APL.txt.
package utils
import (
	"context"
	"encoding/json"
	"fmt"
	"io"
	"net/http"
	"net/url"
	"strings"
	"time"
	"github.com/sirupsen/logrus"
	"github.com/vegacloud/kubernetes/metricsagent/pkg/config"
)
// AuthResponse holds the response from the auth server
type AuthResponse struct {
	AccessToken string `json:"access_token"`
	ExpiresIn   int    `json:"expires_in"`
	TokenType   string `json:"token_type"`
}
var tokenCache struct {
	token     string
	expiresAt time.Time
}
// GetVegaAuthToken gets an auth token from the auth server
func GetVegaAuthToken(
	ctx context.Context,
	client *http.Client,
	cfg *config.Config,
) (string, error) {
	// Check if the token is still valid
	if time.Now().Before(tokenCache.expiresAt) {
		return tokenCache.token, nil
	}
	authURL := fmt.Sprintf("%s/realms/%s/protocol/openid-connect/token", cfg.AuthServiceURL, cfg.VegaOrgSlug)
	logrus.WithFields(logrus.Fields{
		"function": "GetVegaAuthToken",
		"clientID": cfg.VegaClientID,
		"slug":     cfg.VegaOrgSlug,
		"url":      cfg.AuthServiceURL,
		"authURL":  authURL,
	}).Debug("Getting auth token")
	form := url.Values{
		"grant_type":    {"client_credentials"},
		"client_id":     {cfg.VegaClientID},
		"client_secret": {cfg.VegaClientSecret},
	}
	req, err := http.NewRequestWithContext(ctx, http.MethodPost, authURL, strings.NewReader(form.Encode()))
	if err != nil {
		return "", fmt.Errorf("error creating request for slug %s: %w", cfg.VegaOrgSlug, err)
	}
	req.Header.Set("Content-Type", "application/x-www-form-urlencoded")
	// Use a loop with a retry mechanism
	for i := 0; i < 3; i++ {
		resp, err := client.Do(req)
		if err != nil {
			logrus.WithFields(logrus.Fields{
				"function": "GetVegaAuthToken",
				"attempt":  i + 1,
				"error":    err,
			}).Warn("Failed to send request, retrying")
			if i == 2 {
				return "", fmt.Errorf("sending request after retries: %w", err)
			}
			time.Sleep(500 * time.Millisecond)
			continue
		}
		// Ensure response body is closed
		defer resp.Body.Close()
		// Handle non-2xx status codes
		if resp.StatusCode < 200 || resp.StatusCode > 299 {
			body, _ := io.ReadAll(resp.Body)
			logrus.WithFields(logrus.Fields{
				"function":   "GetVegaAuthToken",
				"statusCode": resp.StatusCode,
				"body":       string(body),
			}).Error("Received non-2xx status code")
			return "", fmt.Errorf("unexpected status code: %d", resp.StatusCode)
		}
		// Decode the JSON response
		var authResp AuthResponse
		if err := json.NewDecoder(resp.Body).Decode(&authResp); err != nil {
			return "", fmt.Errorf("decoding response for slug %s: %w", cfg.VegaOrgSlug, err)
		}
		logrus.WithFields(logrus.Fields{
			"function":    "GetVegaAuthToken",
			"accessToken": authResp.AccessToken,
			"expiresIn":   authResp.ExpiresIn,
		}).Debug("Auth token obtained successfully")
		// Cache the token
		tokenCache.token = authResp.AccessToken
		tokenCache.expiresAt = time.Now().Add(time.Duration(authResp.ExpiresIn) * time.Second)
		return authResp.AccessToken, nil
	}
	// Return an error if all attempts fail
	return "", fmt.Errorf("failed to obtain auth token after retries")
}
</file>

<file path="pkg/utils/k8sconfig.go">
// Package utils provides utility functions for the agent
// Copyright 2024 Vega Cloud, Inc.
//
// Use of this software is governed by the Business Source License
// included in the file licenses/BSL.txt.
//
// As of the Change Date specified in that file, in accordance with
// the Business Source License, use of this software will be governed
// by the Apache License, Version 2.0, included in the file
// licenses/APL.txt.
package utils
import (
	"context"
	"fmt"
	"os"
	"path/filepath"
	"strings"
	"sync"
	"github.com/sirupsen/logrus"
	"github.com/vegacloud/kubernetes/metricsagent/pkg/config"
	authenticationv1 "k8s.io/api/authentication/v1"
	authorizationv1 "k8s.io/api/authorization/v1"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/client-go/kubernetes"
	"k8s.io/client-go/rest"
	"k8s.io/client-go/tools/clientcmd"
)
// K8sClientConfig holds the Kubernetes clientset and configuration
type K8sClientConfig struct {
	Clientset          *kubernetes.Clientset
	Config             *rest.Config
	UseInClusterConfig bool
	ClusterHostURL     string
	Namespace          string
	ClusterUID         string
	ClusterVersion     string
}
var (
	instance *K8sClientConfig
	once     sync.Once
)
// logCurrentIdentity attempts to get and log the current service account identity
func logCurrentIdentity(ctx context.Context, clientset *kubernetes.Clientset) {
	logger := logrus.WithField("function", "logCurrentIdentity")
	// Try to get self review
	selfReview := &authenticationv1.SelfSubjectReview{}
	result, err := clientset.AuthenticationV1().SelfSubjectReviews().Create(ctx, selfReview, metav1.CreateOptions{})
	if err != nil {
		logger.WithError(err).Error("Failed to get self subject review")
		return
	}
	logger.WithFields(logrus.Fields{
		"username": result.Status.UserInfo.Username,
		"uid":      result.Status.UserInfo.UID,
		"groups":   result.Status.UserInfo.Groups,
	}).Info("Current identity")
	// Try to get self access review
	accessReview := &authorizationv1.SelfSubjectRulesReview{
		Spec: authorizationv1.SelfSubjectRulesReviewSpec{
			Namespace: "default",
		},
	}
	accessResult, err := clientset.AuthorizationV1().SelfSubjectRulesReviews().Create(ctx, accessReview, metav1.CreateOptions{})
	if err != nil {
		logger.WithError(err).Error("Failed to get self subject rules review")
		return
	}
	logger.WithField("rules", accessResult.Status.ResourceRules).Debug("Current permissions")
}
// GetClientConfig returns a Kubernetes ClientConfig using in-cluster or kubeconfig
func GetClientConfig(ctx context.Context, cfg *config.Config) (*K8sClientConfig, error) {
	var err error
	once.Do(func() {
		logrus.Debug("GetClientConfig: Attempting to get Kubernetes client configuration")
		inClusterConfig, inClusterErr := rest.InClusterConfig()
		if inClusterErr != nil {
			logrus.Debug("GetClientConfig: Not in cluster, attempting to use kubeconfig")
			instance, err = getOutOfClusterConfig(ctx, cfg)
			return
		}
		// Explicitly set the bearer token from the specified path
		token, tokenErr := os.ReadFile(cfg.VegaBearerTokenPath)
		if tokenErr != nil {
			err = fmt.Errorf("failed to read service account token from %s: %w", cfg.VegaBearerTokenPath, tokenErr)
			return
		}
		// Override the token in the config
		inClusterConfig.BearerToken = string(token)
		inClusterConfig.BearerTokenFile = cfg.VegaBearerTokenPath
		inClusterConfig.QPS = cfg.QPS
		inClusterConfig.Burst = cfg.Burst
		inClusterConfig.Timeout = cfg.Timeout
		logrus.WithFields(logrus.Fields{
			"token_path": cfg.VegaBearerTokenPath,
			"token_len":  len(string(token)),
			"qps":        cfg.QPS,
			"burst":      cfg.Burst,
			"timeout":    cfg.Timeout,
		}).Debug("Using explicit service account token")
		instance, err = createClientConfig(ctx, inClusterConfig, true, cfg)
		if err != nil {
			return
		}
		// Log the current identity
		logCurrentIdentity(ctx, instance.Clientset)
	})
	return instance, nil
}
// GetExistingClientConfig returns the existing client config without creating a new one
func GetExistingClientConfig() (*K8sClientConfig, error) {
	if instance == nil {
		return nil, fmt.Errorf("kubernetes client configuration has not been initialized")
	}
	return instance, nil
}
func getOutOfClusterConfig(ctx context.Context, cfg *config.Config) (*K8sClientConfig, error) {
	var kubeconfigPath string
	if kc := os.Getenv("KUBECONFIG"); kc != "" {
		kubeconfigPath = kc
		logrus.Infof("getOutOfClusterConfig: Using KUBECONFIG environment variable: %s", kubeconfigPath)
	} else {
		homeDir, err := os.UserHomeDir()
		if err != nil {
			return nil, fmt.Errorf("getOutOfClusterConfig: unable to determine user's home directory: %v", err)
		}
		kubeconfigPath = filepath.Join(homeDir, ".kube", "config")
		logrus.Infof("getOutOfClusterConfig: Using default kubeconfig path: %s", kubeconfigPath)
	}
	if _, err := os.Stat(kubeconfigPath); os.IsNotExist(err) {
		return nil, fmt.Errorf("getOutOfClusterConfig: kubeconfig file not found: %s", kubeconfigPath)
	}
	config, err := clientcmd.BuildConfigFromFlags("", kubeconfigPath)
	if err != nil {
		return nil, fmt.Errorf("getOutOfClusterConfig: failed to build config from kubeconfig file: %v", err)
	}
	return createClientConfig(ctx, config, false, cfg)
}
func createClientConfig(
	ctx context.Context,
	config *rest.Config,
	inCluster bool,
	cfg *config.Config,
) (*K8sClientConfig, error) {
	clientset, err := kubernetes.NewForConfig(config)
	if err != nil {
		return nil, fmt.Errorf("createClientConfig: failed to create clientset: %v", err)
	}
	clientConfig := &K8sClientConfig{
		Clientset:          clientset,
		Config:             config,
		UseInClusterConfig: inCluster,
		ClusterHostURL:     config.Host,
		Namespace:          cfg.VegaNamespace,
	}
	if err := enrichClientConfig(ctx, clientConfig); err != nil {
		return nil, err
	}
	logrus.Infof(
		"createClientConfig: Successfully created Kubernetes client configuration. Cluster URL: %s",
		clientConfig.ClusterHostURL,
	)
	return clientConfig, nil
}
func enrichClientConfig(ctx context.Context, config *K8sClientConfig) error {
	var err error
	// Get cluster UID
	config.ClusterUID, err = getNamespaceUID(ctx, config.Clientset, config.Namespace)
	if err != nil {
		return fmt.Errorf("enrichClientConfig: unable to find the namespace %s: %v", config.Namespace, err)
	}
	// Get cluster version
	config.ClusterVersion, err = getClusterVersion(config.Clientset)
	if err != nil {
		logrus.Warnf("enrichClientConfig: Unable to determine the cluster version: %v", err)
	}
	return nil
}
// getNamespaceUID retrieves the UID of a given namespace
func getNamespaceUID(ctx context.Context, clientset *kubernetes.Clientset, namespace string) (string, error) {
	logrus.Debugf("Attempting to get namespace %s", namespace)
	_, err := os.ReadFile("/var/run/secrets/kubernetes.io/serviceaccount/token")
	if err != nil {
		logrus.Debugf("Error reading service account token: %v", err)
	} else {
		logrus.Debugf("Service account token exists and is readable")
	}
	ns, err := clientset.CoreV1().Namespaces().Get(ctx, namespace, metav1.GetOptions{})
	if err != nil {
		return "", fmt.Errorf("getNamespaceUID: failed to get namespace %s: %v", namespace, err)
	}
	return string(ns.UID), nil
}
// getClusterVersion retrieves the version of the Kubernetes cluster
func getClusterVersion(clientset *kubernetes.Clientset) (string, error) {
	version, err := clientset.Discovery().ServerVersion()
	if err != nil {
		return "", fmt.Errorf("getClusterVersion: failed to get server version: %v", err)
	}
	return version.String(), nil
}
// VerifyClientIdentity checks if the client is using the expected service account
func VerifyClientIdentity(ctx context.Context, clientset *kubernetes.Clientset, expectedNamespace string) error {
	logger := logrus.WithField("function", "VerifyClientIdentity")
	selfReview := &authenticationv1.SelfSubjectReview{}
	result, err := clientset.AuthenticationV1().SelfSubjectReviews().Create(ctx, selfReview, metav1.CreateOptions{})
	if err != nil {
		return fmt.Errorf("failed to get self subject review: %w", err)
	}
	// Log the identity information
	logger.WithFields(logrus.Fields{
		"username": result.Status.UserInfo.Username,
		"uid":      result.Status.UserInfo.UID,
		"groups":   result.Status.UserInfo.Groups,
	}).Info("Current client identity")
	// Verify the service account namespace
	if !strings.Contains(result.Status.UserInfo.Username, expectedNamespace) {
		return fmt.Errorf("client is not using the expected service account in namespace %s", expectedNamespace)
	}
	return nil
}
</file>

<file path="pkg/utils/safememory.go">
// Copyright 2024 Vega Cloud, Inc.
//
// Use of this software is governed by the Business Source License
// included in the file licenses/BSL.txt.
//
// As of the Change Date specified in that file, in accordance with
// the Business Source License, use of this software will be governed
// by the Apache License, Version 2.0, included in the file
// licenses/APL.txt.
// Package utils provides utility functions for the metrics agent
package utils
import "github.com/sirupsen/logrus"
// SafeGPUMemory converts GPU memory value to bytes safely
func SafeGPUMemory(value int64) uint64 {
	const (
		GB        = uint64(1024 * 1024 * 1024)
		maxUint64 = ^uint64(0)
	)
	// First convert the value to uint64 safely
	if value < 0 {
		logrus.Warnf("Negative GPU memory value %d, using 0", value)
		return 0
	}
	uvalue := uint64(value)
	// Check if multiplication would overflow
	if uvalue > maxUint64/GB {
		logrus.Warnf("GPU memory value %d would overflow, capping at maximum", value)
		return maxUint64
	}
	return uvalue * GB
}
// SafeInt32Conversion converts int to int32 safely
func SafeInt32Conversion(value int) int32 {
	const maxInt32 = 1<<31 - 1
	const minInt32 = -1 << 31
	if value > maxInt32 {
		logrus.Warnf("Value %d exceeds maximum int32, capping at maximum", value)
		return maxInt32
	}
	if value < minInt32 {
		logrus.Warnf("Value %d is below minimum int32, capping at minimum", value)
		return minInt32
	}
	return int32(value)
}
</file>

<file path="pkg/utils/validate.go">
package utils
import (
	"fmt"
	"reflect"
	"strings"
)
// HasField checks if a field exists in a struct or pointer to struct
func HasField(input interface{}, field string) (err error) {
	val := reflect.ValueOf(input)
	// Ensure we're dealing with a pointer or struct
	if val.Kind() == reflect.Ptr {
		val = val.Elem()
	}
	if val.Kind() != reflect.Struct {
		return fmt.Errorf("input is not a struct or pointer to struct")
	}
	// Handle nested fields using dot notation
	if strings.Contains(field, ".") {
		parts := strings.SplitN(field, ".", 2) // Split into two parts
		subField := val.FieldByName(parts[0])
		if !subField.IsValid() {
			return fmt.Errorf("missing required field: %s", parts[0])
		}
		return HasField(subField.Interface(), parts[1]) // Recursive call for nested fields
	}
	// Check if the field exists
	if !val.FieldByName(field).IsValid() {
		return fmt.Errorf("missing required field: %s", field)
	}
	return nil
}
</file>

<file path="test/resources/AWS_EKS_FARGATE.cft.yaml">
AWSTemplateFormatVersion: '2010-09-09'
Description: 'AWS CloudFormation template to create a test EKS cluster using Fargate for compute resources.'
Parameters:
  ClusterName:
    Type: String
    Default: eks-test-cluster
  VpcId:
    Type: AWS::EC2::VPC::Id
    Description: VPC ID for the EKS cluster
  SubnetIds:
    Type: List<AWS::EC2::Subnet::Id>
    Description: Subnet IDs for the EKS cluster
Resources:
  EKSCluster:
    Type: AWS::EKS::Cluster
    Properties:
      Name: !Ref ClusterName
      Version: '1.27'
      RoleArn: !GetAtt EKSClusterRole.Arn
      ResourcesVpcConfig:
        SubnetIds: !Ref SubnetIds
  EKSClusterRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: eks.amazonaws.com
            Action: 'sts:AssumeRole'
      Policies:
        - PolicyName: EKSClusterPolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - 'ec2:Describe*'
                  - 'ec2:CreateTags'
                Resource: '*'
  FargateProfile:
    Type: AWS::EKS::FargateProfile
    Properties:
      ClusterName: !Ref EKSCluster
      FargateProfileName: fargate-profile
      PodExecutionRoleArn: !GetAtt FargatePodExecutionRole.Arn
      Subnets: !Ref SubnetIds
      Selectors:
        - Namespace: kube-system
        - Namespace: default
  FargatePodExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: eks-fargate-pods.amazonaws.com
            Action: 'sts:AssumeRole'
      Policies:
        - PolicyName: FargateExecutionPolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - 'logs:CreateLogStream'
                  - 'logs:CreateLogGroup'
                  - 'logs:PutLogEvents'
                Resource: '*'
Outputs:
  ClusterName:
    Description: The name of the EKS cluster
    Value: !Ref EKSCluster
  FargateProfileName:
    Description: The name of the Fargate profile
    Value: !Ref FargateProfile
</file>

<file path="test/resources/AWS_EKS_NODES.cft.yaml">
AWSTemplateFormatVersion: "2010-09-09"
Description: AWS CloudFormation template to create a production-ready EKS
  cluster with enhanced security and monitoring.
Parameters:
  ClusterName:
    Type: String
    Default: eks-cluster
    Description: Name of the EKS cluster
  Environment:
    Type: String
    Default: development
    AllowedValues:
      - development
      - staging
      - production
    Description: Environment type for the cluster
  KubernetesVersion:
    Type: String
    Default: "1.30"
    AllowedValues:
      - "1.28"
      - "1.29"
      - "1.30"
    Description: Kubernetes version for the cluster
  NodeInstanceType:
    Type: String
    Default: t3.medium
    AllowedValues:
      - t3.medium
      - t3.large
      - t3.xlarge
    Description: EC2 instance type for the worker nodes
  KeyName:
    Type: AWS::EC2::KeyPair::KeyName
    Description: Name of an existing EC2 KeyPair to enable SSH access to the worker nodes
  VpcId:
    Type: AWS::EC2::VPC::Id
    Description: VPC ID for the EKS cluster
    Default: "vpc-0c92e063ef953b289"
  SubnetIds:
    Type: List<AWS::EC2::Subnet::Id>
    Description: Subnet IDs for the EKS cluster nodes
  NodeDiskSize:
    Type: Number
    Default: 50
    MinValue: 20
    MaxValue: 100
    Description: Size of the node's EBS volume in GiB
  EnableClusterLogging:
    Type: String
    Default: "true"
    AllowedValues:
      - "true"
      - "false"
    Description: Enable CloudWatch logging for the EKS cluster
Conditions:
  EnableLogging: !Equals
    - !Ref EnableClusterLogging
    - "true"
Resources:
  EKSCluster:
    Type: AWS::EKS::Cluster
    Properties:
      Name: !Ref ClusterName
      Version: !Ref KubernetesVersion
      RoleArn: !GetAtt EKSClusterRole.Arn
      ResourcesVpcConfig:
        SubnetIds: !Ref SubnetIds
        SecurityGroupIds:
          - !Ref ClusterSecurityGroup
        EndpointPrivateAccess: true
        EndpointPublicAccess: true
      Tags:
        - Key: !Sub kubernetes.io/cluster/${ClusterName}
          Value: owned
        - Key: Environment
          Value: !Ref Environment
      Logging:
        ClusterLogging:
          EnabledTypes:
            - !If
              - EnableLogging
              - Type: api
              - !Ref AWS::NoValue
            - !If
              - EnableLogging
              - Type: audit
              - !Ref AWS::NoValue
  ClusterSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Security group for EKS cluster
      VpcId: !Ref VpcId
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: 443
          ToPort: 443
          CidrIp: 0.0.0.0/0
      Tags:
        - Key: Name
          Value: !Sub ${ClusterName}-cluster-sg
  NodeSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Security group for EKS worker nodes
      VpcId: !Ref VpcId
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: 22
          ToPort: 22
          CidrIp: 10.0.0.0/8
        # Allow inbound traffic from the cluster security group
        - IpProtocol: tcp
          FromPort: 1025
          ToPort: 65535
          SourceSecurityGroupId: !Ref ClusterSecurityGroup
      SecurityGroupEgress:
        - IpProtocol: -1
          CidrIp: 0.0.0.0/0
      Tags:
        - Key: Name
          Value: !Sub ${ClusterName}-node-sg
        - Key: !Sub kubernetes.io/cluster/${ClusterName}
          Value: owned
  # Allow nodes to communicate with each other
  NodeSecurityGroupIngress:
    Type: AWS::EC2::SecurityGroupIngress
    Properties:
      Description: Allow nodes to communicate with each other
      GroupId: !Ref NodeSecurityGroup
      SourceSecurityGroupId: !Ref NodeSecurityGroup
      IpProtocol: -1
  # Allow worker nodes to communicate with control plane
  ClusterSecurityGroupIngress:
    Type: AWS::EC2::SecurityGroupIngress
    Properties:
      Description: Allow worker nodes to communicate with control plane
      GroupId: !Ref ClusterSecurityGroup
      SourceSecurityGroupId: !Ref NodeSecurityGroup
      IpProtocol: tcp
      FromPort: 443
      ToPort: 443
  EKSClusterRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Principal:
              Service: eks.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/AmazonEKSClusterPolicy
        - arn:aws:iam::aws:policy/AmazonEKSVPCResourceController
  NodeLaunchTemplate:
    Type: AWS::EC2::LaunchTemplate
    Properties:
      LaunchTemplateData:
        InstanceType: !Ref NodeInstanceType
        KeyName: !Ref KeyName
        SecurityGroupIds:
          - !Ref NodeSecurityGroup
        BlockDeviceMappings:
          - DeviceName: /dev/xvda
            Ebs:
              VolumeSize: !Ref NodeDiskSize
        TagSpecifications:
          - ResourceType: instance
            Tags:
              - Key: Environment
                Value: !Ref Environment
  NodeGroup:
    Type: AWS::EKS::Nodegroup
    Properties:
      ClusterName: !Ref EKSCluster
      NodegroupName: !Sub ${ClusterName}-workers
      NodeRole: !GetAtt NodeInstanceRole.Arn
      Subnets: !Ref SubnetIds
      LaunchTemplate:
        Id: !Ref NodeLaunchTemplate
        Version: !GetAtt NodeLaunchTemplate.LatestVersionNumber
      ScalingConfig:
        MinSize: 2
        DesiredSize: 2
        MaxSize: 4
      AmiType: AL2023_x86_64_STANDARD
      Tags:
        Environment: !Ref Environment
      UpdateConfig:
        MaxUnavailable: 1
  NodeInstanceRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Principal:
              Service: ec2.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/AmazonEKSWorkerNodePolicy
        - arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy
        - arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly
        - arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore
        - arn:aws:iam::aws:policy/AmazonEKSServicePolicy
Outputs:
  ClusterName:
    Description: The name of the EKS cluster
    Value: !Ref EKSCluster
    Export:
      Name: !Sub ${AWS::StackName}-cluster-name
  ClusterEndpoint:
    Description: The endpoint for the EKS cluster API server
    Value: !GetAtt EKSCluster.Endpoint
  ClusterSecurityGroupId:
    Description: Security group for the cluster control plane
    Value: !Ref ClusterSecurityGroup
  NodeSecurityGroupId:
    Description: Security group for the cluster nodes
    Value: !Ref NodeSecurityGroup
  NodeInstanceRole:
    Description: The node instance role ARN
    Value: !GetAtt NodeInstanceRole.Arn
  ClusterOIDCIssuer:
    Description: The OIDC provider URL for the cluster
    Value: !GetAtt EKSCluster.OpenIdConnectIssuerUrl
  KubernetesVersion:
    Description: The running version of Kubernetes
    Value: !Ref KubernetesVersion
</file>

<file path="test/resources/AZURECLUSTER-nodes.yaml">
{
    "$schema": "https://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
    "contentVersion": "1.0.0.0",
    "parameters": {
        "apiVersion": {
            "type": "String"
        },
        "resourceName": {
            "type": "String",
            "metadata": {
                "description": "The name of the Managed Cluster resource."
            }
        },
        "location": {
            "type": "String",
            "metadata": {
                "description": "The location of AKS resource."
            }
        },
        "isLocationEdgeZone": {
            "defaultValue": false,
            "type": "Bool"
        },
        "edgeZone": {
            "defaultValue": {},
            "type": "Object",
            "metadata": {
                "description": "Extended location of the cluster."
            }
        },
        "useServicePrincipal": {
            "defaultValue": false,
            "type": "Bool"
        },
        "clusterSku": {
            "defaultValue": {
                "name": "Base",
                "tier": "Standard"
            },
            "type": "Object",
            "metadata": {
                "descirption": "The managed cluster SKU tier."
            }
        },
        "clusterTags": {
            "defaultValue": {},
            "type": "Object",
            "metadata": {
                "description": "Specifies the tags of the AKS cluster."
            }
        },
        "tagsForAllResources": {
            "defaultValue": {},
            "type": "Object"
        },
        "clusterIdentity": {
            "defaultValue": {
                "type": "SystemAssigned"
            },
            "type": "Object",
            "metadata": {
                "description": "The identity of the managed cluster, if configured."
            }
        },
        "enableAadProfile": {
            "defaultValue": false,
            "type": "Bool",
            "metadata": {
                "description": "Flag to turn on or off of Microsoft Entra ID Profile."
            }
        },
        "aadProfile": {
            "defaultValue": {},
            "type": "Object",
            "metadata": {
                "descirption": "The Microsoft Entra ID configuration."
            }
        },
        "dnsPrefix": {
            "type": "String",
            "metadata": {
                "description": "Optional DNS prefix to use with hosted Kubernetes API server FQDN."
            }
        },
        "kubernetesVersion": {
            "defaultValue": "1.7.7",
            "type": "String",
            "metadata": {
                "description": "The version of Kubernetes."
            }
        },
        "enableRBAC": {
            "defaultValue": true,
            "type": "Bool",
            "metadata": {
                "description": "Boolean flag to turn on and off of RBAC."
            }
        },
        "windowsProfile": {
            "defaultValue": false,
            "type": "Bool",
            "metadata": {
                "description": "Boolean flag to turn on and off of virtual machine scale sets"
            }
        },
        "nodeResourceGroup": {
            "type": "String",
            "metadata": {
                "description": "The name of the resource group containing agent pool nodes."
            }
        },
        "upgradeChannel": {
            "defaultValue": "none",
            "allowedValues": [
                "none",
                "patch",
                "rapid",
                "stable",
                "node-image"
            ],
            "type": "String",
            "metadata": {
                "description": "Auto upgrade channel for a managed cluster."
            }
        },
        "servicePrincipalClientId": {
            "defaultValue": "",
            "type": "SecureString",
            "metadata": {
                "description": "Client ID (used by cloudprovider)."
            }
        },
        "servicePrincipalClientSecret": {
            "defaultValue": "",
            "type": "SecureString",
            "metadata": {
                "description": "The Service Principal Client Secret."
            }
        },
        "adminGroupObjectIDs": {
            "defaultValue": "",
            "type": "Array",
            "metadata": {
                "description": "An array of Microsoft Entra group object ids to give administrative access."
            }
        },
        "principalId": {
            "defaultValue": "",
            "type": "String",
            "metadata": {
                "description": "The objectId of service principal."
            }
        },
        "supportPlan": {
            "defaultValue": "KubernetesOfficial",
            "allowedValues": [
                "AKSLongTermSupport",
                "KubernetesOfficial"
            ],
            "type": "String"
        },
        "azureRbac": {
            "defaultValue": false,
            "type": "Bool",
            "metadata": {
                "description": "Enable or disable Azure RBAC."
            }
        },
        "disableLocalAccounts": {
            "defaultValue": false,
            "type": "Bool",
            "metadata": {
                "description": "Enable or disable local accounts."
            }
        },
        "enablePrivateCluster": {
            "defaultValue": false,
            "type": "Bool",
            "metadata": {
                "description": "Enable private network access to the Kubernetes cluster."
            }
        },
        "isPrivateClusterSupported": {
            "defaultValue": false,
            "type": "Bool"
        },
        "enableAuthorizedIpRange": {
            "defaultValue": false,
            "type": "Bool"
        },
        "authorizedIPRanges": {
            "defaultValue": [],
            "type": "Array",
            "metadata": {
                "description": "Boolean flag to turn on and off http application routing."
            }
        },
        "isPublicNetworkAccessEnabled": {
            "defaultValue": false,
            "type": "Bool"
        },
        "publicNetworkAccess": {
            "defaultValue": "Enabled",
            "allowedValues": [
                "Disabled",
                "Enabled",
                "SecuredByPerimeter"
            ],
            "type": "String",
            "metadata": {
                "description": "Allow or deny public network access for AKS."
            }
        },
        "enableDiskEncryptionSetID": {
            "defaultValue": false,
            "type": "Bool",
            "metadata": {
                "description": "Flag to turn on or off of diskEncryptionSetID. Set diskEncryptionSetID to null when false."
            }
        },
        "diskEncryptionSetID": {
            "defaultValue": "",
            "type": "String",
            "metadata": {
                "description": "The ID of the disk encryption set used to encrypt the OS disks of the nodes."
            }
        },
        "aadSessionKey": {
            "defaultValue": "",
            "type": "SecureString"
        },
        "isAzurePolicySupported": {
            "defaultValue": false,
            "type": "Bool"
        },
        "enableAzurePolicy": {
            "defaultValue": false,
            "type": "Bool",
            "metadata": {
                "description": "Boolean flag to turn on and off Azure Policy addon."
            }
        },
        "isSecretStoreCSIDDriverSupported": {
            "defaultValue": false,
            "type": "Bool"
        },
        "enableSecretStoreCSIDriver": {
            "defaultValue": false,
            "type": "Bool",
            "metadata": {
                "description": "Boolean flag to turn on and off secret store CSI driver."
            }
        },
        "enableOmsAgent": {
            "defaultValue": true,
            "type": "Bool",
            "metadata": {
                "description": "Boolean flag to turn on and off omsagent addon."
            }
        },
        "workspaceRegion": {
            "defaultValue": "East US",
            "type": "String",
            "metadata": {
                "description": "Specify the region for your OMS workspace."
            }
        },
        "workspaceName": {
            "defaultValue": "",
            "type": "String",
            "metadata": {
                "description": "Specify the name of the OMS workspace."
            }
        },
        "omsWorkspaceId": {
            "defaultValue": "",
            "type": "String",
            "metadata": {
                "description": "Specify the resource id of the OMS workspace."
            }
        },
        "omsSku": {
            "defaultValue": "standalone",
            "allowedValues": [
                "free",
                "standalone",
                "pernode"
            ],
            "type": "String",
            "metadata": {
                "description": "Select the SKU for your workspace."
            }
        },
        "aciVnetSubnetName": {
            "defaultValue": "",
            "type": "String",
            "metadata": {
                "description": "Name of virtual network subnet used for the ACI Connector."
            }
        },
        "aciConnectorLinuxEnabled": {
            "defaultValue": false,
            "type": "Bool",
            "metadata": {
                "description": "Enables the Linux ACI Connector."
            }
        },
        "acrName": {
            "defaultValue": "",
            "type": "String",
            "metadata": {
                "description": "Specify the name of the Azure Container Registry."
            }
        },
        "acrResourceGroup": {
            "defaultValue": "",
            "type": "String",
            "metadata": {
                "description": "The name of the resource group the container registry is associated with."
            }
        },
        "guidValue": {
            "defaultValue": "[newGuid()]",
            "type": "String",
            "metadata": {
                "description": "The unique id used in the role assignment of the kubernetes service to the container registry service. It is recommended to use the default value."
            }
        },
        "enableVnetSubnetID": {
            "defaultValue": false,
            "type": "Bool",
            "metadata": {
                "description": "Flag to turn on or off of vnetSubnetID."
            }
        },
        "vnetSubnetID": {
            "defaultValue": "",
            "type": "String",
            "metadata": {
                "description": "Resource ID of virtual network subnet used for nodes and/or pods IP assignment."
            }
        },
        "loadBalancerSku": {
            "defaultValue": "Standard",
            "allowedValues": [
                "Basic",
                "Standard"
            ],
            "type": "String",
            "metadata": {
                "description": "Specifies the sku of the load balancer used by the virtual machine scale sets used by node pools."
            }
        },
        "networkPolicy": {
            "defaultValue": "",
            "type": "String",
            "metadata": {
                "description": "Network policy used for building the Kubernetes network."
            }
        },
        "networkPlugin": {
            "defaultValue": "azure",
            "allowedValues": [
                "azure",
                "kubenet"
            ],
            "type": "String",
            "metadata": {
                "description": "Network plugin used for building the Kubernetes network."
            }
        },
        "networkPluginMode": {
            "defaultValue": "",
            "type": "String",
            "metadata": {
                "description": "Network plugin mode used for building the Kubernetes network."
            }
        },
        "networkDataplane": {
            "defaultValue": "",
            "type": "String",
            "metadata": {
                "description": "Network dataplane used in the Kubernetes cluster."
            }
        },
        "serviceCidr": {
            "defaultValue": "",
            "type": "String",
            "metadata": {
                "description": "A CIDR notation IP range from which to assign service cluster IPs."
            }
        },
        "dnsServiceIP": {
            "defaultValue": "",
            "type": "String",
            "metadata": {
                "description": "Containers DNS server IP address."
            }
        },
        "spotMaxPrice": {
            "defaultValue": "",
            "type": "String",
            "metadata": {
                "description": "Possible values are any decimal value greater than zero or -1 which indicates the willingness to pay any on-demand price."
            }
        },
        "vmssNodePool": {
            "defaultValue": false,
            "type": "Bool",
            "metadata": {
                "description": "Boolean flag to turn on and off of virtual machine scale sets"
            }
        },
        "isAvailabilityZoneEnabled": {
            "defaultValue": false,
            "type": "Bool",
            "metadata": {
                "description": "Boolean flag to turn on or off of Availability Zone"
            }
        },
        "osDiskSizeGB": {
            "defaultValue": 0,
            "minValue": 0,
            "maxValue": 1023,
            "type": "Int",
            "metadata": {
                "description": "Disk size (in GiB) to provision for each of the agent pool nodes. This value ranges from 0 to 1023. Specifying 0 will apply the default disk size for that agentVMSize."
            }
        },
        "agentCount": {
            "defaultValue": 3,
            "minValue": 1,
            "maxValue": 50,
            "type": "Int",
            "metadata": {
                "description": "The number of agent nodes for the cluster. Production workloads have a recommended minimum of 3."
            }
        },
        "scaleSetEvictionPolicy": {
            "defaultValue": "Delete",
            "allowedValues": [
                "Delete",
                "Deallocate"
            ],
            "type": "String",
            "metadata": {
                "description": "Specifies the ScaleSetEvictionPolicy to be used to specify eviction policy for spot virtual machine scale set. Default to Delete. Allowed values are Delete or Deallocate."
            }
        },
        "scaleSetPriority": {
            "defaultValue": "Regular",
            "allowedValues": [
                "Spot",
                "Regular"
            ],
            "type": "String",
            "metadata": {
                "description": "Specifies the virtual machine scale set priority in the user node pool: Spot or Regular."
            }
        },
        "agentTags": {
            "defaultValue": {},
            "type": "Object",
            "metadata": {
                "description": "Specifies the tags of the agent pool."
            }
        },
        "enableNodePublicIP": {
            "defaultValue": false,
            "type": "Bool",
            "metadata": {
                "description": "Some scenarios may require nodes in a node pool to receive their own dedicated public IP addresses."
            }
        },
        "agentNodeTaints": {
            "defaultValue": [],
            "type": "Array",
            "metadata": {
                "description": "Specifies the taints added to new nodes during node pool create and scale. For example, key=value:NoSchedule. - string."
            }
        },
        "agentNodeLables": {
            "defaultValue": {},
            "type": "Object",
            "metadata": {
                "description": "Specifies the Agent pool node labels to be persisted across all nodes in the system node pool."
            }
        },
        "agentAvailabilityZones": {
            "defaultValue": [],
            "type": "Array",
            "metadata": {
                "description": "Specifies the availability zones for the agent nodes in the agent node pool. Requires the use of VirtualMachineScaleSets as node pool type."
            }
        },
        "agentMode": {
            "defaultValue": "System",
            "allowedValues": [
                "System",
                "User"
            ],
            "type": "String",
            "metadata": {
                "description": "A cluster must have at least one 'System' Agent Pool at all times."
            }
        },
        "agentMaxPods": {
            "defaultValue": 30,
            "type": "Int",
            "metadata": {
                "description": "Specifies the maximum number of pods that can run on a node in the agent node pool. The maximum number of pods per node in an AKS cluster is 250. The default maximum number of pods per node varies between kubenet and Azure CNI networking, and the method of cluster deployment."
            }
        },
        "agentOSType": {
            "defaultValue": "Linux",
            "allowedValues": [
                "Linux",
                "Windows"
            ],
            "type": "String",
            "metadata": {
                "description": "The type of operating system for agent pool."
            }
        },
        "agentVMSize": {
            "defaultValue": "Standard_D2_v3",
            "type": "String",
            "metadata": {
                "description": "The size of the Virtual Machine."
            }
        },
        "agentMaxCount": {
            "defaultValue": 5,
            "type": "Int",
            "metadata": {
                "description": "Specifies the maximum number of nodes for auto-scaling for the system node pool."
            }
        },
        "agentMinCount": {
            "defaultValue": 3,
            "type": "Int",
            "metadata": {
                "description": "Specifies the minimum number of nodes for auto-scaling for the system node pool."
            }
        },
        "enableAutoScaling": {
            "defaultValue": true,
            "type": "Bool",
            "metadata": {
                "description": "Specifies whether to enable auto-scaling for the system node pool."
            }
        },
        "serviceMeshMode": {
            "defaultValue": "Disabled",
            "allowedValues": [
                "Disabled",
                "Istio"
            ],
            "type": "String"
        },
        "istioInternalIngressGateway": {
            "defaultValue": false,
            "type": "Bool"
        },
        "istioExternalIngressGateway": {
            "defaultValue": false,
            "type": "Bool"
        },
        "nodeOSUpgradeChannel": {
            "defaultValue": "NodeImage",
            "allowedValues": [
                "None",
                "Unmanaged",
                "SecurityPatch",
                "NodeImage"
            ],
            "type": "String",
            "metadata": {
                "description": "Auto upgrade channel for node OS security."
            }
        },
        "isImageCleanerEnabled": {
            "defaultValue": false,
            "type": "Bool"
        },
        "imageCleanerIntervalHours": {
            "defaultValue": 168,
            "type": "Int"
        },
        "enableOIDC": {
            "defaultValue": true,
            "type": "Bool",
            "metadata": {
                "description": "Whether the OIDC issuer is enabled."
            }
        },
        "issuerURL": {
            "defaultValue": "",
            "type": "String",
            "metadata": {
                "description": "The OIDC issuer url of the Managed Cluster."
            }
        },
        "enableWorkloadIdentity": {
            "defaultValue": true,
            "type": "Bool",
            "metadata": {
                "description": "Whether to enable workload identity."
            }
        }
    },
    "variables": {
        "isScaleSetPrioritySpot": "[equals(parameters('scaleSetPriority'), 'Spot')]",
        "defaultAadProfile": {
            "managed": true,
            "adminGroupObjectIDs": "[parameters('adminGroupObjectIDs')]",
            "enableAzureRBAC": "[parameters('azureRbac')]"
        },
        "defaultApiServerAccessProfile": {
            "authorizedIPRanges": "[if(parameters('enableAuthorizedIpRange'), parameters('authorizedIPRanges'), null())]",
            "enablePrivateCluster": "[parameters('enablePrivateCluster')]"
        },
        "defaultAzurePolicy": {
            "enabled": "[parameters('enableAzurePolicy')]"
        },
        "defaultSecrectStoreProvider": {
            "enabled": "[parameters('enableSecretStoreCSIDriver')]",
            "config": "[if(parameters('enableSecretStoreCSIDriver'), variables('secrectStoreConfig'), null())]"
        },
        "secrectStoreConfig": {
            "enableSecretRotation": "false",
            "rotationPollInterval": "2m"
        },
        "servicePrincipalProfile": {
            "ClientId": "[parameters('servicePrincipalClientId')]",
            "Secret": "[parameters('servicePrincipalClientSecret')]"
        }
    },
    "resources": [
        {
            "type": "Microsoft.ContainerService/managedClusters",
            "apiVersion": "[parameters('apiVersion')]",
            "name": "[parameters('resourceName')]",
            "location": "[parameters('location')]",
            "extendedLocation": "[if(parameters('isLocationEdgeZone'), parameters('edgeZone'), null())]",
            "dependsOn": [
                "VnetDeployment-fdc9a6a8-0dbc-4b7d-526a-a0edafc70904"
            ],
            "tags": "[parameters('clusterTags')]",
            "sku": "[parameters('clusterSku')]",
            "identity": "[parameters('clusterIdentity')]",
            "properties": {
                "kubernetesVersion": "[parameters('kubernetesVersion')]",
                "enableRBAC": "[parameters('enableRBAC')]",
                "dnsPrefix": "[parameters('dnsPrefix')]",
                "nodeResourceGroup": "[parameters('nodeResourceGroup')]",
                "disableLocalAccounts": "[parameters('disableLocalAccounts')]",
                "aadProfile": "[if(parameters('enableAadProfile'), variables('defaultAadProfile'), null())]",
                "autoUpgradeProfile": {
                    "upgradeChannel": "[parameters('upgradeChannel')]",
                    "nodeOSUpgradeChannel": "[parameters('nodeOSUpgradeChannel')]"
                },
                "agentPoolProfiles": [
                    {
                        "name": "test",
                        "osDiskSizeGB": "[parameters('osDiskSizeGB')]",
                        "count": 1,
                        "enableAutoScaling": true,
                        "minCount": 1,
                        "maxCount": 3,
                        "vmSize": "Standard_D2pls_v6",
                        "osType": "Linux",
                        "osSKU": "AzureLinux",
                        "type": "VirtualMachineScaleSets",
                        "mode": "User",
                        "maxPods": 30,
                        "availabilityZones": [],
                        "nodeLabels": {},
                        "nodeTaints": [],
                        "enableNodePublicIP": false,
                        "tags": {},
                        "vnetSubnetID": "[parameters('vnetSubnetID')]"
                    },
                    {
                        "name": "system",
                        "osDiskSizeGB": "[parameters('osDiskSizeGB')]",
                        "count": 1,
                        "enableAutoScaling": true,
                        "minCount": 1,
                        "maxCount": 3,
                        "vmSize": "Standard_D2pls_v6",
                        "osType": "Linux",
                        "osSKU": "AzureLinux",
                        "type": "VirtualMachineScaleSets",
                        "mode": "System",
                        "maxPods": 30,
                        "availabilityZones": [],
                        "nodeLabels": {},
                        "nodeTaints": [],
                        "enableNodePublicIP": false,
                        "tags": {},
                        "vnetSubnetID": "[parameters('vnetSubnetID')]"
                    }
                ],
                "apiServerAccessProfile": "[if(parameters('isPrivateClusterSupported'), variables('defaultApiServerAccessProfile'), null())]",
                "addonProfiles": {
                    "azurepolicy": "[if(parameters('isAzurePolicySupported'), variables('defaultAzurePolicy'), null())]",
                    "azureKeyvaultSecretsProvider": "[if(parameters('isSecretStoreCSIDDriverSupported'), variables('defaultSecrectStoreProvider'), null())]"
                },
                "diskEncryptionSetID": "[if(parameters('enableDiskEncryptionSetID'), parameters('diskEncryptionSetID'), null())]",
                "networkProfile": {
                    "loadBalancerSku": "[parameters('loadBalancerSku')]",
                    "networkPlugin": "[parameters('networkPlugin')]",
                    "networkPluginMode": "[parameters('networkPluginMode')]",
                    "networkDataplane": "[parameters('networkDataplane')]",
                    "networkPolicy": "[parameters('networkPolicy')]",
                    "serviceCidr": "[parameters('serviceCidr')]",
                    "dnsServiceIP": "[parameters('dnsServiceIP')]"
                },
                "supportPlan": "[parameters('supportPlan')]",
                "securityProfile": {
                    "imageCleaner": {
                        "enabled": "[parameters('isImageCleanerEnabled')]",
                        "intervalHours": "[parameters('imageCleanerIntervalHours')]"
                    },
                    "workloadIdentity": {
                        "enabled": "[parameters('enableWorkloadIdentity')]"
                    }
                },
                "oidcIssuerProfile": {
                    "enabled": "[parameters('enableOIDC')]"
                }
            }
        },
        {
            "type": "Microsoft.Resources/deployments",
            "apiVersion": "2019-05-01",
            "name": "VnetDeployment-fdc9a6a8-0dbc-4b7d-526a-a0edafc70904",
            "properties": {
                "mode": "Incremental",
                "template": {
                    "$schema": "https://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
                    "contentVersion": "1.0.0.0",
                    "resources": [
                        {
                            "apiVersion": "2024-01-01",
                            "name": "testakscluster_group-vnet",
                            "type": "Microsoft.Network/virtualNetworks",
                            "location": "westus2",
                            "properties": {
                                "addressSpace": {
                                    "addressPrefixes": [
                                        "10.224.0.0/12"
                                    ]
                                },
                                "subnets": [
                                    {
                                        "name": "default",
                                        "id": "/subscriptions/a72cf362-8598-4dbe-9969-eebb11e1e339/resourceGroups/testakscluster_group/providers/Microsoft.Network/virtualNetworks/testakscluster_group-vnet/subnets/default",
                                        "properties": {
                                            "addressPrefix": "10.224.0.0/16",
                                            "serviceEndpoints": [
                                                {
                                                    "service": "Microsoft.ContainerRegistry"
                                                }
                                            ]
                                        }
                                    }
                                ]
                            },
                            "tags": "[parameters('tagsForAllResources')]"
                        }
                    ]
                }
            }
        },
        {
            "type": "Microsoft.Resources/deployments",
            "apiVersion": "2019-05-01",
            "name": "ClusterSubnetRoleAssignmentDeployment-20250107161937-34",
            "dependsOn": [
                "[concat('Microsoft.ContainerService/managedClusters/', parameters('resourceName'))]",
                "VnetDeployment-fdc9a6a8-0dbc-4b7d-526a-a0edafc70904"
            ],
            "properties": {
                "mode": "Incremental",
                "template": {
                    "$schema": "https://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
                    "contentVersion": "1.0.0.0",
                    "parameters": {},
                    "variables": {},
                    "resources": [
                        {
                            "type": "Microsoft.Network/virtualNetworks/subnets/providers/roleAssignments",
                            "apiVersion": "2018-09-01-preview",
                            "name": "testakscluster_group-vnet/default/Microsoft.Authorization/428fc960-47c8-cd8e-a5b9-c744ccabfa9d",
                            "properties": {
                                "roleDefinitionId": "[concat('/subscriptions/', subscription().subscriptionId, '/providers/Microsoft.Authorization/roleDefinitions/', '4d97b98b-1d4f-4787-a291-c67834d212e7')]",
                                "principalId": "[reference(parameters('resourceName'),'2023-10-01','Full').identity.principalId]",
                                "principalType": "ServicePrincipal",
                                "scope": "/subscriptions/a72cf362-8598-4dbe-9969-eebb11e1e339/resourceGroups/testakscluster_group/providers/Microsoft.Network/virtualNetworks/testakscluster_group-vnet/subnets/default"
                            }
                        }
                    ]
                }
            },
            "subscriptionId": "a72cf362-8598-4dbe-9969-eebb11e1e339",
            "resourceGroup": "testakscluster_group"
        }
    ],
    "outputs": {
        "controlPlaneFQDN": {
            "type": "String",
            "value": "[reference(concat('Microsoft.ContainerService/managedClusters/', parameters('resourceName'))).fqdn]"
        }
    }
}
</file>

<file path="test/resources/buildkindtestcluster.sh">
#!/bin/bash
set -euo pipefail
# === Configuration ===
KIND_VERSION="v0.22.0"
K8S_IMAGE="kindest/node:v1.30.0"
CONFIG_FILE="kind-config.yaml"
RESOURCES_FILE="./test-resources.yaml"
CLUSTER_PREFIX="testcluster"
SLEEP_TIME=20
# === Generate Random Cluster Name ===
RAND_SUFFIX=$(head /dev/urandom | tr -dc a-z0-9 | head -c 8)
CLUSTER_NAME="${CLUSTER_PREFIX}-${RAND_SUFFIX}"
echo "$(date +%T) - Generated cluster name: $CLUSTER_NAME"
# === Download kind if not already present ===
if [[ ! -x "./kind" ]]; then
  echo "$(date +%T) - Downloading kind $KIND_VERSION..."
  curl -Lo ./kind https://kind.sigs.k8s.io/dl/latest/kind-linux-amd64
  chmod +x ./kind
fi
# === Create the Kind Cluster ===
echo "$(date +%T) - Creating Kind cluster: $CLUSTER_NAME"
./kind create cluster --name "$CLUSTER_NAME" --config "$CONFIG_FILE" --image="$K8S_IMAGE"
# === Wait for Cluster to Settle ===
echo "$(date +%T) - Sleeping $SLEEP_TIME seconds to allow the cluster to settle"
sleep "$SLEEP_TIME"
# === Set kubectl context (optional if only one kind cluster is running) ===
export KUBECONFIG="$(kind get kubeconfig-path --name="$CLUSTER_NAME" 2>/dev/null || echo "$HOME/.kube/config")"
# === Apply Test Resources ===
echo "$(date +%T) - Applying test resources"
kubectl apply -f "$RESOURCES_FILE"
# === Optional: Debug into a pod ===
#DEBUG_NAMESPACE="test-metrics"
#DEBUG_POD="test-pod"
#DEBUG_TARGET="main-contai"
#DEBUG_IMAGE="busybox"
#echo "$(date +%T) - Starting kubectl debug session (namespace: $DEBUG_NAMESPACE)"
#kubectl debug -n "$DEBUG_NAMESPACE" "$DEBUG_POD" --image="$DEBUG_IMAGE" -it --target="$DEBUG_TARGET"
# === Optional: Cleanup on exit ===
# trap 'echo "Cleaning up..."; ./kind delete cluster --name "$CLUSTER_NAME"' EXIT
</file>

<file path="test/resources/kind-config.yaml">
# Copyright 2024 Vega Cloud, Inc.
# Use of this software is governed by the Business Source License
# included in the file licenses/BSL.txt.
# As of the Change Date specified in that file, in accordance with
# the Business Source License, use of this software will be governed
# by the Apache License, Version 2.0, included in the file
# licenses/APL.txt.
# kind-config.yaml
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
nodes:
  - role: control-plane
  - role: worker
  - role: worker
  - role: worker
</file>

<file path="test/resources/test-resources.yaml">
# Copyright 2024 Vega Cloud, Inc.
# Use of this software is governed by the Business Source License
# included in the file licenses/BSL.txt.
# As of the Change Date specified in that file, in accordance with
# the Business Source License, use of this software will be governed
# by the Apache License, Version 2.0, included in the file
# licenses/APL.txt.
---
apiVersion: v1
kind: Namespace
metadata:
  name: test-metrics
  labels:
    environment: test
    purpose: metrics-collection
---
apiVersion: v1
kind: ResourceQuota
metadata:
  name: test-quota
  namespace: test-metrics
spec:
  hard:
    pods: "10"
    requests.cpu: "2"
    requests.memory: "1Gi"
    limits.cpu: "4"
    limits.memory: "2Gi"
---
apiVersion: v1
kind: LimitRange
metadata:
  name: test-limitrange
  namespace: test-metrics
spec:
  limits:
    - type: Container
      defaultRequest:
        cpu: "100m"
        memory: "128Mi"
      default:
        cpu: "200m"
        memory: "256Mi"
      max:
        cpu: "500m"
        memory: "512Mi"
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: test-config
  namespace: test-metrics
  labels:
    app: test-app
data:
  example-key: "example-value"
---
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: test-storageclass
  labels:
    environment: test
provisioner: kubernetes.io/no-provisioner
volumeBindingMode: WaitForFirstConsumer
---
apiVersion: v1
kind: PersistentVolume
metadata:
  name: test-pv
  labels:
    environment: test
spec:
  capacity:
    storage: 1Gi
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  storageClassName: test-storageclass
  hostPath:
    path: /tmp/test-pv
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: test-pvc
  namespace: test-metrics
  labels:
    environment: test
spec:
  accessModes:
    - ReadWriteOnce
  storageClassName: test-storageclass
  resources:
    requests:
      storage: 500Mi
---
apiVersion: v1
kind: Pod
metadata:
  name: test-pod
  namespace: test-metrics
  labels:
    app: test-pod
  annotations:
    test-annotation: "true"
spec:
  readinessGates:
    - conditionType: "test.scheduling.k8s.io/ready"
  securityContext:
    fsGroup: 101
    runAsUser: 101
    runAsGroup: 101
  containers:
    - name: main-container
      image: nginx:stable
      ports:
        - containerPort: 8080
      resources:
        requests:
          cpu: "100m"
          memory: "128Mi"
        limits:
          cpu: "200m"
          memory: "256Mi"
      volumeMounts:
        - name: test-volume
          mountPath: /data
        - name: nginx-cache
          mountPath: /var/cache/nginx
        - name: nginx-run
          mountPath: /var/run
        - name: nginx-conf
          mountPath: /etc/nginx/conf.d/default.conf
          subPath: nginx.conf
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
            - ALL
  initContainers:
    - name: init-test
      image: busybox
      command:
        - sh
        - -c
        - |
          cat <<EOF > /etc/nginx/nginx.conf
          server {
              listen 8080;
              server_name localhost;
              location / {
                  root   /usr/share/nginx/html;
                  index  index.html index.htm;
              }
          }
          EOF
      volumeMounts:
        - name: nginx-conf
          mountPath: /etc/nginx
  volumes:
    - name: test-volume
      persistentVolumeClaim:
        claimName: test-pvc
    - name: nginx-cache
      emptyDir: {}
    - name: nginx-run
      emptyDir: {}
    - name: nginx-conf
      emptyDir: {}
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: test-deployment
  namespace: test-metrics
  labels:
    app: test-deployment
spec:
  replicas: 2
  selector:
    matchLabels:
      app: test-deployment
  template:
    metadata:
      labels:
        app: test-deployment
    spec:
      containers:
        - name: web
          image: nginx:stable
          ports:
            - containerPort: 8080
          resources:
            requests:
              cpu: "100m"
              memory: "128Mi"
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: test-daemonset
  namespace: test-metrics
  labels:
    app: test-daemonset
spec:
  selector:
    matchLabels:
      app: test-daemonset
  template:
    metadata:
      labels:
        app: test-daemonset
    spec:
      containers:
        - name: daemon
          image: nginx:stable
          ports:
            - containerPort: 8080
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: test-statefulset
  namespace: test-metrics
  labels:
    app: test-statefulset
spec:
  serviceName: "test-statefulset-service"
  replicas: 1
  selector:
    matchLabels:
      app: test-statefulset
  template:
    metadata:
      labels:
        app: test-statefulset
    spec:
      containers:
        - name: stateful
          image: nginx:stable
          ports:
            - containerPort: 8080
---
apiVersion: batch/v1
kind: Job
metadata:
  name: test-job
  namespace: test-metrics
  labels:
    app: test-job
spec:
  completions: 1
  parallelism: 1
  template:
    metadata:
      labels:
        app: test-job
    spec:
      restartPolicy: Never
      containers:
        - name: job
          image: busybox
          command: ["sh", "-c", "echo Job Completed; sleep 2"]
---
apiVersion: batch/v1
kind: CronJob
metadata:
  name: test-cronjob
  namespace: test-metrics
  labels:
    app: test-cronjob
spec:
  schedule: "*/5 * * * *"
  jobTemplate:
    spec:
      template:
        metadata:
          labels:
            app: test-cronjob
        spec:
          restartPolicy: Never
          containers:
            - name: cron
              image: busybox
              command: ["sh", "-c", "echo CronJob Run; sleep 1"]
---
apiVersion: v1
kind: ReplicationController
metadata:
  name: test-rc
  namespace: test-metrics
  labels:
    app: test-rc
spec:
  replicas: 1
  selector:
    app: test-rc
  template:
    metadata:
      labels:
        app: test-rc
    spec:
      containers:
        - name: rc-container
          image: nginx:stable
          ports:
            - containerPort: 8080
---
apiVersion: v1
kind: Service
metadata:
  name: test-service
  namespace: test-metrics
  labels:
    app: test-service
spec:
  selector:
    app: test-deployment
  ports:
    - protocol: TCP
      port: 80
      targetPort: 8080
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: test-ingress
  namespace: test-metrics
  labels:
    app: test-ingress
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  rules:
    - host: "test.example.com"
      http:
        paths:
          - path: "/"
            pathType: Prefix
            backend:
              service:
                name: test-service
                port:
                  number: 80
---
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: test-networkpolicy
  namespace: test-metrics
  labels:
    app: test-networkpolicy
spec:
  podSelector:
    matchLabels:
      app: test-pod
  policyTypes:
    - Ingress
  ingress:
    - from:
        - namespaceSelector:
            matchLabels:
              environment: test
      ports:
        - protocol: TCP
          port: 8080
---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: test-hpa
  namespace: test-metrics
  labels:
    app: test-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: test-deployment
  minReplicas: 1
  maxReplicas: 5
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 50
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: test-pdb
  namespace: test-metrics
  labels:
    app: test-pdb
spec:
  minAvailable: 1
  selector:
    matchLabels:
      app: test-deployment
</file>

<file path="Dockerfile">
ARG golang_version=1.23

# Use architecture-specific Alpine image
FROM --platform=linux/${TARGETARCH} golang:${golang_version}-alpine

# Define TARGETARCH within the build stage
ARG TARGETARCH

# Install necessary runtime dependencies
RUN apk update && \
    apk upgrade && \
    apk add --no-cache git ca-certificates curl bash

# Copy the pre-built binary for the target architecture
COPY bin/${TARGETARCH}/vega-metrics-agent /vega-metrics-agent

# Set the entrypoint
ENTRYPOINT ["/vega-metrics-agent"]
</file>

<file path="LICENSE">
Source code in this repository is licensed under the Business Source
License 1.1 (BSL) specified in the source code. Source
code in a given file is licensed under the BSL and the copyright belongs to The
Vega Cloud, Inc. unless otherwise noted at the beginning of the file.
</file>

<file path="main.go">
// Package main is the entrypoint to the Vega Metrics Agent
// Copyright 2024 Vega Cloud, Inc.
//
// Use of this software is governed by the Business Source License
// included in the file licenses/BSL.txt.
//
// As of the Change Date specified in that file, in accordance with
// the Business Source License, use of this software will be governed
// by the Apache License, Version 2.0, included in the file
// licenses/APL.txt.
package main
import (
	"context"
	"fmt"
	"os"
	"os/signal"
	"strings"
	"syscall"
	"time"
	"github.com/sirupsen/logrus"
	"github.com/spf13/cobra"
	"github.com/spf13/viper"
	"k8s.io/client-go/kubernetes"
	"k8s.io/client-go/rest"
	"github.com/vegacloud/kubernetes/metricsagent/pkg/agent"
	"github.com/vegacloud/kubernetes/metricsagent/pkg/config"
	"github.com/vegacloud/kubernetes/metricsagent/pkg/health"
	"github.com/vegacloud/kubernetes/metricsagent/pkg/utils"
)
func main() {
	time.Local = time.UTC
	rootCmd := &cobra.Command{
		Use:   "vega-metrics-agent",
		Short: "A metrics agent for collecting Kubernetes node and pod metrics and sending to Vega Cloud",
		RunE:  runRootCmd,
	}
	rootCmd.Flags().BoolP("version", "v", false, "Print the version and exit")
	// Vega configuration
	rootCmd.Flags().String("client_id", "", "Client ID (env: VEGA_CLIENT_ID)")
	rootCmd.Flags().String("client_secret", "", "Client Secret (env: VEGA_CLIENT_SECRET)")
	rootCmd.Flags().String("org_slug", "", "Organization slug (env: VEGA_ORG_SLUG)")
	rootCmd.Flags().String("cluster_name", "", "Cluster name (env: VEGA_CLUSTER_NAME)")
	rootCmd.Flags().Bool("insecure",
		config.DefaultVegaInsecure,
		"Insecure TLS (env: VEGA_INSECURE)")
	rootCmd.Flags().String("poll_interval",
		string(config.DefaultPollInterval),
		"Polling interval in minutes (env: VEGA_POLL_INTERVAL)")
	// Logging configuration
	rootCmd.Flags().String("log_level",
		config.DefaultLogLevel,
		"Log level (DEBUG, INFO, WARN, ERROR) (env: VEGA_LOG_LEVEL)")
	// Kubernetes configuration
	rootCmd.Flags().String("bearer_token_path",
		config.DefaultBearerTokenPath,
		"Bearer token path (env: VEGA_BEARER_TOKEN_PATH)")
	rootCmd.Flags().String("work_dir", config.DefaultWorkDir, "Work directory (env: VEGA_WORK_DIR)")
	rootCmd.Flags().Int("max_concurrency", config.DefaultMaxConcurrency, "Max concurrency (env: VEGA_MAX_CONCURRENCY)")
	if err := viper.BindPFlags(rootCmd.Flags()); err != nil {
		logrus.Fatalf("Error binding flags: %v", err)
	}
	if err := rootCmd.Execute(); err != nil {
		logrus.Errorf("Error executing command: %v", err)
	}
}
func runRootCmd(cmd *cobra.Command, _ []string) error {
	versionFlag, err := cmd.Flags().GetBool("version")
	if err != nil {
		return fmt.Errorf("failed to get 'version' flag: %w", err)
	}
	if versionFlag {
		logrus.Infof("Vega Kubernetes and Container Metrics Agent version: %s, Schema version: %s", config.DefaultAgentVersion, config.DefaultSchemaVersion)
		return nil
	}
	requiredFlags := []string{"client_id", "client_secret", "org_slug", "cluster_name"}
	for _, flag := range requiredFlags {
		if err := cmd.MarkFlagRequired(flag); err != nil {
			return fmt.Errorf("failed to mark flag '%s' as required: %w", flag, err)
		}
	}
	cfg, err := config.LoadConfig()
	if err != nil {
		return fmt.Errorf("failed to load config: %w", err)
	}
	initializeLogging(cfg)
	logrus.WithFields(logrus.Fields{
		"version":      cfg.AgentVersion,
		"client_id":    cfg.VegaClientID,
		"org_slug":     cfg.VegaOrgSlug,
		"cluster_name": cfg.VegaClusterName,
	}).Info("Starting Vega Kubernetes and Container Metrics Agent")
	if logrus.IsLevelEnabled(logrus.DebugLevel) {
		logrus.Debugf("Configuration: %+v", cfg)
	}
	logger := logrus.WithFields(logrus.Fields{
		"client_id":    cfg.VegaClientID,
		"org_slug":     cfg.VegaOrgSlug,
		"cluster_name": cfg.VegaClusterName,
	})
	if err := startMetricsAgent(cfg, logger); err != nil {
		return err
	}
	return nil
}
func initializeLogging(cfg *config.Config) {
	logLevel, err := logrus.ParseLevel(strings.ToLower(cfg.LogLevel))
	if err != nil {
		logrus.Warnf("Invalid log level %s, defaulting to INFO", cfg.LogLevel)
		logLevel = logrus.InfoLevel
	}
	logrus.SetLevel(logLevel)
	logrus.SetFormatter(&logrus.TextFormatter{
		FullTimestamp: true,
	})
}
func initializeKubernetesClients(ctx context.Context, cfg *config.Config, logger *logrus.Entry) (*kubernetes.Clientset, *utils.K8sClientConfig, error) {
	logger.Debug("Starting Kubernetes client initialization...")
	// Get Kubernetes client configuration
	logger.Debug("Getting Kubernetes client configuration...")
	// Add functionality to verify we can access the service token
	token, err := os.ReadFile(cfg.VegaBearerTokenPath)
	if err != nil {
		return nil, nil, fmt.Errorf("failed to read service token: %w", err)
	}
	logger.WithField("token", string(token)).Debug("Successfully read service token")
	k8sConfig, err := utils.GetClientConfig(ctx, cfg)
	if err != nil {
		logger.WithError(err).Error("Failed to get Kubernetes client configuration")
		return nil, nil, fmt.Errorf("failed to get Kubernetes client config: %w", err)
	}
	logger.WithFields(logrus.Fields{
		"host":              k8sConfig.Config.Host,
		"bearer_token_path": k8sConfig.Config.BearerTokenFile,
		"qps":               k8sConfig.Config.QPS,
		"burst":             k8sConfig.Config.Burst,
		"timeout":           k8sConfig.Config.Timeout,
	}).Debug("Successfully obtained Kubernetes client configuration")
	return k8sConfig.Clientset, k8sConfig, nil
}
func startMetricsAgent(cfg *config.Config, logger *logrus.Entry) error {
	logger.Debug("Initializing metrics agent...")
	// Configure TLS transport
	logger.Debug("Configuring TLS transport...")
	transport, err := rest.TransportFor(&rest.Config{
		TLSClientConfig: rest.TLSClientConfig{
			Insecure: cfg.VegaInsecure,
		},
	})
	if err != nil {
		logger.WithError(err).Error("Failed to create TLS transport")
		return fmt.Errorf("failed to create transport: %w", err)
	}
	logger.WithField("insecure", cfg.VegaInsecure).Debug("Successfully created TLS transport")
	// Initialize Kubernetes clients
	clientset, k8sConfig, err := initializeKubernetesClients(context.Background(), cfg, logger)
	if err != nil {
		return err
	}
	// Add detailed k8s config logging here
	logger.WithFields(logrus.Fields{
		"cluster_host_url":      k8sConfig.ClusterHostURL,
		"cluster_uid":           k8sConfig.ClusterUID,
		"cluster_version":       k8sConfig.ClusterVersion,
		"namespace":             k8sConfig.Namespace,
		"use_in_cluster_config": k8sConfig.UseInClusterConfig,
		"qps":                   k8sConfig.Config.QPS,
		"burst":                 k8sConfig.Config.Burst,
		"timeout":               k8sConfig.Config.Timeout,
		"bearer_token_file":     k8sConfig.Config.BearerTokenFile,
		"ca_file":               k8sConfig.Config.CAFile,
		"server_name":           k8sConfig.Config.ServerName,
		"insecure_skip_verify":  k8sConfig.Config.Insecure,
	}).Info("Kubernetes configuration details")
	// Configure TLS for the REST client
	if client, ok := clientset.CoreV1().RESTClient().(*rest.RESTClient); ok {
		logger.Debug("Configuring TLS for kubelet client")
		client.Client.Transport = transport
		logger.WithFields(logrus.Fields{
			"insecure":       cfg.VegaInsecure,
			"transport_type": fmt.Sprintf("%T", transport),
		}).Debug("Successfully configured TLS for kubelet client")
	} else {
		logger.Warn("Unable to configure TLS: unexpected REST client type")
	}
	// Create metrics agent
	logger.Debug("Creating metrics agent...")
	// os.Exit(1)
	metricsAgent, err := agent.NewMetricsAgent(cfg, logger)
	if err != nil {
		logger.WithError(err).Error("Failed to create metrics agent")
		return fmt.Errorf("failed to create metrics agent: %w", err)
	}
	logger.Debug("Successfully created metrics agent")
	ctx, cancel := context.WithCancel(context.Background())
	defer cancel()
	// Start health check server
	go func() {
		logger.Info("Starting liveness probe server on :80")
		if err := health.ServerHealthCheck(ctx); err != nil {
			logger.WithError(err).Error("Health check startup failed")
			cancel()
		} else {
			logger.Info("Health check successful")
		}
	}()
	// Handle signals
	sigs := make(chan os.Signal, 1)
	signal.Notify(sigs, syscall.SIGINT, syscall.SIGTERM)
	go func() {
		sig := <-sigs
		logger.WithField("signal", sig).Info("Received signal, initiating shutdown")
		cancel()
	}()
	logger.Info("Starting metrics agent main loop")
	metricsAgent.Run(ctx)
	return nil
}
</file>

<file path="Makefile">
# Copyright 2024 Vega Cloud, Inc.
#
# Use of this software is governed by the Business Source License
# included in the file licenses/BSL.txt.
#
# As of the Change Date specified in that file, in accordance with
# the Business Source License, use of this software will be governed
# by the Apache License, Version 2.0, included in the file
# licenses/APL.txt.
# Variables
APPLICATION = vega-metrics-agent
DOCKER_IMAGE = public.ecr.aws/c0f8b9o4/vegacloud/${APPLICATION}
VERSION = $(shell cat pkg/config/VERSION)
DOCKER_IMAGE_DEV = public.ecr.aws/c0f8b9o4/vegacloud/${APPLICATION}-test
GOLANG_VERSION ?= 1.23

# Go commands
GO_BUILD = CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -o bin/amd64/${APPLICATION}
GO_BUILD_ARM = CGO_ENABLED=0 GOOS=linux GOARCH=arm64 go build -o bin/arm64/${APPLICATION}

GO_FMT = go fmt ./...
GO_LINT = golangci-lint run
GO_SEC = ${HOME}/go/bin/gosec ./...
GO_TEST = go test ./...
GO_VET = go vet ./...

# Docker commands
DOCKER_BUILD = docker buildx build -f Dockerfile \
	--build-arg golang_version=${GOLANG_VERSION} \
	--build-arg app_version=${VERSION} \
	--platform linux/amd64,linux/arm64 \
	-t ${DOCKER_IMAGE}:${VERSION} \
	-t ${DOCKER_IMAGE}:latest  \
        --push .

DOCKER_BUILD_DEV = docker buildx build -f Dockerfile \
	--build-arg golang_version=${GOLANG_VERSION} \
	--build-arg app_version=${VERSION} \
	--platform linux/amd64,linux/arm64 \
	-t ${DOCKER_IMAGE_DEV}:${VERSION} \
        --push .


# Default target
.PHONY: all
all: fmt vet lint sec test build docker-build

# Dev target
.PHONY: alldev
alldev: fmt vet lint sec build docker-build-dev

# Dev target without security checks
.PHONY: alldevnosec
alldevnosec: fmt vet lint build docker-build-dev


# Format Go code
.PHONY: fmt
fmt:
	@echo "Formatting Go code..."
	${GO_FMT}

# Run linters
.PHONY: lint
lint:
	@echo "Running Go linters..."
	${GO_LINT}

# Run security checks
.PHONY: sec
sec:
	@echo "Running security checks..."
	${GO_SEC}

# Run tests
.PHONY: test
test:
	@echo "Running Go tests..."
	${GO_TEST}

# Run Go vet
.PHONY: vet
vet:
	@echo "Running Go vet..."
	${GO_VET}

# Build Go binary locally
.PHONY: build
build:
	@echo "Building Go application locally..."
	mkdir -p bin
	${GO_BUILD}
	${GO_BUILD_ARM}

# Build Docker image
.PHONY: docker-build
docker-build:
	@echo "Building Docker image..."
	${DOCKER_BUILD}


# Build Docker image
.PHONY: docker-build-dev
docker-build-dev:
	@echo "Building Docker dev image..."
	${DOCKER_BUILD_DEV}


# Push Docker image
#.PHONY: docker-push
#docker-push:
#	docker push ${DOCKER_IMAGE}:${VERSION}
#	docker push ${DOCKER_IMAGE}:latest

#.PHONY: docker-push-dev
#docker-push-dev:
#	docker push ${DOCKER_IMAGE_DEV}:${VERSION}

# Clean build artifacts
.PHONY: clean
clean:
	@echo "Cleaning up..."
	rm -rf bin/

# Help target
.PHONY: help
help:
	@echo "Usage:"
	@echo "  make all              - Format, vet, lint, sec, test, build locally, and build the Docker image"
	@echo "  make fmt              - Format the Go code"
	@echo "  make lint             - Run Go linters"
	@echo "  make sec              - Run security checks"
	@echo "  make test             - Run Go tests"
	@echo "  make vet              - Run Go vet"
	@echo "  make build            - Build the Go application locally"
	@echo "  make docker-build     - Build Docker image using Dockerfile"
	@echo "  make docker-push      - Push Docker image to registry"
	@echo "  make clean            - Clean build artifacts"
</file>

<file path="charts/vega-metrics-agent/.gitignore">
values-dev.yaml
values-brent.yaml
values-devlocal.yaml
values-synthetic.yaml
</file>

<file path="charts/vega-metrics-agent/.repomixignore">
# Add patterns to ignore here, one per line
# Example:
# *.log
# tmp/
</file>

<file path="pkg/collectors/node.go">
// Copyright 2024 Vega Cloud, Inc.
//
// Use of this software is governed by the Business Source License
// included in the file licenses/BSL.txt.
//
// As of the Change Date specified in that file, in accordance with
// the Business Source License, use of this software will be governed
// by the Apache License, Version 2.0, included in the file
// licenses/APL.txt.
// Package collectors hosts the collection functions
package collectors
import (
	"context"
	"sync"
	// "crypto/tls"
	"encoding/json"
	// "errors"
	"fmt"
	"math"
	// "os"
	"strconv"
	"strings"
	// "sync"
	// "time"
	dto "github.com/prometheus/client_model/go"
	"github.com/sirupsen/logrus"
	v1 "k8s.io/api/core/v1"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/client-go/kubernetes"
	"github.com/vegacloud/kubernetes/metricsagent/pkg/config"
	"github.com/vegacloud/kubernetes/metricsagent/pkg/models"
	"github.com/vegacloud/kubernetes/metricsagent/pkg/utils"
)
// NodeCollector collects metrics from Kubernetes nodes.
type NodeCollector struct {
	clientset *kubernetes.Clientset
	config    *config.Config
}
// NewNodeCollector initializes a new NodeCollector.
func NewNodeCollector(
	clientset *kubernetes.Clientset,
	cfg *config.Config,
) *NodeCollector {
	// Log that we are starting the NodeCollector
	// logrus.Debug("Starting NodeCollector")
	// // Check if we have a token
	// if token, err := os.ReadFile("/var/run/secrets/kubernetes.io/serviceaccount/token"); err == nil {
	// 	clientset.CoreV1().RESTClient().(*rest.RESTClient).Client.Transport = &http.Transport{
	// 		TLSClientConfig: &tls.Config{
	// 			InsecureSkipVerify: cfg.VegaInsecure,
	// 		},
	// 	}
	// 	clientset.CoreV1().RESTClient().(*rest.RESTClient).Client.Transport = transport.NewBearerAuthRoundTripper(
	// 		string(token),
	// 		clientset.CoreV1().RESTClient().(*rest.RESTClient).Client.Transport,
	// 	)
	// }
	logrus.Debug("NodeCollector initialized successfully")
	return &NodeCollector{
		clientset: clientset,
		config:    cfg,
	}
}
// CollectMetrics collects metrics for all nodes
func (nc *NodeCollector) CollectMetrics(ctx context.Context) (interface{}, error) {
	nodes, err := nc.clientset.CoreV1().Nodes().List(ctx, metav1.ListOptions{})
	if err != nil {
		return nil, err
	}
	var metrics []models.EnhancedNodeMetrics
	for _, node := range nodes.Items {
		nodeMetrics, err := nc.CollectNodeMetrics(ctx, &node)
		if err != nil {
			continue
		}
		metrics = append(metrics, *nodeMetrics)
	}
	return metrics, nil
}
// Update collectCPUMetrics to use the new method
func (nc *NodeCollector) collectCPUMetrics(ctx context.Context, node *v1.Node) (models.CPUMetrics, error) {
	// Try to get metrics using the metrics.k8s.io API first
	config, err := utils.GetExistingClientConfig()
	if err != nil {
		logrus.WithError(err).Warn("Failed to get existing client config for metrics API, falling back to kubelet")
		return nc.collectCPUMetricsFromKubelet(ctx, node)
	}
	nodeMetrics, err := utils.GetNodeMetricsFromAPI(ctx, nc.clientset, config.Config, node.Name)
	if err != nil {
		logrus.WithError(err).Warnf("Failed to get metrics for node %s from metrics API, falling back to kubelet", node.Name)
		return nc.collectCPUMetricsFromKubelet(ctx, node)
	}
	// If we got metrics from the API, parse them
	if nodeMetrics != nil && nodeMetrics.Usage.Cpu() != nil {
		cpuUsage := nodeMetrics.Usage.Cpu().MilliValue()
		// Create a CPUMetrics object with the data we have
		cpuMetrics := models.CPUMetrics{
			UsageTotal:   uint64(cpuUsage * 1000000), // Convert millicores to nanoseconds
			PerCoreUsage: make(map[string]uint64),
		}
		// Log successful retrieval
		logrus.WithFields(logrus.Fields{
			"node": node.Name,
			"cpu":  cpuUsage,
		}).Debug("Successfully retrieved CPU metrics from metrics.k8s.io API")
		return cpuMetrics, nil
	}
	// If we couldn't get metrics from the API or they're incomplete, fall back to kubelet
	logrus.Debugf("No CPU metrics available from metrics API for node %s, falling back to kubelet", node.Name)
	return nc.collectCPUMetricsFromKubelet(ctx, node)
}
// Add the fallback method that uses the original kubelet approach
func (nc *NodeCollector) collectCPUMetricsFromKubelet(ctx context.Context, node *v1.Node) (models.CPUMetrics, error) {
	metricFamilies, err := FetchMetricsViaKubelet(ctx, nc.clientset, node.Name, "metrics/cadvisor")
	if err != nil {
		return models.CPUMetrics{}, err
	}
	cpuMetrics := models.CPUMetrics{
		PerCoreUsage: make(map[string]uint64),
	}
	// Process metric families to extract CPU stats
	if family, ok := metricFamilies["container_cpu_usage_seconds_total"]; ok {
		for _, metric := range family.Metric {
			// Get the container from the metric
			var containerID string
			var containerName string
			for _, label := range metric.Label {
				if label.GetName() == "id" {
					containerID = label.GetValue()
				}
				if label.GetName() == "name" {
					containerName = label.GetValue()
				}
			}
			if containerID == "" || containerName != "/" {
				continue // Only consider the root container
			}
			if metric.Counter != nil {
				// Convert seconds to nanoseconds
				cpuMetrics.UsageTotal = uint64(metric.Counter.GetValue() * 1e9)
			}
		}
	}
	// Additional processing for per-core metrics
	if family, ok := metricFamilies["container_cpu_usage_seconds_total"]; ok {
		for _, metric := range family.Metric {
			// Check if this is a per-core metric
			var cpu string
			var containerName string
			for _, label := range metric.Label {
				if label.GetName() == "cpu" {
					cpu = label.GetValue()
				}
				if label.GetName() == "name" {
					containerName = label.GetValue()
				}
			}
			// Only consider root container and CPU-specific metrics
			if containerName == "/" && cpu != "" {
				if metric.Counter != nil {
					// Convert seconds to nanoseconds
					cpuMetrics.PerCoreUsage[cpu] = uint64(metric.Counter.GetValue() * 1e9)
				}
			}
		}
	}
	return cpuMetrics, nil
}
// collectRuntimeMetrics collects runtime metrics
func (nc *NodeCollector) collectRuntimeMetrics(ctx context.Context, node *v1.Node) (models.RuntimeMetrics, error) {
	metricFamilies, err := FetchMetricsViaKubelet(ctx, nc.clientset, node.Name, "metrics/probes")
	if err != nil {
		return models.RuntimeMetrics{}, err
	}
	runtimeMetrics := models.RuntimeMetrics{
		Operations: make(map[string]models.RuntimeOperation),
	}
	// Parse runtime operations
	if operations, ok := metricFamilies["runtime_operations_total"]; ok {
		for _, metric := range operations.Metric {
			if metric.Counter != nil {
				opType := getLabel(metric, "operation_type")
				if opType != "" {
					runtimeMetrics.Operations[opType] = models.RuntimeOperation{
						Count: uint64(metric.Counter.GetValue()),
						Type:  opType,
					}
				}
			}
		}
	}
	// Parse runtime errors
	if errors, ok := metricFamilies["runtime_operations_errors_total"]; ok {
		for _, metric := range errors.Metric {
			if metric.Counter != nil {
				opType := getLabel(metric, "operation_type")
				if op, exists := runtimeMetrics.Operations[opType]; exists {
					op.Errors = uint64(metric.Counter.GetValue())
					runtimeMetrics.Operations[opType] = op
				}
			}
		}
	}
	return runtimeMetrics, nil
}
// Update collectMemoryMetrics
func (nc *NodeCollector) collectMemoryMetrics(ctx context.Context, node *v1.Node) (models.MemoryMetrics, error) {
	metricFamilies, err := FetchMetricsViaKubelet(ctx, nc.clientset, node.Name, "metrics/cadvisor")
	if err != nil {
		return models.MemoryMetrics{}, err
	}
	memoryMetrics := models.MemoryMetrics{}
	// Total memory usage (equivalent to metrics-server memory usage)
	if memUsage, ok := metricFamilies["container_memory_usage_bytes"]; ok {
		for _, metric := range memUsage.Metric {
			if metric.Gauge != nil {
				memoryMetrics.Used = uint64(metric.Gauge.GetValue())
			}
		}
	}
	// Additional detailed memory metrics
	if memWorkingSet, ok := metricFamilies["container_memory_working_set_bytes"]; ok {
		for _, metric := range memWorkingSet.Metric {
			if metric.Gauge != nil {
				memoryMetrics.WorkingSet = uint64(metric.Gauge.GetValue())
			}
		}
	}
	if memRSS, ok := metricFamilies["container_memory_rss"]; ok {
		for _, metric := range memRSS.Metric {
			if metric.Gauge != nil {
				memoryMetrics.RSS = uint64(metric.Gauge.GetValue())
			}
		}
	}
	return memoryMetrics, nil
}
// // getBearerToken retrieves the token from a file or environment variable.
// func (nc *NodeCollector) getBearerToken() (string, error) {
// 	// First, try to read from file
// 	if nc.config.VegaBearerTokenPath != "" {
// 		tokenBytes, err := os.ReadFile(nc.config.VegaBearerTokenPath)
// 		if err == nil {
// 			token := strings.TrimSpace(string(tokenBytes))
// 			logrus.Debug("Successfully read Service Account bearer token from file")
// 			return token, nil
// 		}
// 		logrus.Printf("Failed to read bearer token from file, defaulting to BEARER_TOKEN environment variable: %v", err)
// 	}
// 	// If file read failed or no file path was provided, try environment variable
// 	token := strings.TrimSpace(os.Getenv("BEARER_TOKEN"))
// 	if token != "" {
// 		logrus.Debug("Successfully read bearer token from environment variable")
// 		return token, nil
// 	}
// 	// If both file and environment variable failed, return an error
// 	return "", errors.New("bearer token not found in file or environment")
// }
func (nc *NodeCollector) collectNetworkMetrics(ctx context.Context, node *v1.Node) (models.NetworkMetrics, error) {
	metricFamilies, err := FetchMetricsViaKubelet(ctx, nc.clientset, node.Name, "metrics/cadvisor")
	if err != nil {
		return models.NetworkMetrics{}, fmt.Errorf("failed to fetch network metrics: %w", err)
	}
	networkMetrics := models.NetworkMetrics{
		Interfaces: make([]models.InterfaceStats, 0),
		Summary:    models.NetworkSummary{},
	}
	interfaceMap := make(map[string]*models.InterfaceStats)
	// Process node network metrics for detailed interface stats
	for name, family := range metricFamilies {
		if !strings.HasPrefix(name, "node_network_") {
			continue
		}
		for _, metric := range family.Metric {
			interfaceName := getLabel(metric, "device")
			if interfaceName == "" {
				continue
			}
			if _, exists := interfaceMap[interfaceName]; !exists {
				interfaceMap[interfaceName] = &models.InterfaceStats{
					InterfaceName: interfaceName,
				}
			}
			if metric.Counter != nil {
				value := uint64(metric.Counter.GetValue())
				switch name {
				case "node_network_receive_bytes_total":
					interfaceMap[interfaceName].RxBytes = value
					networkMetrics.Summary.RxBytesTotal += value
				case "node_network_transmit_bytes_total":
					interfaceMap[interfaceName].TxBytes = value
					networkMetrics.Summary.TxBytesTotal += value
				case "node_network_receive_packets_total":
					interfaceMap[interfaceName].RxPackets = value
				case "node_network_transmit_packets_total":
					interfaceMap[interfaceName].TxPackets = value
				case "node_network_receive_errs_total":
					interfaceMap[interfaceName].RxErrors = value
				case "node_network_transmit_errs_total":
					interfaceMap[interfaceName].TxErrors = value
				}
			}
		}
	}
	// Convert interface map to slice
	for _, v := range interfaceMap {
		networkMetrics.Interfaces = append(networkMetrics.Interfaces, *v)
	}
	// Also collect container network metrics if they provide additional information
	if rxBytes, ok := metricFamilies["container_network_receive_bytes_total"]; ok {
		for _, metric := range rxBytes.Metric {
			if metric.Counter != nil {
				networkMetrics.Summary.ContainerRxBytesTotal += uint64(metric.Counter.GetValue())
			}
		}
	}
	if txBytes, ok := metricFamilies["container_network_transmit_bytes_total"]; ok {
		for _, metric := range txBytes.Metric {
			if metric.Counter != nil {
				networkMetrics.Summary.ContainerTxBytesTotal += uint64(metric.Counter.GetValue())
			}
		}
	}
	return networkMetrics, nil
}
func (nc *NodeCollector) collectDiskMetrics(ctx context.Context, node *v1.Node) (models.DiskMetrics, error) {
	metricFamilies, err := FetchMetricsViaKubelet(ctx, nc.clientset, node.Name, "metrics/cadvisor")
	if err != nil {
		return models.DiskMetrics{}, fmt.Errorf("failed to fetch disk metrics: %w", err)
	}
	diskMetrics := models.DiskMetrics{
		Devices: make([]models.NodeDiskStats, 0),
	}
	deviceMap := make(map[string]*models.NodeDiskStats)
	// Process per-device metrics
	for name, family := range metricFamilies {
		if !strings.HasPrefix(name, "node_disk_") {
			continue
		}
		for _, metric := range family.Metric {
			device := getLabel(metric, "device")
			if device == "" {
				continue
			}
			if _, exists := deviceMap[device]; !exists {
				deviceMap[device] = &models.NodeDiskStats{
					Device: device,
				}
			}
			if metric.Counter != nil {
				value := uint64(metric.Counter.GetValue())
				switch name {
				case "node_disk_read_bytes_total":
					deviceMap[device].ReadBytes = value
					diskMetrics.ReadBytes += safeInt64(value)
				case "node_disk_written_bytes_total":
					deviceMap[device].WriteBytes = value
					diskMetrics.WriteBytes += safeInt64(value)
				case "node_disk_reads_completed_total":
					deviceMap[device].ReadOps = value
				case "node_disk_writes_completed_total":
					deviceMap[device].WriteOps = value
				}
			}
		}
	}
	// Convert device map to slice
	for _, device := range deviceMap {
		diskMetrics.Devices = append(diskMetrics.Devices, *device)
	}
	return diskMetrics, nil
}
func (nc *NodeCollector) collectProcessMetrics(ctx context.Context, node *v1.Node) (models.ProcessMetrics, error) {
	metricFamilies, err := FetchMetricsViaKubelet(ctx, nc.clientset, node.Name, "metrics")
	if err != nil {
		return models.ProcessMetrics{}, fmt.Errorf("failed to fetch process metrics: %w", err)
	}
	var processMetrics models.ProcessMetrics
	if procCount, ok := metricFamilies["process_cpu_seconds_total"]; ok {
		processMetrics.ProcessCount = len(procCount.Metric)
	}
	return processMetrics, nil
}
// parseResourceList converts Kubernetes resource list to ResourceMetrics
func (nc *NodeCollector) parseResourceList(rl v1.ResourceList) models.ResourceMetrics {
	metrics := models.ResourceMetrics{}
	// CPU is reported in cores, convert to millicores
	if cpu, ok := rl[v1.ResourceCPU]; ok {
		metrics.CPU = cpu.MilliValue()
	}
	// Memory is reported in bytes
	if memory, ok := rl[v1.ResourceMemory]; ok {
		metrics.Memory = memory.Value()
	}
	// Persistent Storage
	if storage, ok := rl[v1.ResourceStorage]; ok {
		metrics.Storage = storage.Value()
	}
	// Ephemeral storage should be tracked separately from persistent storage
	if ephemeralStorage, ok := rl[v1.ResourceEphemeralStorage]; ok {
		metrics.EphemeralStorage = ephemeralStorage.Value()
	}
	// Add pods resource if available
	if pods, ok := rl[v1.ResourcePods]; ok {
		metrics.Pods = pods.Value()
	}
	return metrics
}
func (nc *NodeCollector) collectFilesystemMetrics(ctx context.Context, node *v1.Node) (models.FSMetrics, error) {
	rawStats, err := FetchRawStatsViaKubelet(ctx, nc.clientset, node.Name, "stats/summary")
	if err != nil {
		return models.FSMetrics{}, fmt.Errorf("failed to fetch filesystem stats: %w", err)
	}
	var stats struct {
		Node struct {
			Fs struct {
				CapacityBytes  uint64 `json:"capacityBytes"`
				UsedBytes      uint64 `json:"usedBytes"`
				AvailableBytes uint64 `json:"availableBytes"`
				InodesFree     uint64 `json:"inodesFree"`
				InodesUsed     uint64 `json:"inodesUsed"`
			} `json:"fs"`
		} `json:"node"`
	}
	if err := json.Unmarshal(rawStats, &stats); err != nil {
		return models.FSMetrics{}, fmt.Errorf("failed to unmarshal filesystem stats: %w", err)
	}
	return models.FSMetrics{
		TotalBytes:     stats.Node.Fs.CapacityBytes,
		UsedBytes:      stats.Node.Fs.UsedBytes,
		AvailableBytes: stats.Node.Fs.AvailableBytes,
		Inodes: models.InodeStats{
			Free:  stats.Node.Fs.InodesFree,
			Used:  stats.Node.Fs.InodesUsed,
			Total: stats.Node.Fs.InodesFree + stats.Node.Fs.InodesUsed,
		},
	}, nil
}
func (nc *NodeCollector) collectContainerStats(ctx context.Context, node *v1.Node) (models.ContainerStats, error) {
	metricFamilies, err := FetchMetricsViaKubelet(ctx, nc.clientset, node.Name, "metrics/cadvisor")
	if err != nil {
		return models.ContainerStats{}, fmt.Errorf("failed to fetch container metrics: %w", err)
	}
	stats := models.ContainerStats{
		PerContainer: make(map[string]models.ContainerMetrics),
	}
	// Basic container count from running containers
	if count, ok := metricFamilies["container_last_seen"]; ok {
		stats.RunningCount = len(count.Metric)
	}
	return stats, nil
}
func (nc *NodeCollector) collectSystemMetrics(ctx context.Context, node *v1.Node) (models.SystemMetrics, error) {
	metricFamilies, err := FetchMetricsViaKubelet(ctx, nc.clientset, node.Name, "metrics")
	if err != nil {
		return models.SystemMetrics{}, fmt.Errorf("failed to fetch system metrics: %w", err)
	}
	var systemMetrics models.SystemMetrics
	// Parse system metrics
	if nodeUptimeMetric, ok := metricFamilies["node_boot_time_seconds"]; ok {
		for _, metric := range nodeUptimeMetric.Metric {
			if metric.Gauge != nil {
				systemMetrics.BootTimeSeconds = float64(metric.Gauge.GetValue())
			}
		}
	}
	// Add additional system information
	cpuValue := node.Status.Capacity.Cpu().Value()
	if cpuValue >= 0 {
		systemMetrics.NumCPUs = cpuValue
	}
	systemMetrics.KernelVersion = node.Status.NodeInfo.KernelVersion
	systemMetrics.OSVersion = node.Status.NodeInfo.OSImage
	systemMetrics.MachineID = node.Status.NodeInfo.MachineID
	systemMetrics.SystemUUID = node.Status.NodeInfo.SystemUUID
	return systemMetrics, nil
}
// safeInt64 converts uint64 to int64 safely
func safeInt64(val uint64) int64 {
	if val > math.MaxInt64 {
		return math.MaxInt64
	}
	return int64(val)
}
// // safeInt32 converts uint64 to int32 safely
// func safeInt32(val uint64) int32 {
// 	if val > math.MaxInt32 {
// 		return math.MaxInt32
// 	}
// 	return int32(val)
// }
// // safeUint64 converts int64 to uint64 safely
// func safeUint64(val int64) uint64 {
// 	if val < 0 {
// 		return 0
// 	}
// 	return uint64(val)
// }
func (nc *NodeCollector) parseLatencyMetric(family *dto.MetricFamily) models.LatencyMetric {
	latencyMetric := models.LatencyMetric{}
	for _, metric := range family.Metric {
		if metric.Summary != nil {
			for _, quantile := range metric.Summary.Quantile {
				switch *quantile.Quantile {
				case 0.50:
					latencyMetric.P50 = *quantile.Value
				case 0.90:
					latencyMetric.P90 = *quantile.Value
				case 0.99:
					latencyMetric.P99 = *quantile.Value
				}
			}
			if metric.Summary.SampleCount != nil {
				count := *metric.Summary.SampleCount
				latencyMetric.Count = safeInt64(count)
			}
		}
	}
	return latencyMetric
}
func (nc *NodeCollector) collectVolumeMetrics(ctx context.Context, node *v1.Node) (models.VolumeMetrics, error) {
	metricFamilies, err := FetchMetricsViaKubelet(ctx, nc.clientset, node.Name, "metrics")
	if err != nil {
		return models.VolumeMetrics{}, fmt.Errorf("failed to fetch volume metrics: %w", err)
	}
	volumeMetrics := models.VolumeMetrics{
		OperationLatency: make(map[string]models.LatencyMetric),
	}
	// Parse volume metrics
	if attachCount, ok := metricFamilies["volume_manager_total_volumes"]; ok {
		for _, metric := range attachCount.Metric {
			if metric.Gauge != nil {
				volumeMetrics.InUseCount = uint64(metric.Gauge.GetValue())
			}
		}
	}
	// Parse operation latency metrics if available
	if latencyMetrics, ok := metricFamilies["storage_operation_duration_seconds"]; ok {
		for _, metric := range latencyMetrics.Metric {
			if metric.Summary != nil {
				opType := getLabel(metric, "operation_name")
				if opType != "" {
					volumeMetrics.OperationLatency[opType] = nc.parseLatencyMetric(latencyMetrics)
				}
			}
		}
	}
	return volumeMetrics, nil
}
func (nc *NodeCollector) collectNodeInfo(node *v1.Node) models.NodeInfo {
	return models.NodeInfo{
		Architecture:            node.Status.NodeInfo.Architecture,
		ContainerRuntimeVersion: node.Status.NodeInfo.ContainerRuntimeVersion,
		KernelVersion:           node.Status.NodeInfo.KernelVersion,
		OSImage:                 node.Status.NodeInfo.OSImage,
		KubeletVersion:          node.Status.NodeInfo.KubeletVersion,
	}
}
func (nc *NodeCollector) collectHardwareTopology(ctx context.Context, node *v1.Node) (*models.HardwareTopology, error) {
	cpuValue := node.Status.Capacity.Cpu().Value()
	// Since cpuValue is already an int64, this check is unnecessary
	// You can remove the check entirely or if you want to be extra careful:
	if cpuValue < 0 {
		return nil, fmt.Errorf("invalid negative CPU value: %d", cpuValue)
	}
	topology := &models.HardwareTopology{
		Sockets: cpuValue,
		Cores:   cpuValue,
	}
	metricFamilies, err := FetchMetricsViaKubelet(ctx, nc.clientset, node.Name, "metrics/cadvisor")
	if err != nil {
		return topology, nil // Return basic topology even if detailed info fails
	}
	// Parse NUMA information if available
	if numaInfo, ok := metricFamilies["node_numa_memory_bytes"]; ok {
		for _, metric := range numaInfo.Metric {
			if nodeIDStr := getLabel(metric, "numa_node"); nodeIDStr != "" {
				nodeID, err := strconv.ParseInt(nodeIDStr, 10, 32)
				if err != nil {
					continue
				}
				topology.NUMANodes = append(topology.NUMANodes, models.NUMANode{
					ID:     int32(nodeID),
					Memory: uint64(metric.Gauge.GetValue()),
				})
			}
		}
	}
	return topology, nil
}
func (nc *NodeCollector) collectPowerMetrics(ctx context.Context, node *v1.Node) (*models.PowerMetrics, error) {
	metricFamilies, err := FetchMetricsViaKubelet(ctx, nc.clientset, node.Name, "metrics/cadvisor")
	if err != nil {
		return nil, fmt.Errorf("failed to fetch power metrics: %w", err)
	}
	powerMetrics := &models.PowerMetrics{}
	if power, ok := metricFamilies["node_power_watts"]; ok {
		for _, metric := range power.Metric {
			if metric.Gauge != nil {
				powerMetrics.CurrentWatts = metric.Gauge.GetValue()
				break
			}
		}
	}
	return powerMetrics, nil
}
func (nc *NodeCollector) collectNodeTaintsAndTolerations(node v1.Node) []models.NodeTaint {
	taints := make([]models.NodeTaint, 0, len(node.Spec.Taints))
	for _, taint := range node.Spec.Taints {
		nodeTaint := models.NodeTaint{
			Key:    taint.Key,
			Value:  taint.Value,
			Effect: string(taint.Effect),
		}
		if taint.TimeAdded != nil {
			timeAdded := taint.TimeAdded.Time
			nodeTaint.TimeAdded = &timeAdded
		}
		taints = append(taints, nodeTaint)
	}
	return taints
}
func (nc *NodeCollector) collectNodeLease(ctx context.Context, nodeName string) (*models.NodeLease, error) {
	// If anything fails, log it and return empty lease
	if nc == nil || nc.clientset == nil {
		logrus.Warn("node collector or clientset is nil")
		return &models.NodeLease{}, nil
	}
	lease, err := nc.clientset.CoordinationV1().Leases("kube-node-lease").Get(ctx, nodeName, metav1.GetOptions{})
	if err != nil {
		logrus.WithError(err).Debug("failed to get node lease")
		return &models.NodeLease{}, nil
	}
	result := &models.NodeLease{}
	// Safely get values, defaulting to empty/zero values if nil
	if lease.Spec.HolderIdentity != nil {
		result.HolderIdentity = *lease.Spec.HolderIdentity
	}
	if lease.Spec.LeaseDurationSeconds != nil {
		result.LeaseDurationSeconds = *lease.Spec.LeaseDurationSeconds
	}
	if lease.Spec.AcquireTime != nil {
		result.AcquireTime = &lease.Spec.AcquireTime.Time
	}
	if lease.Spec.RenewTime != nil {
		result.RenewTime = &lease.Spec.RenewTime.Time
	}
	return result, nil
}
func (nc *NodeCollector) collectExtendedResources(node v1.Node) map[string]models.ExtendedResource {
	resources := make(map[string]models.ExtendedResource)
	for resourceName, quantity := range node.Status.Capacity {
		if !isStandardResource(resourceName) {
			capUnstructured := quantity.ToUnstructured()
			allocUnstructured := node.Status.Allocatable[resourceName].ToUnstructured()
			resources[string(resourceName)] = models.ExtendedResource{
				Name:        string(resourceName),
				Capacity:    fmt.Sprintf("%v", capUnstructured),
				Allocatable: fmt.Sprintf("%v", allocUnstructured),
			}
		}
	}
	return resources
}
// Helper function to identify standard resources
func isStandardResource(resourceName v1.ResourceName) bool {
	standardResources := []v1.ResourceName{
		v1.ResourceCPU,
		v1.ResourceMemory,
		v1.ResourceStorage,
		v1.ResourceEphemeralStorage,
		v1.ResourcePods,
	}
	for _, std := range standardResources {
		if resourceName == std {
			return true
		}
	}
	return false
}
func (nc *NodeCollector) collectVolumeHealthMetrics(ctx context.Context, node *v1.Node) ([]models.VolumeHealthMetrics, error) {
	pods, err := nc.clientset.CoreV1().Pods("").List(ctx, metav1.ListOptions{
		FieldSelector: fmt.Sprintf("spec.nodeName=%s", node.Name),
	})
	if err != nil {
		return nil, err
	}
	var volumeHealthMetrics []models.VolumeHealthMetrics
	for _, pod := range pods.Items {
		for _, volume := range pod.Spec.Volumes {
			if volume.PersistentVolumeClaim != nil {
				pvc, err := nc.clientset.CoreV1().PersistentVolumeClaims(pod.Namespace).Get(ctx, volume.PersistentVolumeClaim.ClaimName, metav1.GetOptions{})
				if err != nil {
					continue
				}
				metric := models.VolumeHealthMetrics{
					VolumeName: volume.Name,
					PodName:    pod.Name,
					Namespace:  pod.Namespace,
					State:      string(pvc.Status.Phase),
				}
				volumeHealthMetrics = append(volumeHealthMetrics, metric)
			}
		}
	}
	return volumeHealthMetrics, nil
}
func (nc *NodeCollector) collectVolumeAttachmentMetrics(ctx context.Context, nodeName string) ([]models.VolumeAttachmentMetrics, error) {
	// Get all volume attachments and filter by node name in memory
	attachments, err := nc.clientset.StorageV1().VolumeAttachments().List(ctx, metav1.ListOptions{})
	if err != nil {
		return nil, err
	}
	var metrics []models.VolumeAttachmentMetrics
	for _, attachment := range attachments.Items {
		// Filter for attachments matching our node
		if attachment.Spec.NodeName != nodeName {
			continue
		}
		metric := models.VolumeAttachmentMetrics{
			VolumeName: func() string {
				if attachment.Spec.Source.PersistentVolumeName != nil {
					return *attachment.Spec.Source.PersistentVolumeName
				}
				return ""
			}(),
			AttachmentState: func() string {
				if attachment.Status.Attached {
					return "attached"
				}
				return "detached"
			}(),
			AttachTime: attachment.CreationTimestamp.Time,
		}
		metrics = append(metrics, metric)
	}
	return metrics, nil
}
// CollectNodeMetrics collects all metrics for a node
func (nc *NodeCollector) CollectNodeMetrics(ctx context.Context, node *v1.Node) (*models.EnhancedNodeMetrics, error) {
	metrics := &models.EnhancedNodeMetrics{
		Name:        node.Name,
		Conditions:  nc.getNodeConditions(node),
		Labels:      node.Labels,
		Annotations: node.Annotations,
		NodeInfo:    nc.collectNodeInfo(node),
	}
	// Collect resource metrics
	metrics.Capacity = nc.parseResourceList(node.Status.Capacity)
	metrics.Allocatable = nc.parseResourceList(node.Status.Allocatable)
	// Collect all detailed metrics in parallel using goroutines
	var wg sync.WaitGroup
	var errChan = make(chan error, 15) // Buffer for potential errors
	var mu sync.Mutex
	detailedMetrics := models.NodeDetailedMetrics{}
	// Helper function to safely update metrics
	safeUpdate := func(f func()) {
		mu.Lock()
		defer mu.Unlock()
		f()
	}
	// CPU Metrics
	wg.Add(1)
	go func() {
		defer wg.Done()
		if cpuMetrics, err := nc.collectCPUMetrics(ctx, node); err == nil {
			safeUpdate(func() { detailedMetrics.CPU = cpuMetrics })
		} else {
			errChan <- fmt.Errorf("CPU metrics: %w", err)
		}
	}()
	// Memory Metrics
	wg.Add(1)
	go func() {
		defer wg.Done()
		if memMetrics, err := nc.collectMemoryMetrics(ctx, node); err == nil {
			safeUpdate(func() { detailedMetrics.Memory = memMetrics })
		} else {
			errChan <- fmt.Errorf("memory metrics: %w", err)
		}
	}()
	// Network Metrics
	wg.Add(1)
	go func() {
		defer wg.Done()
		if netMetrics, err := nc.collectNetworkMetrics(ctx, node); err == nil {
			safeUpdate(func() { detailedMetrics.Network = netMetrics })
		} else {
			errChan <- fmt.Errorf("network metrics: %w", err)
		}
	}()
	// Disk Metrics
	wg.Add(1)
	go func() {
		defer wg.Done()
		if diskMetrics, err := nc.collectDiskMetrics(ctx, node); err == nil {
			safeUpdate(func() { detailedMetrics.DiskIO = diskMetrics })
		} else {
			errChan <- fmt.Errorf("disk metrics: %w", err)
		}
	}()
	// Filesystem Metrics
	wg.Add(1)
	go func() {
		defer wg.Done()
		if fsMetrics, err := nc.collectFilesystemMetrics(ctx, node); err == nil {
			safeUpdate(func() { detailedMetrics.Filesystem = fsMetrics })
		} else {
			errChan <- fmt.Errorf("filesystem metrics: %w", err)
		}
	}()
	// Process Metrics
	wg.Add(1)
	go func() {
		defer wg.Done()
		if procMetrics, err := nc.collectProcessMetrics(ctx, node); err == nil {
			safeUpdate(func() { detailedMetrics.Process = procMetrics })
		} else {
			errChan <- fmt.Errorf("process metrics: %w", err)
		}
	}()
	// Runtime Metrics
	wg.Add(1)
	go func() {
		defer wg.Done()
		if runtimeMetrics, err := nc.collectRuntimeMetrics(ctx, node); err == nil {
			safeUpdate(func() { detailedMetrics.Runtime = runtimeMetrics })
		} else {
			errChan <- fmt.Errorf("runtime metrics: %w", err)
		}
	}()
	// System Metrics
	wg.Add(1)
	go func() {
		defer wg.Done()
		if sysMetrics, err := nc.collectSystemMetrics(ctx, node); err == nil {
			safeUpdate(func() { detailedMetrics.System = sysMetrics })
		} else {
			errChan <- fmt.Errorf("system metrics: %w", err)
		}
	}()
	// Volume Metrics
	wg.Add(1)
	go func() {
		defer wg.Done()
		if volMetrics, err := nc.collectVolumeMetrics(ctx, node); err == nil {
			safeUpdate(func() { detailedMetrics.Volume = volMetrics })
		} else {
			errChan <- fmt.Errorf("volume metrics: %w", err)
		}
	}()
	// Container Stats
	wg.Add(1)
	go func() {
		defer wg.Done()
		if containerStats, err := nc.collectContainerStats(ctx, node); err == nil {
			safeUpdate(func() { detailedMetrics.Container = containerStats })
		} else {
			errChan <- fmt.Errorf("container stats: %w", err)
		}
	}()
	// Hardware Topology
	wg.Add(1)
	go func() {
		defer wg.Done()
		if topology, err := nc.collectHardwareTopology(ctx, node); err == nil {
			safeUpdate(func() { metrics.HardwareTopology = topology })
		} else {
			errChan <- fmt.Errorf("hardware topology: %w", err)
		}
	}()
	// Power Metrics
	wg.Add(1)
	go func() {
		defer wg.Done()
		if powerMetrics, err := nc.collectPowerMetrics(ctx, node); err == nil {
			safeUpdate(func() { metrics.PowerMetrics = powerMetrics })
		} else {
			errChan <- fmt.Errorf("power metrics: %w", err)
		}
	}()
	// Volume Health
	wg.Add(1)
	go func() {
		defer wg.Done()
		if volumeHealth, err := nc.collectVolumeHealthMetrics(ctx, node); err == nil {
			safeUpdate(func() { metrics.VolumeHealth = volumeHealth })
		} else {
			errChan <- fmt.Errorf("volume health: %w", err)
		}
	}()
	// Volume Attachments
	wg.Add(1)
	go func() {
		defer wg.Done()
		if attachments, err := nc.collectVolumeAttachmentMetrics(ctx, node.Name); err == nil {
			safeUpdate(func() { metrics.VolumeAttachments = attachments })
		} else {
			errChan <- fmt.Errorf("volume attachments: %w", err)
		}
	}()
	// Node Lease
	wg.Add(1)
	go func() {
		defer wg.Done()
		lease, _ := nc.collectNodeLease(ctx, node.Name) // Ignore error as we always return a value
		safeUpdate(func() {
			metrics.Lease = lease
		})
	}()
	// Wait for all collectors to complete
	wg.Wait()
	close(errChan)
	// Collect any errors
	var errors []string
	for err := range errChan {
		errors = append(errors, err.Error())
	}
	// Add non-parallel collections
	metrics.Taints = nc.collectNodeTaintsAndTolerations(*node)
	metrics.ExtendedResources = nc.collectExtendedResources(*node)
	metrics.DetailedMetrics = detailedMetrics
	// If there were any errors, log them but don't fail the entire collection
	if len(errors) > 0 {
		logrus.WithField("errors", strings.Join(errors, "; ")).
			Warn("Some metrics collections failed")
	}
	return metrics, nil
}
func (nc *NodeCollector) getNodeConditions(node *v1.Node) models.NodeConditions {
	conditions := models.NodeConditions{}
	for _, condition := range node.Status.Conditions {
		switch condition.Type {
		case v1.NodeReady:
			conditions.Ready = condition.Status == v1.ConditionTrue
		case v1.NodeMemoryPressure:
			conditions.MemoryPressure = condition.Status == v1.ConditionTrue
		case v1.NodeDiskPressure:
			conditions.DiskPressure = condition.Status == v1.ConditionTrue
		case v1.NodePIDPressure:
			conditions.PIDPressure = condition.Status == v1.ConditionTrue
		}
	}
	return conditions
}
// Helper function to get label value
func getLabel(metric *dto.Metric, name string) string {
	for _, label := range metric.Label {
		if label.GetName() == name {
			return label.GetValue()
		}
	}
	return ""
}
</file>

<file path="pkg/collectors/pod.go">
// Copyright 2024 Vega Cloud, Inc.
//
// Use of this software is governed by the Business Source License
// included in the file licenses/BSL.txt.
//
// As of the Change Date specified in that file, in accordance with
// the Business Source License, use of this software will be governed
// by the Apache License, Version 2.0, included in the file
// licenses/APL.txt.
// File: pkg/collectors/pod.go
// Package collectors hosts the collection functions
package collectors
import (
	"context"
	"crypto/tls"
	"fmt"
	"net/http"
	"os"
	"time"
	"github.com/prometheus/common/expfmt"
	"github.com/sirupsen/logrus"
	v1 "k8s.io/api/core/v1"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/apimachinery/pkg/labels"
	"k8s.io/client-go/kubernetes"
	"github.com/vegacloud/kubernetes/metricsagent/pkg/config"
	"github.com/vegacloud/kubernetes/metricsagent/pkg/models"
	"github.com/vegacloud/kubernetes/metricsagent/pkg/utils"
)
// PodCollector collects metrics for all pods in the cluster
type PodCollector struct {
	clientset  *kubernetes.Clientset
	config     *config.Config
	httpClient *http.Client
}
// NewPodCollector creates a new PodCollector
func NewPodCollector(clientset *kubernetes.Clientset, cfg *config.Config) *PodCollector {
	logrus.Debug("Starting PodCollector")
	// Initialize HTTP client with reasonable defaults
	httpClient := &http.Client{
		Timeout:   time.Second * 10,
		Transport: &http.Transport{TLSClientConfig: &tls.Config{InsecureSkipVerify: cfg.VegaInsecure}}, // #nosec G402
	}
	logrus.Debug("PodCollector created successfully")
	return &PodCollector{
		clientset:  clientset,
		config:     cfg,
		httpClient: httpClient,
	}
}
// CollectMetrics collects metrics for all pods in the cluster
func (pc *PodCollector) CollectMetrics(ctx context.Context) (interface{}, error) {
	logrus.WithField("collector", "PodCollector")
	// Verify client identity before collecting metrics
	if err := VerifyCollectorClient(ctx, pc.clientset, pc.config.VegaNamespace, "PodCollector"); err != nil {
		return nil, err
	}
	metrics, err := pc.CollectEnhancedPodMetrics(ctx)
	if err != nil {
		return nil, err
	}
	logrus.Debug("Successfully collected pod metrics")
	return metrics, nil
}
// CollectEnhancedPodMetrics collects metrics from Kubernetes pods.
func (pc *PodCollector) CollectEnhancedPodMetrics(ctx context.Context) ([]models.EnhancedPodMetrics, error) {
	pods, err := pc.clientset.CoreV1().Pods("").List(ctx, metav1.ListOptions{})
	if err != nil {
		return nil, fmt.Errorf("failed to list pods: %w", err)
	}
	logrus.Debugf("Successfully listed %d pods", len(pods.Items))
	enhancedPodMetrics := make([]models.EnhancedPodMetrics, 0, len(pods.Items))
	for _, pod := range pods.Items {
		metrics, err := pc.collectSinglePodMetrics(ctx, pod)
		if err != nil {
			logrus.Warnf("Failed to collect metrics for pod %s/%s: %v", pod.Namespace, pod.Name, err)
			continue
		}
		enhancedPodMetrics = append(enhancedPodMetrics, metrics)
	}
	logrus.Debug("Successfully collected enhanced pod metrics")
	return enhancedPodMetrics, nil
}
func (pc *PodCollector) collectSinglePodMetrics(ctx context.Context, pod v1.Pod) (models.EnhancedPodMetrics, error) {
	if pod.Labels == nil {
		pod.Labels = make(map[string]string)
	}
	metrics := models.EnhancedPodMetrics{
		PodMetrics: models.PodMetrics{
			Name:      pod.Name,
			Namespace: pod.Namespace,
			Phase:     string(pod.Status.Phase),
			Labels:    pod.Labels,
		},
		QoSClass: string(pod.Status.QOSClass),
		StartTime: func() *time.Time {
			if pod.Status.StartTime != nil {
				t := pod.Status.StartTime.Time
				return &t
			}
			return nil
		}(),
		Priority:          pod.Spec.Priority,
		PriorityClassName: pod.Spec.PriorityClassName,
		NodeName:          pod.Spec.NodeName,
		HostIP:            pod.Status.HostIP,
		NominatedNodeName: pod.Status.NominatedNodeName,
	}
	// Set QoSClass in the nested PodMetrics object
	metrics.PodMetrics.QoSClass = string(pod.Status.QOSClass)
	// Collect Pod IPs
	podIPs := make([]string, 0, len(pod.Status.PodIPs))
	for _, ip := range pod.Status.PodIPs {
		podIPs = append(podIPs, ip.IP)
	}
	metrics.PodIPs = podIPs
	// Collect Readiness Gates
	readinessGates := make([]models.PodReadinessGate, 0, len(pod.Spec.ReadinessGates))
	for _, gate := range pod.Spec.ReadinessGates {
		status := false
		for _, condition := range pod.Status.Conditions {
			if string(condition.Type) == string(gate.ConditionType) {
				status = condition.Status == v1.ConditionTrue
				break
			}
		}
		readinessGates = append(readinessGates, models.PodReadinessGate{
			ConditionType: string(gate.ConditionType),
			Status:        status,
		})
	}
	metrics.ReadinessGates = readinessGates
	// Collect Pod Conditions
	for _, condition := range pod.Status.Conditions {
		switch condition.Type {
		case v1.PodScheduled:
			metrics.Conditions.PodScheduled = condition.Status == v1.ConditionTrue
		case v1.PodInitialized:
			metrics.Conditions.Initialized = condition.Status == v1.ConditionTrue
		case v1.ContainersReady:
			metrics.Conditions.ContainersReady = condition.Status == v1.ConditionTrue
		case v1.PodReady:
			metrics.Conditions.Ready = condition.Status == v1.ConditionTrue
		}
	}
	// Copy conditions to the nested PodMetrics object
	metrics.PodMetrics.Conditions = metrics.Conditions
	// Collect Resource Metrics
	for _, container := range pod.Spec.Containers {
		metrics.Requests.CPU += container.Resources.Requests.Cpu().MilliValue()
		metrics.Requests.Memory += container.Resources.Requests.Memory().Value()
		metrics.Limits.CPU += container.Resources.Limits.Cpu().MilliValue()
		metrics.Limits.Memory += container.Resources.Limits.Memory().Value()
	}
	// Copy resource metrics to the nested PodMetrics object
	metrics.PodMetrics.Requests = metrics.Requests
	metrics.PodMetrics.Limits = metrics.Limits
	// Get Pod Metrics from Kubelet
	podMetrics, err := pc.getPodMetrics(ctx, &pod)
	if err != nil {
		return metrics, fmt.Errorf("failed to get pod metrics: %w", err)
	}
	// Save our current resource values that we want to preserve
	savedRequests := metrics.PodMetrics.Requests
	savedLimits := metrics.PodMetrics.Limits
	savedQoSClass := metrics.PodMetrics.QoSClass
	savedConditions := metrics.PodMetrics.Conditions
	// Update metrics.PodMetrics with the data from podMetrics
	metrics.PodMetrics = *podMetrics
	// Restore the important resource values we want to preserve
	// These values are more accurate than what might be in podMetrics
	metrics.PodMetrics.Requests = savedRequests
	metrics.PodMetrics.Limits = savedLimits
	metrics.PodMetrics.QoSClass = savedQoSClass
	metrics.PodMetrics.Conditions = savedConditions
	// Extract containers from the pod metrics
	metrics.Containers = pc.extractContainerMetrics(pod, podMetrics)
	metrics.TotalRestarts = pc.getTotalRestarts(pod)
	// Set completion time for completed pods
	if pod.Status.Phase == v1.PodSucceeded || pod.Status.Phase == v1.PodFailed {
		for _, containerStatus := range pod.Status.ContainerStatuses {
			if containerStatus.State.Terminated != nil {
				metrics.CompletionTime = &containerStatus.State.Terminated.FinishedAt.Time
				break
			}
		}
	}
	// Add annotations
	metrics.Annotations = pod.Annotations
	// Add volume mounts
	metrics.VolumeMounts = make([]models.VolumeMountMetrics, 0)
	for _, container := range pod.Spec.Containers {
		for _, volumeMount := range container.VolumeMounts {
			metrics.VolumeMounts = append(metrics.VolumeMounts, models.VolumeMountMetrics{
				Name:        volumeMount.Name,
				MountPath:   volumeMount.MountPath,
				ReadOnly:    volumeMount.ReadOnly,
				SubPath:     volumeMount.SubPath,
				SubPathExpr: volumeMount.SubPathExpr,
				MountPropagation: func() string {
					if volumeMount.MountPropagation != nil {
						return string(*volumeMount.MountPropagation)
					}
					return ""
				}(),
			})
		}
	}
	// Add image pull policy
	imagePullPolicies := make([]string, 0)
	for _, container := range pod.Spec.Containers {
		imagePullPolicies = append(imagePullPolicies, string(container.ImagePullPolicy))
	}
	// Use the most common pull policy, or "Mixed" if there are different policies
	if len(imagePullPolicies) > 0 {
		allSame := true
		for i := 1; i < len(imagePullPolicies); i++ {
			if imagePullPolicies[i] != imagePullPolicies[0] {
				allSame = false
				break
			}
		}
		if allSame {
			metrics.ImagePullPolicy = imagePullPolicies[0]
		} else {
			metrics.ImagePullPolicy = "Mixed"
		}
	}
	// Add service account information
	metrics.ServiceAccountName = pod.Spec.ServiceAccountName
	// Collect PDB metrics
	pdbMetrics, err := pc.collectPodDisruptionBudget(ctx, pod)
	if err != nil {
		logrus.Warnf("Failed to collect PDB metrics for pod %s/%s: %v", pod.Namespace, pod.Name, err)
	} else {
		metrics.DisruptionBudget = pdbMetrics
	}
	// Collect topology spread constraints
	metrics.TopologySpread = pc.collectTopologySpread(pod)
	// Collect pod overhead
	if pod.Spec.Overhead != nil {
		metrics.Overhead = &models.PodOverheadMetrics{
			CPU:    pod.Spec.Overhead.Cpu().String(),
			Memory: pod.Spec.Overhead.Memory().String(),
		}
	}
	// Collect scheduling gates
	for _, gate := range pod.Spec.SchedulingGates {
		metrics.SchedulingGates = append(metrics.SchedulingGates, models.PodSchedulingGate{
			Name:   gate.Name,
			Active: true,
		})
	}
	// Collect QoS details
	metrics.QoSDetails = pc.collectQoSDetails(pod)
	logrus.Debugf("Successfully collected metrics for pod %s/%s", pod.Namespace, pod.Name)
	return metrics, nil
}
func (pc *PodCollector) getPodMetrics(ctx context.Context, pod *v1.Pod) (*models.PodMetrics, error) {
	// Initialize metrics structure with the pod's basic info and resource data
	metrics := &models.PodMetrics{
		Name:       pod.Name,
		Namespace:  pod.Namespace,
		Phase:      string(pod.Status.Phase),
		Labels:     pod.Labels,
		QoSClass:   string(pod.Status.QOSClass),
		Usage:      models.ResourceMetrics{},
		Containers: make([]models.ContainerMetrics, 0),
	}
	// Set conditions from the pod status
	for _, condition := range pod.Status.Conditions {
		switch condition.Type {
		case v1.PodScheduled:
			metrics.Conditions.PodScheduled = condition.Status == v1.ConditionTrue
		case v1.PodInitialized:
			metrics.Conditions.Initialized = condition.Status == v1.ConditionTrue
		case v1.ContainersReady:
			metrics.Conditions.ContainersReady = condition.Status == v1.ConditionTrue
		case v1.PodReady:
			metrics.Conditions.Ready = condition.Status == v1.ConditionTrue
		}
	}
	// Calculate resource requests and limits
	for _, container := range pod.Spec.Containers {
		metrics.Requests.CPU += container.Resources.Requests.Cpu().MilliValue()
		metrics.Requests.Memory += container.Resources.Requests.Memory().Value()
		metrics.Limits.CPU += container.Resources.Limits.Cpu().MilliValue()
		metrics.Limits.Memory += container.Resources.Limits.Memory().Value()
	}
	// First, try to get metrics using the metrics.k8s.io API
	config, err := utils.GetExistingClientConfig()
	var gotUsageMetrics bool
	if err == nil {
		// Try the direct metrics API call
		apiMetrics, apiErr := utils.GetPodMetricsFromAPI(ctx, pc.clientset, config.Config, pod.Namespace, pod.Name)
		if apiErr == nil && apiMetrics != nil && len(apiMetrics.Containers) > 0 {
			logrus.Debugf("Successfully retrieved pod metrics from metrics.k8s.io API for %s/%s", pod.Namespace, pod.Name)
			// Reset CPU and memory usage values to ensure clean counting
			metrics.Usage.CPU = 0
			metrics.Usage.Memory = 0
			// Extract usage data from API metrics
			for _, container := range apiMetrics.Containers {
				if container.Usage.Cpu() != nil {
					cpuMilliValue := container.Usage.Cpu().MilliValue()
					metrics.Usage.CPU += cpuMilliValue
					logrus.Debugf("Container %s CPU usage: %d millicores", container.Name, cpuMilliValue)
				}
				if container.Usage.Memory() != nil {
					memoryValue := container.Usage.Memory().Value()
					metrics.Usage.Memory += memoryValue
					logrus.Debugf("Container %s Memory usage: %d bytes", container.Name, memoryValue)
				}
				// Create a container metrics entry
				containerMetric := models.ContainerMetrics{
					Name:       container.Name,
					UsageNanos: container.Usage.Cpu().MilliValue() * 1000000, // Convert millicores to nanoseconds
					UsageBytes: container.Usage.Memory().Value(),
				}
				// Set CPU usage field
				containerMetric.CPU.UsageTotal = uint64(container.Usage.Cpu().MilliValue() * 1000000)
				// Set memory metrics
				containerMetric.Memory = models.MemoryMetrics{
					Used:       uint64(container.Usage.Memory().Value()),
					WorkingSet: uint64(container.Usage.Memory().Value()),
				}
				metrics.Containers = append(metrics.Containers, containerMetric)
			}
			// If we've successfully retrieved metrics from the API, mark as successful
			if metrics.Usage.CPU > 0 || metrics.Usage.Memory > 0 {
				logrus.Infof("Got valid usage metrics from metrics.k8s.io API for pod %s/%s: CPU=%d Memory=%d",
					pod.Namespace, pod.Name, metrics.Usage.CPU, metrics.Usage.Memory)
				gotUsageMetrics = true
			}
		} else {
			logrus.Debugf("Could not get pod metrics from metrics.k8s.io API for %s/%s: %v", pod.Namespace, pod.Name, apiErr)
		}
	}
	// If the metrics.k8s.io API fails or returns empty data, fall back to kubelet metrics
	if !gotUsageMetrics {
		logrus.Debugf("Falling back to kubelet metrics for pod %s/%s", pod.Namespace, pod.Name)
		// Skip metrics collection if pod is not running on a node
		if pod.Spec.NodeName == "" {
			logrus.Debugf("Pod %s/%s is not scheduled on any node, skipping metrics collection", pod.Namespace, pod.Name)
			return metrics, nil
		}
		// Get node internal IP where the pod is running
		node, err := pc.clientset.CoreV1().Nodes().Get(ctx, pod.Spec.NodeName, metav1.GetOptions{})
		if err != nil {
			logrus.Warnf("Failed to get node info for pod %s/%s: %v", pod.Namespace, pod.Name, err)
			return metrics, nil
		}
		var nodeAddress string
		for _, addr := range node.Status.Addresses {
			if addr.Type == v1.NodeInternalIP {
				nodeAddress = addr.Address
				break
			}
		}
		if nodeAddress == "" {
			logrus.Warnf("No internal IP found for node %s", pod.Spec.NodeName)
			return metrics, nil
		}
		// Ensure HTTP client exists
		if pc.httpClient == nil {
			logrus.Warn("HTTP client not initialized, creating default client")
			pc.httpClient = &http.Client{
				Timeout:   time.Second * 10,
				Transport: &http.Transport{TLSClientConfig: &tls.Config{InsecureSkipVerify: pc.config.VegaInsecure}}, // #nosec G402
			}
		}
		// Construct URL for kubelet metrics
		metricsURL := fmt.Sprintf("https://%s:10250/metrics/resource", nodeAddress)
		// Create request
		req, err := http.NewRequestWithContext(ctx, "GET", metricsURL, nil)
		if err != nil {
			logrus.Warnf("Failed to create request for pod %s/%s: %v", pod.Namespace, pod.Name, err)
			return metrics, nil
		}
		// Get bearer token from service account
		token, err := os.ReadFile("/var/run/secrets/kubernetes.io/serviceaccount/token")
		if err != nil {
			logrus.Warnf("Failed to read service account token: %v", err)
			return metrics, nil
		}
		req.Header.Set("Authorization", "Bearer "+string(token))
		// Make request
		resp, err := pc.httpClient.Do(req)
		if err != nil {
			logrus.Warnf("Failed to get metrics from kubelet for pod %s/%s: %v", pod.Namespace, pod.Name, err)
			return metrics, nil
		}
		defer resp.Body.Close()
		// Parse metrics
		var parser expfmt.TextParser
		metricFamilies, err := parser.TextToMetricFamilies(resp.Body)
		if err != nil {
			logrus.Warnf("Failed to parse metrics for pod %s/%s: %v", pod.Namespace, pod.Name, err)
			return metrics, nil
		}
		containerMetrics := make(map[string]*models.ContainerMetrics)
		// Parse container metrics for the pod
		for _, family := range metricFamilies {
			for _, metric := range family.Metric {
				labels := make(map[string]string)
				for _, label := range metric.Label {
					labels[*label.Name] = *label.Value
				}
				// Match metrics for this specific pod
				if labels["pod"] == pod.Name && labels["namespace"] == pod.Namespace {
					containerName := labels["container"]
					// Initialize container metrics if not exists
					if _, exists := containerMetrics[containerName]; !exists {
						containerMetrics[containerName] = &models.ContainerMetrics{
							Name: containerName,
						}
					}
					// Update container metrics based on metric type
					switch family.GetName() {
					case "container_cpu_usage_seconds_total":
						value := int64(*metric.Counter.Value * 1000) // Convert to millicores
						containerMetrics[containerName].UsageNanos = value
						metrics.Usage.CPU += value
					case "container_memory_working_set_bytes":
						value := int64(*metric.Gauge.Value)
						containerMetrics[containerName].UsageBytes = value
						containerMetrics[containerName].Memory.WorkingSet = uint64(*metric.Gauge.Value)
						metrics.Usage.Memory += value
					}
				}
			}
		}
		// Convert map to slice
		for _, cm := range containerMetrics {
			metrics.Containers = append(metrics.Containers, *cm)
		}
	}
	return metrics, nil
}
func (pc *PodCollector) extractContainerMetrics(
	pod v1.Pod,
	podMetrics *models.PodMetrics,
) []models.ContainerMetrics {
	containerMetrics := make([]models.ContainerMetrics, 0, len(pod.Status.ContainerStatuses))
	for _, container := range pod.Status.ContainerStatuses {
		metrics := models.ContainerMetrics{
			Name:         container.Name,
			RestartCount: container.RestartCount,
			Ready:        container.Ready,
			State:        getContainerState(container.State),
		}
		if container.LastTerminationState.Terminated != nil {
			metrics.LastTerminationReason = container.LastTerminationState.Terminated.Reason
		}
		// Match container usage from podMetrics
		for _, containerName := range podMetrics.Containers {
			if containerName.Name == container.Name {
				metrics.CPU = containerName.CPU
				metrics.Memory = containerName.Memory
				break
			}
		}
		containerMetrics = append(containerMetrics, metrics)
	}
	logrus.Debugf("Successfully extracted container metrics for pod %s/%s", pod.Namespace, pod.Name)
	return containerMetrics
}
func (pc *PodCollector) getTotalRestarts(pod v1.Pod) int32 {
	var totalRestarts int32
	for _, containerStatus := range pod.Status.ContainerStatuses {
		totalRestarts += containerStatus.RestartCount
	}
	logrus.Debugf("Total restarts for pod %s/%s: %d", pod.Namespace, pod.Name, totalRestarts)
	return totalRestarts
}
func getContainerState(state v1.ContainerState) string {
	if state.Running != nil {
		return "Running"
	}
	if state.Waiting != nil {
		return "Waiting"
	}
	if state.Terminated != nil {
		return "Terminated"
	}
	return "Unknown"
}
func (pc *PodCollector) collectPodDisruptionBudget(ctx context.Context, pod v1.Pod) (*models.PodDisruptionBudgetMetrics, error) {
	pdbs, err := pc.clientset.PolicyV1().PodDisruptionBudgets(pod.Namespace).List(ctx, metav1.ListOptions{})
	if err != nil {
		return nil, err
	}
	for _, pdb := range pdbs.Items {
		selector, err := metav1.LabelSelectorAsSelector(pdb.Spec.Selector)
		if err != nil {
			continue
		}
		if selector.Matches(labels.Set(pod.Labels)) {
			return &models.PodDisruptionBudgetMetrics{
				MinAvailable:       pdb.Spec.MinAvailable.String(),
				MaxUnavailable:     pdb.Spec.MaxUnavailable.String(),
				CurrentHealthy:     pdb.Status.CurrentHealthy,
				DesiredHealthy:     pdb.Status.DesiredHealthy,
				DisruptionsAllowed: pdb.Status.DisruptionsAllowed,
				ExpectedPods:       pdb.Status.ExpectedPods,
			}, nil
		}
	}
	return nil, nil
}
func (pc *PodCollector) collectTopologySpread(pod v1.Pod) []models.TopologySpreadConstraint {
	var constraints []models.TopologySpreadConstraint
	for _, constraint := range pod.Spec.TopologySpreadConstraints {
		constraints = append(constraints, models.TopologySpreadConstraint{
			MaxSkew:           constraint.MaxSkew,
			TopologyKey:       constraint.TopologyKey,
			WhenUnsatisfiable: string(constraint.WhenUnsatisfiable),
			LabelSelector:     constraint.LabelSelector.String(),
			MinDomains:        constraint.MinDomains,
		})
	}
	return constraints
}
func (pc *PodCollector) collectQoSDetails(pod v1.Pod) *models.QoSMetrics {
	qosMetrics := &models.QoSMetrics{
		Class:            string(pod.Status.QOSClass),
		CPUGuaranteed:    true,
		MemoryGuaranteed: true,
	}
	for _, container := range pod.Spec.Containers {
		if container.Resources.Requests.Cpu().IsZero() {
			qosMetrics.CPUGuaranteed = false
		}
		if container.Resources.Requests.Memory().IsZero() {
			qosMetrics.MemoryGuaranteed = false
		}
	}
	return qosMetrics
}
</file>

<file path="pkg/utils/metrics_test.go">
// Package utils provides utility functions for the agent
// Copyright 2024 Vega Cloud, Inc.
//
// Use of this software is governed by the Business Source License
// included in the file licenses/BSL.txt.
//
// As of the Change Date specified in that file, in accordance with
// the Business Source License, use of this software will be governed
// by the Apache License, Version 2.0, included in the file
// licenses/APL.txt.
package utils
import (
	"context"
	"testing"
	"k8s.io/client-go/kubernetes"
	"k8s.io/client-go/rest"
)
func TestGetMetricsClient(t *testing.T) {
	// Create a fake config
	config := &rest.Config{}
	// Test if the metrics client is created successfully
	client, err := GetMetricsClient(config)
	if err != nil {
		t.Fatalf("Failed to create metrics client: %v", err)
	}
	if client == nil {
		t.Fatal("Expected metrics client to be created, got nil")
	}
}
func TestNodeAndPodMetricsFromAPI(t *testing.T) {
	// We won't use real metrics calls in unit tests
	// Instead, we'll ensure the functions exist and have the correct signatures
	// We're going to test if the functions compile with correct types, not actual functionality
	var _ = func() {
		ctx := context.Background()
		clientset := &kubernetes.Clientset{}
		config := &rest.Config{}
		// Test GetNodeMetricsFromAPI
		_, err := GetNodeMetricsFromAPI(ctx, clientset, config, "test-node")
		if err != nil {
			// We expect this to fail in tests since we don't have real clients
			// but we're only checking method signatures
		}
		// Test GetPodMetricsFromAPI
		_, err = GetPodMetricsFromAPI(ctx, clientset, config, "default", "test-pod")
		if err != nil {
			// Similarly, this would fail but we're checking signatures
		}
	}
}
// This test uses fake clients to ensure the function integration works
func TestMetricsIntegration(t *testing.T) {
	t.Skip("This test requires a real Kubernetes cluster and is meant for manual execution only")
	// This test would be run manually against a real cluster
	// In a real environment, we'd set up the following:
	/*
		ctx := context.Background()
		config, err := rest.InClusterConfig()
		if err != nil {
			t.Fatalf("Failed to get in-cluster config: %v", err)
		}
		clientset, err := kubernetes.NewForConfig(config)
		if err != nil {
			t.Fatalf("Failed to create clientset: %v", err)
		}
		// Test node metrics
		nodeMetrics, err := GetNodeMetricsFromAPI(ctx, clientset, config, "some-node-name")
		if err != nil {
			t.Fatalf("Failed to get node metrics: %v", err)
		}
		if nodeMetrics == nil {
			t.Fatal("Expected node metrics, got nil")
		}
		// Test pod metrics
		podMetrics, err := GetPodMetricsFromAPI(ctx, clientset, config, "default", "some-pod-name")
		if err != nil {
			t.Fatalf("Failed to get pod metrics: %v", err)
		}
		if podMetrics == nil {
			t.Fatal("Expected pod metrics, got nil")
		}
	*/
}
</file>

<file path="pkg/utils/metrics.go">
// Package utils provides utility functions for the agent
// Copyright 2024 Vega Cloud, Inc.
//
// Use of this software is governed by the Business Source License
// included in the file licenses/BSL.txt.
//
// As of the Change Date specified in that file, in accordance with
// the Business Source License, use of this software will be governed
// by the Apache License, Version 2.0, included in the file
// licenses/APL.txt.
package utils
import (
	"context"
	"fmt"
	"sync"
	"github.com/sirupsen/logrus"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/client-go/kubernetes"
	"k8s.io/client-go/rest"
	metricsapi "k8s.io/metrics/pkg/apis/metrics/v1beta1"
	metricsv "k8s.io/metrics/pkg/client/clientset/versioned"
)
var (
	metricsClientInstance *metricsv.Clientset
	metricsClientOnce     sync.Once
)
// MetricsClientConfig holds the Kubernetes metrics clientset
type MetricsClientConfig struct {
	MetricsClientset *metricsv.Clientset
}
// GetMetricsClient returns a metrics client for the metrics.k8s.io API
func GetMetricsClient(config *rest.Config) (*metricsv.Clientset, error) {
	var err error
	metricsClientOnce.Do(func() {
		metricsClientInstance, err = metricsv.NewForConfig(config)
		if err != nil {
			logrus.WithError(err).Error("Failed to create metrics client")
		}
		logrus.Debug("Metrics client created successfully")
	})
	if err != nil {
		return nil, fmt.Errorf("failed to create metrics client: %w", err)
	}
	return metricsClientInstance, nil
}
// GetNodeMetricsFromAPI fetches node metrics using the metrics.k8s.io API
func GetNodeMetricsFromAPI(ctx context.Context, clientset *kubernetes.Clientset, config *rest.Config, nodeName string) (*metricsapi.NodeMetrics, error) {
	metricsClient, err := GetMetricsClient(config)
	if err != nil {
		return nil, err
	}
	// If nodeName is empty, we want to get metrics for all nodes
	if nodeName == "" {
		logrus.Debug("No node name specified, returning nil")
		return nil, nil
	}
	nodeMetrics, err := metricsClient.MetricsV1beta1().NodeMetricses().Get(ctx, nodeName, metav1.GetOptions{})
	if err != nil {
		return nil, fmt.Errorf("failed to get metrics for node %s: %w", nodeName, err)
	}
	return nodeMetrics, nil
}
// GetAllNodeMetricsFromAPI fetches metrics for all nodes using the metrics.k8s.io API
func GetAllNodeMetricsFromAPI(ctx context.Context, clientset *kubernetes.Clientset, config *rest.Config) (*metricsapi.NodeMetricsList, error) {
	metricsClient, err := GetMetricsClient(config)
	if err != nil {
		return nil, err
	}
	nodeMetrics, err := metricsClient.MetricsV1beta1().NodeMetricses().List(ctx, metav1.ListOptions{})
	if err != nil {
		return nil, fmt.Errorf("failed to list node metrics: %w", err)
	}
	return nodeMetrics, nil
}
// GetPodMetricsFromAPI fetches pod metrics using the metrics.k8s.io API
func GetPodMetricsFromAPI(ctx context.Context, clientset *kubernetes.Clientset, config *rest.Config, namespace, podName string) (*metricsapi.PodMetrics, error) {
	metricsClient, err := GetMetricsClient(config)
	if err != nil {
		return nil, err
	}
	// If podName is empty, we want to get metrics for all pods in the namespace
	if podName == "" {
		logrus.Debug("No pod name specified, returning nil")
		return nil, nil
	}
	podMetrics, err := metricsClient.MetricsV1beta1().PodMetricses(namespace).Get(ctx, podName, metav1.GetOptions{})
	if err != nil {
		return nil, fmt.Errorf("failed to get metrics for pod %s/%s: %w", namespace, podName, err)
	}
	return podMetrics, nil
}
// GetAllPodMetricsFromAPI fetches metrics for all pods using the metrics.k8s.io API
func GetAllPodMetricsFromAPI(ctx context.Context, clientset *kubernetes.Clientset, config *rest.Config, namespace string) (*metricsapi.PodMetricsList, error) {
	metricsClient, err := GetMetricsClient(config)
	if err != nil {
		return nil, err
	}
	// If namespace is empty, get metrics for pods in all namespaces
	podMetrics, err := metricsClient.MetricsV1beta1().PodMetricses(namespace).List(ctx, metav1.ListOptions{})
	if err != nil {
		return nil, fmt.Errorf("failed to list pod metrics for namespace %s: %w", namespace, err)
	}
	return podMetrics, nil
}
</file>

<file path=".gitignore">
# Ignore all Chart.lock files
**/Chart.lock
bin/*
charts/vega-metrics-agent/values-devlocal.yaml
charts/vega-metrics-agent/values-*.yaml
</file>

<file path="charts/vega-metrics-agent/templates/deployment.yaml">
# Copyright 2024 Vega Cloud, Inc.
#
# Use of this software is governed by the Business Source License
# included in the file licenses/BSL.txt.
#
# As of the Change Date specified in that file, in accordance with
# the Business Source License, use of this software will be governed
# by the Apache License, Version 2.0, included in the file
# licenses/APL.txt.
apiVersion: apps/v1
kind: Deployment
metadata:
  name: metrics-agent
  namespace: "{{ .Values.namespace }}"
  labels:
    app: metrics-agent
  annotations:
    "helm.sh/hook-weight": "5"
    "helm.sh/hook-depends-on": "pre-install"
spec:
  replicas: {{ .Values.replicaCount }}
  selector:
    matchLabels:
      app: metrics-agent
  template:
    metadata:
      labels:
        app: metrics-agent
    spec:
      serviceAccountName: {{ .Values.serviceAccount.name }}
      automountServiceAccountToken: true
      # Add node selector if provided
      {{- with .Values.nodeSelector }}
      nodeSelector:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      # Add affinity rules if provided
      {{- with .Values.affinity }}
      affinity:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      # Add tolerations if provided
      {{- with .Values.tolerations }}
      tolerations:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      initContainers:
        - name: wait-for-permissions
          image: bitnami/kubectl:1.30.7
          command: ['sh', '-c', 'until kubectl auth can-i list pods --all-namespaces; do echo waiting for permissions; sleep 2; done']
      containers:
        - name: metrics-agent
          image: "{{ .Values.image.repository }}:{{ .Values.image.tag }}"
          imagePullPolicy: "{{ .Values.image.pullPolicy }}"
          args:
            - 'kubernetes'
          env:
            - name: KUBERNETES_CLIENT_LOG_LEVEL
              value: "8"
            - name: VEGA_CLIENT_ID
              valueFrom:
                secretKeyRef:
                  name: vega-metrics-agent-secret
                  key: VEGA_CLIENT_ID
            - name: VEGA_CLIENT_SECRET
              valueFrom:
                secretKeyRef:
                  name: vega-metrics-agent-secret
                  key: VEGA_CLIENT_SECRET
            - name: VEGA_ORG_SLUG
              value: "{{ .Values.vega.orgSlug }}"
            - name: VEGA_CLUSTER_NAME
              value: "{{ .Values.vega.clusterName }}"
            # API Rate Limiting Configuration
            - name: VEGA_QPS
              value: "{{ .Values.apiRateLimiting.qps }}"
            - name: VEGA_BURST
              value: "{{ .Values.apiRateLimiting.burst }}"
            - name: VEGA_TIMEOUT
              value: "{{ .Values.apiRateLimiting.timeout }}s"
            # Advanced Collection Settings
            - name: VEGA_MAX_CONCURRENCY
              value: "{{ .Values.maxConcurrency }}"
          {{- range $key, $value := .Values.env }}
            - name: {{ $key }}
              value: {{ $value | quote }}
          {{- end }}
          resources:
            requests:
              memory: "{{ .Values.resources.requests.memory }}"
              cpu: "{{ .Values.resources.requests.cpu }}"
            limits:
              memory: "{{ .Values.resources.limits.memory }}"
              cpu: "{{ .Values.resources.limits.cpu }}"
          securityContext:
            runAsUser: {{ .Values.securityContext.runAsUser }}
            runAsNonRoot: {{ .Values.securityContext.runAsNonRoot }}
            allowPrivilegeEscalation: {{ .Values.securityContext.allowPrivilegeEscalation }}
          livenessProbe:
            exec:
              command:
                - touch
                - /tmp/healthy
            initialDelaySeconds: 120
            periodSeconds: 600
            timeoutSeconds: 5
</file>

<file path="pkg/config/config_loader.go">
// Copyright 2024 Vega Cloud, Inc.
//
// Use of this software is governed by the Business Source License
// included in the file licenses/BSL.txt.
//
// As of the Change Date specified in that file, in accordance with
// the Business Source License, use of this software will be governed
// by the Apache License, Version 2.0, included in the file
// licenses/APL.txt.
// Package config handles loading configuration using Viper
package config
import (
	"errors"
	"fmt"
	"os"
	"regexp"
	"time"
	"github.com/google/uuid"
	"github.com/spf13/viper"
)
func IsS3SafeBucketName(bueckt_name string) bool {
	// We build a regex character class that includes:
	//   - 0-9, a-z, A-Z for alphanumeric characters
	//   - !, _ , . , * , ' and ( as safe special characters.
	// The hyphen (-) is placed at the beginning to avoid confusion with a range.
	pattern := `^[-0-9A-Za-z!_.*'\(]+$`
	matched, err := regexp.MatchString(pattern, bueckt_name)
	if err != nil {
		// In case of a regex error, return false (or handle as needed)
		return false
	}
	return matched
}
// LoadConfig initializes the configuration from environment variables and command-line flags.
func LoadConfig() (*Config, error) {
	// Use the global Viper instance instead of creating a new one.
	viper.SetEnvPrefix("VEGA")
	viper.AutomaticEnv()
	// Set default values
	setDefaults()
	// Map environment variables to Viper keys
	envVars := map[string]string{
		"START_COLLECTION_NOW":  "start_collection_now",
		"SAVE_LOCAL":            "save_local",
		"AGENT_ID":              "agent_id",
		"SHOULD_AGENT_CHECK_IN": "should_agent_check_in",
		"METRICS_COLLECTOR_API": "metrics_collector_api",
		"AUTH_SERVICE_URL":      "auth_service_url",
		"LOG_LEVEL":             "log_level",
	}
	for envVar, viperKey := range envVars {
		if value := os.Getenv(envVar); value != "" {
			viper.Set(viperKey, value)
		}
	}
	// Bind environment variables
	if err := viper.BindEnv("client_id"); err != nil {
		return nil, err
	}
	// Bind command-line flags (already set in main.go)
	var cfg Config
	if err := viper.Unmarshal(&cfg); err != nil {
		return nil, err
	}
	// Parse poll_interval manually since Viper treats it as a string
	if pollIntervalStr := viper.GetString("poll_interval"); pollIntervalStr != "" {
		pollInterval, err := time.ParseDuration(pollIntervalStr)
		if err != nil {
			return nil, fmt.Errorf("invalid poll_interval: %v", err)
		}
		cfg.VegaPollInterval = pollInterval
	}
	// Validate required fields
	requiredFields := []string{cfg.VegaClientID, cfg.VegaClientSecret, cfg.VegaOrgSlug, cfg.VegaClusterName}
	for _, field := range requiredFields {
		if field == "" {
			return nil, errors.New("missing required config values: client_id, client_secret, org_slug, or cluster_name")
		}
	}
	// Validate that the cluster name is safe for use in S3 bucket names
	if !IsS3SafeBucketName(cfg.VegaClusterName) {
		return nil, fmt.Errorf("cluster_name '%s' contains invalid characters for S3 bucket names; only alphanumeric characters and the following special characters are allowed: -!_.*'(", cfg.VegaClusterName)
	}
	return &cfg, nil
}
// setDefaults sets default values for the configuration
func setDefaults() {
	viper.SetDefault("poll_interval", DefaultPollInterval)
	viper.SetDefault("log_level", DefaultLogLevel)
	viper.SetDefault("use_insecure", DefaultVegaInsecure)
	viper.SetDefault("collection_retry_limit", DefaultVegaCollectionRetryLimit)
	viper.SetDefault("upload_region", DefaultS3Region)
	viper.SetDefault("bearer_token_path", DefaultBearerTokenPath)
	viper.SetDefault("start_collection_now", DefaultStartCollectionNow)
	viper.SetDefault("save_local", DefaultSaveLocal)
	viper.SetDefault("metrics_collector_api", DefaultMetricsCollectorAPI)
	viper.SetDefault("auth_service_url", DefaultAuthServiceURL)
	viper.SetDefault("work_dir", DefaultWorkDir)
	viper.SetDefault("namespace", DefaultVegaNamespace)
	viper.SetDefault("max_concurrency", DefaultMaxConcurrency)
	viper.SetDefault("agent_id", uuid.New().String())
	viper.SetDefault("should_agent_check_in", DefaultShouldAgentCheckIn)
	viper.SetDefault("schema_version", DefaultSchemaVersion)
	viper.SetDefault("agent_version", DefaultAgentVersion)
	viper.SetDefault("qps", DefaultQPS)
	viper.SetDefault("burst", DefaultBurst)
	viper.SetDefault("timeout", DefaultTimeout)
}
</file>

<file path="pkg/utils/s3.go">
// Package utils provides utility functions for the agent
// Copyright 2024 Vega Cloud, Inc.
//
// Use of this software is governed by the Business Source License
// included in the file licenses/BSL.txt.
//
// As of the Change Date specified in that file, in accordance with
// the Business Source License, use of this software will be governed
// by the Apache License, Version 2.0, included in the file
// licenses/APL.txt.
// Package utils provides utility functions for the agent
package utils
import (
	"bytes"
	"context"
	"encoding/json"
	"fmt"
	"io"
	"net/http"
	"sync"
	"time"
	"github.com/aws/aws-sdk-go/aws"
	"github.com/aws/aws-sdk-go/aws/session"
	"github.com/sirupsen/logrus"
	"github.com/vegacloud/kubernetes/metricsagent/pkg/config"
)
// Uploader defines the interface for uploading data
type Uploader interface {
	UploadMetrics(ctx context.Context, metrics map[string]interface{}) error
}
// S3Uploader implements the Uploader interface for uploading data to S3
type S3Uploader struct {
	config    *config.Config
	s3Session *session.Session
	client    *http.Client // HTTP client for making requests
}
// NewS3Uploader creates a new S3Uploader instance
func NewS3Uploader(cfg *config.Config) (*S3Uploader, error) {
	sess, err := session.NewSession(&aws.Config{
		Region: aws.String(cfg.VegaUploadRegion),
	})
	if err != nil {
		return nil, fmt.Errorf("failed to create S3 session: %w", err)
	}
	// Create a new HTTP client with a timeout
	client := &http.Client{Timeout: 10 * time.Second}
	return &S3Uploader{
		config:    cfg,
		s3Session: sess,
		client:    client,
	}, nil
}
// getPresignedURL generates a presigned URL for uploading to S3
func (u *S3Uploader) getPresignedURL(ctx context.Context, clusterName, filename string) (string, error) {
	logrus.Debugf("getPresignedURL: Generating presigned URL for object key: %s", filename)
	// Get the auth token using the refactored GetAuthToken function
	token, err := GetVegaAuthToken(ctx, u.client, u.config)
	if err != nil {
		return "", fmt.Errorf("getPresignedURL: failed to get auth token: %w", err)
	}
	url := fmt.Sprintf(
		"%s/generate-presigned-url?cluster_name=%s&object_key=%s&slug=%s",
		u.config.MetricsCollectorAPI,
		clusterName,
		filename,
		u.config.VegaOrgSlug)
	req, err := http.NewRequestWithContext(ctx, "GET", url, nil)
	if err != nil {
		return "", fmt.Errorf("getPresignedURL: error creating request: %w", err)
	}
	// Use bearer token for authentication
	req.Header.Set("Authorization", "Bearer "+token)
	resp, err := u.client.Do(req)
	if err != nil {
		return "", fmt.Errorf("getPresignedURL: error making request: %w", err)
	}
	defer resp.Body.Close()
	if resp.StatusCode != http.StatusOK {
		return "", fmt.Errorf("getPresignedURL: API returned non-200 status: %d", resp.StatusCode)
	}
	body, err := io.ReadAll(resp.Body)
	if err != nil {
		return "", fmt.Errorf("getPresignedURL: error reading response body: %w", err)
	}
	var result struct {
		PresignedURL string `json:"presigned_url"`
	}
	if err := json.Unmarshal(body, &result); err != nil {
		return "", fmt.Errorf("getPresignedURL: error unmarshaling response: %w", err)
	}
	return result.PresignedURL, nil
}
func (u *S3Uploader) uploadToS3(ctx context.Context, presignedURL string, data []byte) error {
	client := &http.Client{
		Timeout: time.Minute * 5, // Increased timeout for large uploads
	}
	var lastErr error
	for i := 0; i < 3; i++ {
		req, err := http.NewRequestWithContext(ctx, "PUT", presignedURL, bytes.NewReader(data))
		if err != nil {
			return fmt.Errorf("uploadToS3: failed to create request: %w", err)
		}
		req.ContentLength = int64(len(data))
		req.Header.Set("Content-Type", "application/json")
		resp, err := client.Do(req)
		if err != nil {
			lastErr = err
			logrus.Warnf("uploadToS3: Failed to upload to S3, attempt %d: %v", i+1, err)
			time.Sleep(2 * time.Second) // Backoff before retrying
			continue
		}
		defer resp.Body.Close()
		if resp.StatusCode != http.StatusOK {
			body, _ := io.ReadAll(resp.Body)
			lastErr = fmt.Errorf("uploadToS3: S3 upload failed with status %d: %s", resp.StatusCode, string(body))
			logrus.Warnf("uploadToS3: Failed to upload to S3, attempt %d: %v", i+1, lastErr)
			time.Sleep(2 * time.Second) // Backoff before retrying
			continue
		}
		return nil
	}
	return lastErr
}
// MetricsUpload is the struct for the metrics upload
type MetricsUpload struct {
	SchemaVersion string      `json:"schemaVersion"`
	Items         interface{} `json:"items"`
}
// UploadMetrics uploads metrics to S3
func (u *S3Uploader) UploadMetrics(ctx context.Context, metrics map[string]interface{}) error {
	var wg sync.WaitGroup
	errChan := make(chan error, len(metrics))
	concurrencyLimit := u.config.VegaMaxConcurrency
	semaphore := make(chan struct{}, concurrencyLimit)
	for collectorName, data := range metrics {
		wg.Add(1)
		go func(collectorName string, data interface{}) {
			defer wg.Done()
			// Acquire a slot in the semaphore
			semaphore <- struct{}{}
			defer func() { <-semaphore }() // Release the slot when done
			metricsUpload := MetricsUpload{
				SchemaVersion: u.config.SchemaVersion,
				Items:         data,
			}
			// Marshal the metrics data to JSON
			jsonData, err := json.Marshal(metricsUpload)
			if err != nil {
				errChan <- fmt.Errorf("failed to marshal metrics for collector %s: %w", collectorName, err)
				return
			}
			filename := fmt.Sprintf("%s_%sUTC.json", collectorName, time.Now().Format("2006-01-02_15:04"))
			// Generate a presigned URL for the file
			presignedURL, err := u.getPresignedURL(ctx, u.config.VegaClusterName, filename)
			if err != nil {
				errChan <- fmt.Errorf("failed to generate presigned URL for collector %s: %w", collectorName, err)
				return
			}
			// Upload the JSON file to S3 using the presigned URL
			if err := u.uploadToS3(ctx, presignedURL, jsonData); err != nil {
				errChan <- fmt.Errorf("failed to upload metrics for collector %s: %w", collectorName, err)
				return
			}
			logrus.Infof("Successfully uploaded metrics for collector %s to S3", collectorName)
		}(collectorName, data)
	}
	wg.Wait()
	close(errChan)
	// Check if any errors occurred during the upload process
	for err := range errChan {
		if err != nil {
			return err
		}
	}
	return nil
}
</file>

<file path="go.mod">
module github.com/vegacloud/kubernetes/metricsagent

go 1.23.4

require (
	github.com/aws/aws-sdk-go v1.55.6
	github.com/robfig/cron/v3 v3.0.1
	github.com/spf13/cobra v1.9.1
	github.com/spf13/viper v1.20.1
	k8s.io/api v0.32.3
	k8s.io/apimachinery v0.32.3
	k8s.io/client-go v0.32.3
	k8s.io/metrics v0.32.3
)

require (
	github.com/go-viper/mapstructure/v2 v2.2.1 // indirect
	github.com/inconshreveable/mousetrap v1.1.0 // indirect
	github.com/pkg/errors v0.9.1 // indirect
	gopkg.in/evanphx/json-patch.v4 v4.12.0 // indirect
	sigs.k8s.io/randfill v1.0.0 // indirect
)

require (
	github.com/davecgh/go-spew v1.1.2-0.20180830191138-d8f796af33cc // indirect
	github.com/emicklei/go-restful/v3 v3.12.2 // indirect
	github.com/fsnotify/fsnotify v1.9.0 // indirect
	github.com/fxamacker/cbor/v2 v2.8.0 // indirect
	github.com/go-logr/logr v1.4.2 // indirect
	github.com/go-openapi/jsonpointer v0.21.1 // indirect
	github.com/go-openapi/jsonreference v0.21.0 // indirect
	github.com/go-openapi/swag v0.23.1 // indirect
	github.com/gogo/protobuf v1.3.2 // indirect
	github.com/golang/protobuf v1.5.4 // indirect
	github.com/google/gnostic-models v0.6.9 // indirect
	github.com/google/go-cmp v0.7.0 // indirect
	github.com/google/gofuzz v1.2.0 // indirect
	github.com/google/uuid v1.6.0
	github.com/hashicorp/hcl v1.0.0 // indirect
	github.com/jmespath/go-jmespath v0.4.0 // indirect
	github.com/josharian/intern v1.0.0 // indirect
	github.com/json-iterator/go v1.1.12 // indirect
	github.com/magiconair/properties v1.8.10 // indirect
	github.com/mailru/easyjson v0.9.0 // indirect
	github.com/mitchellh/mapstructure v1.5.0 // indirect
	github.com/modern-go/concurrent v0.0.0-20180306012644-bacd9c7ef1dd // indirect
	github.com/modern-go/reflect2 v1.0.2 // indirect
	github.com/munnerz/goautoneg v0.0.0-20191010083416-a7dc8b61c822 // indirect
	github.com/pelletier/go-toml/v2 v2.2.4 // indirect
	github.com/prometheus/client_model v0.6.2
	github.com/prometheus/common v0.63.0
	github.com/sagikazarmark/locafero v0.9.0 // indirect
	github.com/sagikazarmark/slog-shim v0.1.0 // indirect
	github.com/sirupsen/logrus v1.9.3
	github.com/sourcegraph/conc v0.3.0 // indirect
	github.com/spf13/afero v1.14.0 // indirect
	github.com/spf13/cast v1.7.1 // indirect
	github.com/spf13/pflag v1.0.6 // indirect
	github.com/subosito/gotenv v1.6.0 // indirect
	github.com/x448/float16 v0.8.4 // indirect
	go.uber.org/multierr v1.11.0 // indirect
	golang.org/x/exp v0.0.0-20250408133849-7e4ce0ab07d0 // indirect
	golang.org/x/net v0.39.0 // indirect
	golang.org/x/oauth2 v0.29.0 // indirect
	golang.org/x/sys v0.32.0 // indirect
	golang.org/x/term v0.31.0 // indirect
	golang.org/x/text v0.24.0 // indirect
	golang.org/x/time v0.11.0 // indirect
	google.golang.org/protobuf v1.36.6 // indirect
	gopkg.in/inf.v0 v0.9.1 // indirect
	gopkg.in/ini.v1 v1.67.0 // indirect
	gopkg.in/yaml.v3 v3.0.1 // indirect
	k8s.io/klog/v2 v2.130.1 // indirect
	k8s.io/kube-openapi v0.0.0-20250318190949-c8a335a9a2ff // indirect
	k8s.io/utils v0.0.0-20250321185631-1f6e0b77f77e // indirect
	sigs.k8s.io/json v0.0.0-20241014173422-cfa47c3a1cc8 // indirect
	sigs.k8s.io/structured-merge-diff/v4 v4.7.0 // indirect
	sigs.k8s.io/yaml v1.4.0 // indirect
)
</file>

<file path="README.md">
# Vega Kubernetes Metrics Agent

## Overview

The **Vega Kubernetes Metrics Agent** is a robust Go-based tool designed to gather, process, and upload comprehensive metrics from Kubernetes clusters. It collects a wide range of metrics across nodes, pods, persistent volumes, namespaces, workloads, networking components, and more. The agent supports both in-cluster and out-of-cluster deployment scenarios, providing flexibility for various operational environments.

## Architecture

The agent uses a collector-based architecture where:
- Each collector specializes in gathering specific metrics (nodes, pods, etc.)
- Metrics are collected in parallel with configurable concurrency
- Data is securely uploaded to S3 storage using pre-signed URLs
- Support for both metrics API and direct Kubelet collection with automatic fallback

## Key Features

- **Comprehensive Metrics Collection**:
  - **Node Metrics**: Detailed metrics for each node including capacity, allocatable resources, usage, and hardware details
  - **Pod Metrics**: Metrics for all pods covering resource requests, limits, usage, and container status
  - **Cluster Metrics**: Aggregated cluster-wide metrics with cloud provider detection
  - **Persistent Volume Metrics**: Metrics for persistent volumes, claims, and storage classes
  - **Namespace Metrics**: Resource quotas, limit ranges, and detailed usage
  - **Workload Metrics**: Deployments, stateful sets, daemon sets, jobs, and cron jobs
  - **Networking Metrics**: Services, ingresses, and network policies
  - **Orchestration Metrics**: HPAs, replication controllers, and replica sets

- **Multiple Collection Methods**:
  - **Metrics API Integration**: Primary collection through the `metrics.k8s.io` API
  - **Kubelet Direct Collection**: Fallback mechanism for detailed node metrics
  - **Automatic Failover**: Graceful degradation if primary collection method fails

- **Advanced Configuration**:
  - **API Rate Limiting**: Configurable QPS, Burst, and Timeout settings
  - **Concurrency Control**: Parallel collection with throttling
  - **Customizable Parameters**: Extensive configuration options through environment variables and flags

- **Operational Features**:
  - **Health Check**: Simple HTTP endpoint for liveness monitoring
  - **Secure Authentication**: Bearer token authentication for API access
  - **Cloud Provider Detection**: Automatic identification of AWS (EKS), Azure (AKS), GCP (GKE)
  - **Agent Check-in**: Optional capability to report agent status

## Installation

### Prerequisites

Before installing, ensure the following:

- A Kubernetes cluster
- Go 1.23+ (if building from source)
- AWS credentials (for S3 uploads)

### Building from Source

1. Clone the repository:
    ```sh
    git clone https://github.com/vegacloud/vega-metrics-agent.git
    cd vega-metrics-agent
    ```

2. Build the project:
    ```sh
    make build
    ```

3. Run the agent:
    ```sh
    ./vega-metrics-agent --help
    ```

### Deploying with Helm Chart

The easiest way to deploy the Vega Metrics Agent is using the provided Helm chart.

#### Basic Installation

```sh
helm install vega-metrics-agent ./charts/vega-metrics-agent \
  --set vega.clientId=YOUR_CLIENT_ID \
  --set vega.clientSecret=YOUR_CLIENT_SECRET \
  --set vega.orgSlug=YOUR_ORG_SLUG \
  --set vega.clusterName=YOUR_CLUSTER_NAME
```

#### Customizing API Rate Limiting

To customize the API rate limiting settings, use the following parameters:

```sh
helm install vega-metrics-agent ./charts/vega-metrics-agent \
  --set vega.clientId=YOUR_CLIENT_ID \
  --set vega.clientSecret=YOUR_CLIENT_SECRET \
  --set vega.orgSlug=YOUR_ORG_SLUG \
  --set vega.clusterName=YOUR_CLUSTER_NAME \
  --set apiRateLimiting.qps=200 \
  --set apiRateLimiting.burst=300 \
  --set apiRateLimiting.timeout=15
```

#### Adjusting Concurrency

To control the maximum number of concurrent metric collection operations:

```sh
helm install vega-metrics-agent ./charts/vega-metrics-agent \
  --set maxConcurrency=12
```

#### Using a Custom Values File

Create a file named `custom-values.yaml` with your desired configuration:

```yaml
vega:
  clientId: "YOUR_CLIENT_ID"
  clientSecret: "YOUR_CLIENT_SECRET"
  orgSlug: "YOUR_ORG_SLUG"
  clusterName: "YOUR_CLUSTER_NAME"

apiRateLimiting:
  qps: 200
  burst: 300
  timeout: 15

maxConcurrency: 12

resources:
  requests:
    memory: "4Gi"
    cpu: "750m"
  limits:
    memory: "8Gi"
    cpu: "1500m"
```

Then install using:

```sh
helm install vega-metrics-agent ./charts/vega-metrics-agent -f custom-values.yaml
```

#### Helm Chart Parameters

| Parameter | Description | Default |
|-----------|-------------|---------|
| `apiRateLimiting.qps` | Kubernetes API requests per second | 100 |
| `apiRateLimiting.burst` | Maximum burst of API requests allowed | 100 |
| `apiRateLimiting.timeout` | API request timeout in seconds | 10 |
| `maxConcurrency` | Maximum concurrent collector operations | 8 |
| `resources.requests.memory` | Memory request for the agent | "2Gi" |
| `resources.requests.cpu` | CPU request for the agent | "500m" |
| `resources.limits.memory` | Memory limit for the agent | "4Gi" |
| `resources.limits.cpu` | CPU limit for the agent | "1000m" |
| `replicaCount` | Number of agent replicas to run | 1 |
| `image.repository` | Agent container image repository | public.ecr.aws/c0f8b9o4/vegacloud/vega-metrics-agent |
| `image.tag` | Agent container image tag | 1.1.3 |
| `image.pullPolicy` | Container image pull policy | Always |

**Note**: If you do not specify the API rate limiting or concurrency parameters, the agent will use its built-in defaults, which are optimized for most use cases.

### Configuration

The Vega Metrics Agent can be configured using either environment variables or command-line flags. Below are the key configuration parameters:

| Environment Variable         | Description                                 | Required  | Default Value |
|------------------------------|---------------------------------------------|-----------|---------------|
| VEGA_CLIENT_ID              | Client ID for authentication                | Yes       | |
| VEGA_CLIENT_SECRET          | Client secret for authentication            | Yes       | |
| VEGA_CLUSTER_NAME           | Name of the Kubernetes cluster              | Yes       | |
| VEGA_ORG_SLUG               | Your Vega Cloud Organization slug           | Yes       | |
| VEGA_POLL_INTERVAL          | Interval for polling metrics                | No        | 60m |
| VEGA_UPLOAD_REGION          | AWS region for S3 uploads                   | No        | us-west-2 |
| LOG_LEVEL                   | Log level (DEBUG, INFO, WARN, ERROR)        | No        | INFO |
| VEGA_INSECURE               | Use insecure connections                    | No        | false |
| VEGA_WORK_DIR               | Working directory for temporary files       | No        | /tmp |
| VEGA_COLLECTION_RETRY_LIMIT | Retry limit for metric collection           | No        | 3 |
| VEGA_BEARER_TOKEN_PATH      | Path to the bearer token file               | No        | /var/run/secrets/kubernetes.io/serviceaccount/token |
| VEGA_NAMESPACE              | Kubernetes namespace for agent deployment   | No        | vegacloud |
| VEGA_QPS                    | API rate limiter for requests per second    | No        | 100 |
| VEGA_BURST                  | API rate limiter burst allowance            | No        | 100 |
| VEGA_TIMEOUT                | Timeout for API requests                    | No        | 10s |
| VEGA_MAX_CONCURRENCY        | Maximum number of concurrent collectors     | No        | 8 |

Additional parameters for local testing and debugging include:

- AGENT_ID: Unique identifier for the agent
- SHOULD_AGENT_CHECK_IN: Determines if the agent should check in with the metrics server
- START_COLLECTION_NOW: Start metric collection immediately
- SAVE_LOCAL: Save metrics locally

#### API Rate Limiting Configuration

The agent provides the following parameters to control the rate of API requests to the Kubernetes API server:

- **QPS (Queries Per Second)**: Controls the sustainable rate of requests to the Kubernetes API. Default is 100 QPS.
- **Burst**: Sets the maximum burst of requests allowed beyond the QPS rate. Default is 100 requests.
- **Timeout**: Sets the timeout for individual API requests. Default is 10 seconds.

These settings can be adjusted based on your cluster size and API server capacity. For larger clusters or environments with high API server load, you may need to tune these values to prevent overwhelming the Kubernetes API server.

Example environment variable configuration:
```
VEGA_QPS=200
VEGA_BURST=300
VEGA_TIMEOUT=15s
```

Example command line configuration:
```
--qps=200 --burst=300 --timeout=15s
```

### Deploying in Kubernetes

The default namespace for the agent is `vegacloud`. When deployed, the agent gathers metrics from the Kubernetes API and directly from the cluster nodes. Metrics are uploaded to an Amazon S3 bucket at the configured interval.

Ensure that the agent has outbound access to:

- **api.vegacloud.io** (port 443) — for pre-signed URL retrieval and check-ins
- **vegametricsocean.s3.us-west-2.amazonaws.com** (port 443) — for uploading data

If your cluster is behind a firewall, add these addresses to your outbound allowlist.

### Supported Kubernetes Versions

The Vega Kubernetes Metrics Agent supports Kubernetes versions up to 1.30 across cloud platforms such as AWS (EKS), Google Cloud (GKE), Azure (AKS), and Oracle Cloud (OKE). The agent automatically detects the cloud provider and adapts its collection methods accordingly.

## Usage

### Running the Agent

To run the agent, execute:

```sh
vega-metrics-agent --help
```

This displays help for available flags, such as:

- `--client_id`: Client ID for authentication
- `--client_secret`: Client secret for authentication
- `--cluster_name`: The name of the Kubernetes cluster
- `--log_level`: Set log verbosity (DEBUG, INFO, WARN, ERROR)
- `--qps`: Set API request rate limit in queries per second
- `--burst`: Set API request burst allowance
- `--timeout`: Set API request timeout duration (e.g., 10s, 15s, 1m)
- `--max_concurrency`: Set maximum concurrent collector operations

### Health Check

You can check the agent's health by accessing the `/health` endpoint on port 80. This endpoint returns a simple "OK" response if the agent is running properly.

### Networking and System Requirements

#### Networking

Ensure the container running the agent allows outbound HTTPS requests to the following:

- api.vegacloud.io (port 443)
- vegametricsocean.s3.us-west-2.amazonaws.com (port 443)

#### Resource Recommendations

Based on the number of nodes in your cluster, here are guidelines for CPU and memory resources for the agent. Please note: Your mileage may vary depending on cluster size and configuration:

| Nodes   | CPU Request | CPU Limit | Mem Request | Mem Limit |
|---------|-------------|-----------|-------------|-----------|
| < 50    | 200m        | 500m      | 512Mi       | 1Gi       |
| 50-100  | 300m        | 700m      | 1Gi         | 2Gi       |
| 100-250 | 500m        | 1000m     | 2Gi         | 4Gi       |
| 250-500 | 750m        | 1500m     | 4Gi         | 8Gi       |
| 500-1000| 1000m       | 2000m     | 8Gi         | 12Gi      |
| 1000+   | 1500m       | 3000m     | 12Gi        | 16Gi      |

**Notes on resource allocation:**

- **CPU requests** should be set to allow guaranteed minimum CPU resources. The metrics agent doesn't need high CPU most of the time but benefits from having a consistent baseline.
- **CPU limits** should be set moderately higher than requests to allow for metric collection spikes. Setting CPU limits too low can cause throttling that may interrupt metrics collection.
- **Memory requests** should be set to accommodate the baseline memory footprint plus overhead for metrics processing.
- **Memory limits** should be set higher than requests to prevent OOM (Out of Memory) kills during peak collection periods.

These values should be adjusted based on your specific monitoring needs, collection frequency, and the total number of metrics being collected. For clusters with high pod density or custom metric collection, increase these values accordingly.

## Contributing

We welcome contributions! If you have any suggestions, improvements, or bug reports, feel free to open an issue or submit a pull request.

## License

This project is licensed under the Business Source License (BSL) 1.1. After the specified change date, it will be governed by the Apache License 2.0.

## Support
- Enterprise Customers: Support for the Vega Kubernetes Metrics Agent is available through the [Vega Cloud Support Portal](https://support.vegacloud.io/).
- Community and General Public support: Support is best effort. Please file an issue, bug report, or feature request using the [GitHub Issues](
    https://github.com/vegacloud/vega-metrics-agent/issues).

## Recent Changes

### Helm Chart Enhancements

The Helm chart now includes support for configuring the API rate limiting and concurrency settings. These settings help you optimize the agent's performance in various cluster environments:

- **API Rate Limiting**: Control the rate at which the agent makes API requests to the Kubernetes API server through the `apiRateLimiting.qps`, `apiRateLimiting.burst`, and `apiRateLimiting.timeout` parameters.
- **Concurrency Control**: Adjust the maximum number of concurrent collection operations through the `maxConcurrency` parameter.

If you do not specify these parameters, the agent will use its built-in defaults, which are optimized for most use cases.

### API Rate Limiting Enhancement

The Metrics Agent now includes configurable rate limiting for Kubernetes API requests through the QPS, Burst, and Timeout settings. These parameters allow you to fine-tune how the agent interacts with your Kubernetes API server:

- **QPS (Queries Per Second)**: Controls the sustained request rate to the Kubernetes API server.
- **Burst**: Allows temporary spikes in request rates while maintaining a sustainable average.
- **Timeout**: Sets the maximum duration for API requests before they time out.

For larger clusters or environments with high API server load, adjusting these values can help prevent the agent from overwhelming your Kubernetes API server.

### Metrics Collection Enhancement

The Metrics Agent now supports collecting CPU metrics via the `metrics.k8s.io` API. This change provides the following benefits:

1. **Improved Reliability**: The agent can now retrieve metrics directly from the metrics-server instead of requiring access to the kubelet API on each node.

2. **Better Security**: The agent no longer needs to access the kubelet API directly, reducing the security permissions required.

3. **Fallback Mechanism**: If metrics-server data is unavailable, the agent will automatically fall back to the traditional kubelet-based collection method.

## Requirements

- Kubernetes cluster 
- The latest kubernetes metrics-server installed (optional)
- Service account with appropriate RBAC permissions

## Troubleshooting

If you encounter issues with CPU metrics and you have installed the metrics-server:

1. Verify that the metrics-server is installed and running in your cluster:
   ```
   kubectl get pods -n kube-system | grep metrics-server
   ```

2. Check that the metrics API is available:
   ```
   kubectl get apiservices | grep metrics
   ```

3. Test direct access to the metrics API:
   ```
   kubectl get --raw /apis/metrics.k8s.io/v1beta1/nodes
   ```

4. Check the agent logs for any connection errors
</file>

<file path="charts/vega-metrics-agent/values.yaml">
# Copyright 2024 Vega Cloud, Inc.
#
# Use of this software is governed by the Business Source License
# included in the file licenses/BSL.txt.
#
# As of the Change Date specified in that file, in accordance with
# the Business Source License, use of this software will be governed
# by the Apache License, Version 2.0, included in the file
# licenses/APL.txt.
namespace: vegacloud
serviceAccount:
  name: vega-metrics-sa
image:
  repository: public.ecr.aws/c0f8b9o4/vegacloud/vega-metrics-agent
  tag: 1.1.3
  pullPolicy: Always
replicaCount: 1
resources:
  requests:
    memory: "2Gi"
    cpu: "500m"
  limits:
    memory: "4Gi"
    cpu: "1000m"
securityContext:
  runAsUser: 10000
  runAsNonRoot: true
  allowPrivilegeEscalation: false
# Node selector to constrain pods to specific nodes
nodeSelector: {}
  # Example:
  # disktype: ssd
  # kubernetes.io/os: linux
# Pod affinity/anti-affinity rules
affinity: {}
  # Example:
  # podAntiAffinity:
  #   requiredDuringSchedulingIgnoredDuringExecution:
  #   - labelSelector:
  #       matchExpressions:
  #       - key: app
  #         operator: In
  #         values:
  #         - metrics-agent
  #     topologyKey: kubernetes.io/hostname
# Tolerations allow pods to be scheduled on nodes with matching taints
tolerations: []
  # Example:
  # - key: "example-key"
  #   operator: "Exists"
  #   effect: "NoSchedule"
vega:
  clientId: "XXXXX" # Log into your portal and visit settings->Client Registration to obtain this
  clientSecret: "XXXX" # Log into your portal and visit settings->Client Registration to obtain this
  orgSlug: "XXXX"
  clusterName: "XXXX" # This must be a unique identifier for your cluster. may not contain spaces or special characters. regex: ^[-0-9A-Za-z!_.*'\(]+$
env:
  # For production, you should be using certificates internal to your cluster. 
  # We put this by default becuase most k8s clusters are not using tls certs internally.
  VEGA_INSECURE: true
# VEGA_POLL_INTERVAL: "120m" # Default is 60M
</file>

</files>
